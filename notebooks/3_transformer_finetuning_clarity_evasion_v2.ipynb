{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# QEvasion – Transformer Fine-tuning (Clarity & Evasion)\n",
        "\n",
        "In this notebook we fine-tune a pretrained transformer encoder on the QEvasion dataset\n",
        "for the two main tasks:\n",
        "\n",
        "- **Task 1 – Clarity-level classification (3-way)**  \n",
        "  Labels: `clarity_label` → `clarity_id`\n",
        "\n",
        "- **Task 2 – Evasion-level classification (9-way)**  \n",
        "  Labels: `evasion_label` → `evasion_id` (on the train split)  \n",
        "  + special **test evaluation** using annotators (`annotator1/2/3`).\n",
        "\n",
        "We:\n",
        "1. Load and preprocess the data.\n",
        "2. Create train/validation/test splits.\n",
        "3. Tokenize question–answer pairs with a pretrained tokenizer.\n",
        "4. Fine-tune a transformer with a **manual PyTorch loop** (no `Trainer`).\n",
        "5. Evaluate Task 1 on the official test split.\n",
        "6. Train and evaluate Task 2, including test evaluation using annotators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install -q \"transformers==4.45.2\" \"datasets>=2.19\" sentencepiece safetensors scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path(os.getcwd()).parent\n",
        "sys.path.append(str(project_root))\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Import data utilities\n",
        "from src.data import (\n",
        "    load_qevasion_prepared,\n",
        "    prepare_task1_data,\n",
        "    prepare_task2_data,\n",
        "    CLARITY_LABELS,\n",
        "    EVASION_LABELS,\n",
        "    CLARITY_TO_ID,\n",
        "    EVASION_TO_ID,\n",
        "    ID_TO_CLARITY,\n",
        "    ID_TO_EVASION\n",
        ")\n",
        "\n",
        "# Import metrics utilities\n",
        "from src.metrics import (\n",
        "    evaluate_task1,\n",
        "    evaluate_task2_standard,\n",
        "    evaluate_task2_multi_annotator,\n",
        "    plot_confusion_matrix,\n",
        "    compute_per_class_metrics,\n",
        "    majority_baseline_accuracy\n",
        ")\n",
        "\n",
        "# Import model architectures and losses\n",
        "from src.models import (\n",
        "    MultiTaskTransformer,\n",
        "    FocalLoss\n",
        ")\n",
        "\n",
        "# Import training utilities\n",
        "from src.training import (\n",
        "    EarlyStopping,\n",
        "    evaluate,\n",
        "    evaluate_multitask,\n",
        "    train_model\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration:\n",
            "  Model: distilbert-base-uncased\n",
            "  Max Length: 256\n",
            "  Batch Size: 16\n",
            "  Learning Rate: 2e-05\n",
            "  Max Epochs: 10\n",
            "  Early Stopping Patience: 3\n"
          ]
        }
      ],
      "source": [
        "# Model configuration\n",
        "MODEL_NAME = \"distilbert-base-uncased\"  # Options: \"roberta-base\", \"bert-base-uncased\"\n",
        "MAX_LENGTH = 256\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# Training configuration\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_EPOCHS = 10\n",
        "PATIENCE = 3  # For early stopping\n",
        "\n",
        "# Random seed for reproducibility\n",
        "RANDOM_STATE = 42\n",
        "VAL_SIZE = 0.1\n",
        "\n",
        "print(\"Configuration:\")\n",
        "print(f\"  Model: {MODEL_NAME}\")\n",
        "print(f\"  Max Length: {MAX_LENGTH}\")\n",
        "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"  Learning Rate: {LEARNING_RATE}\")\n",
        "print(f\"  Max Epochs: {NUM_EPOCHS}\")\n",
        "print(f\"  Early Stopping Patience: {PATIENCE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load & Explore Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "TASK 1: CLARITY CLASSIFICATION\n",
            "============================================================\n",
            "Train: 3103 examples\n",
            "Val:   345 examples\n",
            "Test:  308 examples\n",
            "\n",
            "Labels: ['Ambivalent', 'Clear Non-Reply', 'Clear Reply']\n",
            "Majority Baseline Accuracy: 0.6688\n",
            "\n",
            "============================================================\n",
            "TASK 2: EVASION CLASSIFICATION\n",
            "============================================================\n",
            "Train: 3103 examples\n",
            "Val:   345 examples\n",
            "Test:  308 examples (multi-annotator)\n",
            "\n",
            "Labels: ['Claims ignorance', 'Clarification', 'Declining to answer', 'Deflection', 'Dodging', 'Explicit', 'General', 'Implicit', 'Partial/half-answer']\n",
            "Majority Baseline Accuracy: 0.3043\n"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "dataset = load_qevasion_prepared()\n",
        "\n",
        "# Prepare Task 1 (Clarity) data\n",
        "clarity_train_df, clarity_val_df, clarity_test_df = prepare_task1_data(\n",
        "    dataset, val_size=VAL_SIZE, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# Prepare Task 2 (Evasion) data\n",
        "evasion_train_df, evasion_val_df, evasion_test_df = prepare_task2_data(\n",
        "    dataset, val_size=VAL_SIZE, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"TASK 1: CLARITY CLASSIFICATION\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Train: {len(clarity_train_df)} examples\")\n",
        "print(f\"Val:   {len(clarity_val_df)} examples\")\n",
        "print(f\"Test:  {len(clarity_test_df)} examples\")\n",
        "print(f\"\\nLabels: {CLARITY_LABELS}\")\n",
        "print(f\"Majority Baseline Accuracy: {majority_baseline_accuracy(clarity_train_df['clarity_id'].values, clarity_test_df['clarity_id'].values):.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TASK 2: EVASION CLASSIFICATION\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Train: {len(evasion_train_df)} examples\")\n",
        "print(f\"Val:   {len(evasion_val_df)} examples\")\n",
        "print(f\"Test:  {len(evasion_test_df)} examples (multi-annotator)\")\n",
        "print(f\"\\nLabels: {EVASION_LABELS}\")\n",
        "print(f\"Majority Baseline Accuracy: {majority_baseline_accuracy(evasion_train_df['evasion_id'].values, evasion_val_df['evasion_id'].values):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABdEAAAHpCAYAAABtM3XZAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAxHhJREFUeJzs3Qm8zOX///+XnWSXLWuLNUsoaRElilZalKISLbRpVQiJokUi7bRQWiytsiRaVOhTQhQJlSXZosgy/9vz+v6v+b1nzhnrOeac9zzut9twzsycOTPv816u63W9rteVIxKJRAwAAAAAAAAAAKSRM+1dAAAAAAAAAABACKIDAAAAAAAAAJAAQXQAAAAAAAAAABIgiA4AAAAAAAAAQAIE0QEAAAAAAAAASIAgOgAAAAAAAAAACRBEBwAAAAAAAAAgAYLoAAAAAAAAAAAkQBAdAAAAAAAAAIAECKIDKWTUqFGWI0cOd+vTp4+FgT6H/0z6fNn1dxxKmfl5Pv300+hrX3311ZYZfv311+jvaNq0qWWV40jvxd+v93goJXubpOett95y7yd37ty2fPnypL2PjNo2nTt3dq9Ru3Zti0QiGfoeAQDhEsY2dzKlwvb0n69y5coZ/tqHoo2qdr//HeoPHGrabv73H8p+SVbeJvHUflU7Vu9H7dpkyohto/6F+hl6DfU7gEOBIDqQxAv83m5Z4WIbb/369dajRw87/fTT7bDDDsu0hol+T79+/ezEE0+0YsWKWYECBezYY4+1Sy65xCZMmJAlglj6+6ghr9t3332XqcG/YIMwTIKNet3y5s1rRxxxhNWvX9+6du1q8+fPz5Tt6v9u2peyUwfSv++NGzdaVrZ79+5oJ/eiiy6ySpUqxXRk9nbLjA7kwbrtttvc/9on33zzzWS/HQBAyNvc//vf/+zee++1k08+2Y488shoG+m8886zzz77LEOTKtK7FS1aNEM+R9gEg39hDOjHt9dy5cplhx9+uFWpUsXOOecce/75523btm0p3c7Nrn2KsWPHRvtWvl0b3xfb0y2rJZOpf9GmTRv3dd++fV3/A8hsuTP9NwAIlRUrVtjDDz+cqb9DHYO2bdvan3/+GXP/kiVL3O3tt9+2DRs2HLLG/bXXXmvNmzd3X1etWjWmkakLtu+o1atX75C8nzDbsWOHrVu3zt3UeRwxYoT16tUrup2lbNmy0c5jkSJFDqjB61+vY8eOduGFF+7Xz7dq1Sr6+ytWrGiHihquM2bMiHbggvv/wW6TjPbhhx/awoUL3dfXXXddUt9LRm2bWrVqWePGjW3WrFk2ePBgu+yyyzLwXQIAEOvZZ591tyC1j95//313nVXmpQ8ghV2y2l74v8SIrVu3upva0JMmTbLHHnvMJk6caNWqVYs+7/7774+2+ZTtnJHt3H2h/mFmBPcPpk9xsNskoz366KPu/5NOOsm1a5Mpo7aNXkPnwgULFrjz4rnnnpuB7xJIiyA6cIjFX+CVWb169Wr39dChQ+3444+PPpYVLrbxlAXTpEkTlxWzdu1ae+mllzL09ZcuXeoybDZt2uS+V+Ose/fuLgtdHYfJkyfba6+9ZoeCGosFCxZ0jXUa7Jnvvvvus5YtW9rvv//uMn39jAPNSNBsBJ8xkS9fPjv11FMP+fv777//LGfOnFaqVCl3y0qStU0SGTlypPtff7czzjjDfa1zWzBzToMkt9xyi/u6TJkyMdMw8+fPn7Ajp79Doscze9soWKEg+ty5c10mz3HHHZchrwsAyHjZvc3tr4+dOnVy1zElkChgt3jxYnc9VPs4o4LoyjBWOyxIZRKyiqzY9koFvn2mPpHaPjpu1qxZ4/bBs88+27XlfLBbfTXdDjXfX2vYsKFlNcnaJun54Ycf3N9QlKzmPfXUU9F+t9x8883RGdY6J+jc4AWTydL7GyRj2zRr1sz1N3R+1EAMQXRkugiApKpUqZLqkrjb9OnTo/f/9ttvkWuuuSZSp06dSIkSJSK5c+eOFCtWLNKsWbPI+PHj07zOM888E2nQoEGkYMGCkbx580bKlSsXOfPMMyOPPPJI9DkjR46M/q4HHnggen+nTp2i97dq1Sqyffv2fXrvI0aMiP5cx44d032O7k/v8yVy+eWXR59/1FFHRTZt2pTmOUuXLo2+R30O/3x9Pu+FF16ItGjRIlKhQoXIYYcdFsmXL1/kmGOOiXTr1i3y559/xrze6aefHn2NuXPnuu2ube5Pken9Dv99ercXX3wxUrFiRfe1fvfff/8d8/vq1avnHsuVK1dkzZo1CbfFsmXLYl53T2bMmBG5+OKL3WcsUqRIJE+ePJGyZctGLrnkksj3338f89z4zzNs2LDI0Ucf7bZR/fr1I5MnT07z+mvXro3cfvvt7vW1fxUtWtTtK7NmzYp5nv7Ge9snEm374N9P7rjjjuhjhQoVimzYsCHNdtHPe//880/kzjvvjL5HbfvKlStHLrroosi4cePS/L74m3+/wX32ww8/jHTv3j1SpkyZSI4cOdzvTnQcBV97wYIFkVtuuSVyxBFHuPfRunXryJIlS2I+n3+uzgGJtol+X3CbpnfTcxJtE9ExdN9990WqV68eyZ8/f+Twww+PnHjiie6csXv37oTv6aeffoqcd9557pyic8/1118f+ffff/f6N9Wxqd+j19G2TyT4ueK3QXAf1fH04IMPumMqZ86c7ue2bNkSueGGG9w5r1SpUm5/L1y4cOSkk05yx35Qom0T/B0vvfRS5IknnnDHgfYdnXenTZuW5j1/99130Z/p16/fXrcFACDryG5t7s8++yyydevWhNch3YLtyERt4kSCz99Tm01tY/+8888/P+YxbTu1j/TYCSeccMi3p/z888+Rq6++OlK+fHnXHihevHjknHPOiUydOnWPbdRJkyZFGjZs6Nq/6i88+eSTkX0RbCfGv5d4akM2btzYtSP12fQZjz/++MjgwYMjO3bsiHlusE2ktou2tdps2oY33XSTa/vEmzBhgttWapfr9atWrRrp06ePaxPvqW25J3tqn61cudL1M/zjPXv2THe7BI8vfa33qH1A+0LJkiXdvqJ28saNGw+onat+j9p8am/6fTd4fKf3WfQ8te30u/U3Vx9Bbb+gRMdQev2b/e1TxPeD9V50DtDfV/ut9l89X+3vRO9pX9ur6enbt2/0deL7hvvaNwvuF/PmzYs0b97c7dO+fa3jW30HbVvtu/pcar/r+Izf7xJtmwPpi1x44YXuZ7Q/7GscAzhQBNGBLNqgV3ByTw2Kl19+OfrcV155JeHzjjzyyD02QHv06BG9Tw2cfQmSZVYQfdu2bZECBQpEnz9q1Ki9vodEjZ2WLVsm3CY1atSI+ZzBxoIC98HnJvode/rb6DnBn3n11Vejv2vFihXR+xXk35P9CaIPHDgw4ftREHfhwoXpbjM1vuKfrwbPzJkzo89fvny5a9il99p67sSJEzMliK7BBzWY4rdjoqDotddem3AbtG/f/oAavPH7w74G0dPbrjoW161bl24jMbOC6OvXr3fB80Q/265du5jf7e9XQNoPJAVv999//17/pl9++WX0+Qp+H2wQPf5voJ9btWrVHreJOgr7E0SP/x1+4EbbL0gdXnW89LjOMQCA7CM7t7k9BdWDvzOYqJFZQXRR29kHqTZv3hy9X4Fn/xo+CH2otqd8/fXX7nqd3s8ruP/0008nbHdoYD7+Z6ZMmZKhQXTfZkjvpoGGIH+/BgHSa3efffbZMc/v1atXwtc+7bTTYoKJGRVEl/79+0cfVzA3ve3ij69FixbF9O3ibxoA2d92rgZZfLJGcN/dWxBd+7D6LfGvrz7UoQ6iDx8+PDr4lF7785tvvjmo9mp61O/0x3D8AM7+BtE1kBLsJ/j2tYLcibZJ6dKlYwb99hZE35++iBJb/OPxCV5ARmNhUSALT59T7fF33nnHpk6datOnT7eXX37ZLSgk/fv3jz5XNen8tMtnnnnGpk2bZqNHj7Y77rjDLQKTyJNPPmkDBw50X5922mn27rvv7leZhIz2888/27///hv9Xu/pQKlesUrNfPDBB652uf7v0KGDe+zHH3+0cePGJaz5/sADD9jHH39sTzzxRMLXV1mKa665Jvq9prvpPt1Ut1GP+cVA9bfwtI29yy+/3DKKFmDVdDy9vvaVKVOm2COPPOIe++effxJ+FtWPU7kU1ddUKRVfl9yXTpGbbrrJfvvtN/e1tqFqIapWuRYZ0nNVM17T+DKaXj9YLmNvi7f640CLzGgKt0r/vPjii+49a5qfaBtpKqqnKYr+76bafPF++eUXV3JEn1l1SQsVKrRP7/2PP/5wJU00Bfaoo45y96lMzYABA2x/+TIowZr7el3/vlXzOxHtl4sWLYpOVdd+/8ILL0S3xxtvvOEWGYq3efNmd67R+efBBx+M3h9fmzU9Or68Y445xg6W/gbt27d3x/Arr7ziFlfTosbab1X2R39n7fP6LH5aqGqWq+zL/vyOe+65xx0/devWdff9/fffNmbMmJjn6Ryr/Ut8zXcAQPaWndrceo+eXkdtpYygzxu/iKDqUnu6DovK46jN6Km9JVp8sl27dodse4ribWpv63otF198sWsraC0dld/T42rPrly5Ms3PLl++3JWPfO+996Lve1/bOftDbcvXX3/dtSPVH1E7rFGjRu4xlZ7w7eug9evXW+nSpV1ZQ7Vb1eYRvYber8yePTvaPlM7UO1dPd66dWt3n9qHe+rHHAytDxMsw7lly5aEz1V/xPftbr31Vvf31T6jfUDlV7Sf7W87V23s8uXLu/KeqoG9r2sbqX2qkk7aR26//fbo/VoUVCVD99f+9ik87Y/6/do/tZ/27NnTvSe9N9H+rGPv/+LJB9ZeTfT5Re3Ygy3VpPIvOuafe+4512f2tc1btGjhjiHtp9rftU/qWBaVAVIfZF/tT18k2N+gfY7MlnUKnQGIoYUq1QgdMmSIq2Gmi1XwYqqAsy4uhQsXtjx58kTrlesiokaJ7r/iiisSvr4ubqpjJ2rM6eLtG2kZSQ3EfV3JO1iPTcqVK3fAv1cLgeqCq8a7Glvbt2+PeXzOnDnpbp+7777bNaZ8QyAR1abUa3sK3sXXXdZ7UONRz1P9eNVy9I1f1Wm+6KKLLKNogRg12tSYUYNWgfP4z5sedRzU2fCfSdtcP/vtt9+6Rp7q26mBKtofO3fu7L5WcPuss86y8ePH219//eUaScH6ehkl2HCO3z/i+eNAtRmPPvpoq1GjhtvOCvJ7CiTr/Xr6m+ypXrb2EXV895c6yr7zqfejbSXqEGkxpv2hxTD1HoOLYuoY1zliT1QvNRggVwPbD0qoQ6Oah6LOXXqLZOp+dWhUb1UdWgXj1cnQ32FPC3QGOyI+WH8wTjnllHTXQVCnS50XncdUB3HXrl3Rx9Sh0/utU6fOPv2OCy64ILpgsvZ/36HWQsbx/Gc6kA4XACDryS5tbtUz9tdutW/ig6Rqv/o2bEbT51N7UdtFQVAlgqi+/BdffOEeVzvH1yzP7O0ZTK7wATP9PrVz9HpKZtH9Cr5pQF3/B5NDRO9VbSRtxxNOOMENxCe67h8MrQujgf2vv/7atRt27twZfUzbRO1tBYTj6f34wKC280MPPRRtRyr4H0zQ0UCCr1V9ww03uP1L1HZSwDWjxQe19fdNNJjj/76iQZGaNWu6v5UEA837085V4FkDOcFFTfeF1rdSMoaCv9pHvvnmG7f/qo/40Ucf2VVXXbVfr7e/fQpPx49P9FBf0AeIdQypL6e/t/bf77//PmZgYX/bq/F8uzUj2uZ+//L9G69p06ZuX3388cddYlowOW5P/dFE9rUvEvxMtM+R2chEB7IoNYwVhNPFdOPGjemORut+8VnPupgqcKuLSoUKFezKK69MeLFSo02vqcxaNbb2NcM2M8UH5hT8PhAakdfCp88//7wtW7YsTQA9uO3iqWGaUbQQlKjBrIa6AnsalRc13vYUiNxf6syo46TOSnwAfU+f12fDiN5PsEGqbAc1yvy+p0adsp78TQH09LKPM5Kyt4Pvb1+2txqdCrBqAECNdS28tWrVqgP6/Qe6PwS3q2YJeL/++mu6x3Jm+PPPP11wWdRZD2b1B9/TTz/9lOZn1YENNtxLlCix130pPRnxWdNbIEiZXPrbaJBKjeVgAP1A3ufpp5++z5/1UP39AACHRnZoc3/++ecuIKvgkbJIFVxq0KCBZZRgFm162bQKgKptLUqc0AxEXYs1YC/6/Idqe6bXfqlfv35MwHZv7RwlnyiAfjBtnL1RkFaLHirbXm3oYAB9T7+vePHiMZm1wc+itnn8Z9IsR982D7Zb/UzEzGyb7619rqCv374ayFAAXp9P+1twQfn9ocSl/Q2g+8C8Auh72q6HQvBvF+wvaP8NLnac3n67P+3VRDKiHatZNPEBdLXFdQwrgK6FZ+MD6Pv7PvenL0LbHIcSQXQgi9IUsWB2tKa/qTGqUW/PN1yVMa2RdGUJ6+KrgJmmB2rEVhfb9BoGvhGhgHPv3r0tK1CjqECBAtHvfXbL/lJw10+PrF69ugtgx09r9NsunqZPZhRNL1RD0Y/Wq9PhA/r7kmGzrzTS78vEKBPk6aefdsF6H7Df0+eN50vQ7K/MKOeiLKX58+dHv4/PxoinTA51KjUdUo1rfRYF9/V31zGSXudlbzJif9jbNo0PAGdGBkX8e9jbe4rPUglO+9xbQ7VkyZLRr30Q/2Ck9zcYNmxY9Gt11FXSRcd4sEG/r/t8/Ofd22f1nyn4OQEA2VdWb3PrGqeSe2oXKfCrTNaMnM0YzKIN3nyJNM8HyhXw1ixFX8pFSQvBkhqZvT33xf60c/anjbM/VJ5GZQ99QoC2mbaDLy+5r22VA22bq92bXiLRwQr2zzTzc08lhZR1rhkUyojXPqVAqNpR6hNdeuml0RkA+yOj+mrpbdfgfcH2+aHKbs7M/da3WzOibe5nncTvF37GjQZLVMJp5syZrm92sG3zvX3e4GeifY7MRhAdyKL8KL8aG6ptrewTNS7jR//9hUT16VTKQ9kuaqT7khFq6KqhEu/GG2+MZjko6OqnhiWTOgbBRnjfvn2jdQ6D1KDeU73j4Dbq2rWra6Sp4aY6jhnZUNV0wj01CvR5fIdD2Sia1irKQPI1CzNC8POqk6W/rToePsNmT/S+PGU3KXPAUy1v7SN+m6ihrAb5/78odfSmv4XqU2c0dTR9CRc10Pdlm2lao+pkK/tG+47qY4qC8T6jY29/t4zouAS3q6bwepqa6l/TZ+5oKqjvZClTPVHm0P68b1EdQZWS8YMcqn+f3nvyU4AzisroeBkxLTq9v0Fwn1dnXcFzZcild37MSPo7adBKNMsBAJD9ZeU2txJDlF2s11awWpnsyu5NBiUp+GxvrY2jAJmo7a73dqi2Z3rtFwXvgskSmdnO2VfBz6syf8q+Vn9EtaH3RDXRg+2n4Gfx6+wEP5PW4Ilvm+umtt++9AX2h9pAyjT20isHGKT3oRrc2uc1gKBgtOq5e8E1qva1nXugbXMF84Ovm952DWbVa/aAl2g/3N+2efzfLthfUBvTB6Hjn5eR7XOtB3AgiUX70zZXspgGiw5mfbP9ETxeaJ8js1ETHcii1OBQzUAF2NTwUG1f1WZWwyqeFj5UuQoFkjQFUiO1aqh46WUhqGGrhrimM2r0VgsQqiZfcDpmenz2iQQv9Log+4wU1Rb0i+8pS1Qj0aKFhVQrbW/ZxHp9BU9V21tT7VSOQ50PbQstXqKsbn1e1U9MtO08LS6qhpEursGFjDJCcIRc9RY11VWdC31+32hViRG/6IzP3FBnI5hxv6/uvffeNPdp2lywsfDJJ5+4EX9lPelvujd6rrL11blRdq/PKNf32pdEjX79TfT3OP/8891n0kCA/ubaB9QAnjVr1l5rdO+N9nd1yFTGR+8ruAirBlT2VsNPtbP1vrXPaPFJdcSCi8v44yD4OpoerTqI+jxqrKaXWXEgevTo4Y5DdSr1tRfs+GqfVoNe0x3V2GzSpInrXKdXmiT+fatUkUoCaT/S9NREDXsNKigTyi8KpkVzdbzr/8xY4FY0vVzTPDVopQ5xZtAx7gdFNNiiwaNXX3010xcT0uv7/Uj7GwAg+8uqbW6Vu9A1Wu0CBa107Vb7Um0XL9jmVFk/tZd8YDW4MOjeaO2e4Oum9/r6HGoT+kXsvfjPkdnbMzhDUYFBzTrUa6ido8+s4KgvOai+Qmas2eNp3aP0knT0uYP9EQXRO3bs6Nqc6svsjdqFWnBSWfk+CSfYjgyu2aNFKrVttZ1V5kLtdc1e0O9XP+hgaPtrv1D/T8Fv9Wk0I0L0+nfeeecef17tebVD1fdRP0lBavVVgq9/oO3c/aV+i/4G2naaHeH7Zdq/zz77bPd1sIyOBguUxKM+ZKLteCB9CiX4KDNfQXP1oXRc69yg/rIvP6m+nV84NKOo3ar9QttciTUZ/frB/V39Yg0Y6XyXXv81o/mYhPofKu0EZKoIgKSqVKmS5iO52/Tp06P3Dx48OHq/v5UsWTJSrVq16PfLli1zz+3UqVOa5/pbgQIFIkuXLnXPGzlyZPT+Bx54wN2n35knTx53n/6fMmXKHt+vfmei3+Vv+j1ex44d0/18ezJz5szIEUccscffsWHDBvdcfY7437t58+ZI2bJl0/zMKaecEv1a78s7/fTT02zToPR+h8ybNy+SI0eONL8n/jUaNmwY8/iHH364T9thX7a1/zu2bt16j59X+1l6n+fYY49N83O5c+eO+VstX748Ur58+T2+D/+Z9XPpbeNEgts+vZu2b69evRJuF/28d/TRRyd8nZo1a0Z27tzpnrdjx45ImTJlEu63e9tn0zuO4j9LettV++TatWujz3/22WfTPOfwww+P2dbBfempp55K83z/d020Tf76669I9erVE26Xdu3aRXbv3h19fnr7y74cI/Hatm3rnlusWDG3vdMT3Ffif1+iY85766230nyW/PnzRxo0aJDmb5do2yT6HXvah4Pn5fnz5+91OwAAso7s1uYOtkf21v7al2tnvODz9+X1ZezYsTGPlypVKs11/lBtT/n6668jhQoVStiGfPrpp/fp+p6oPXKgfxf/3uL7Cfq+cePG6f6d/H1FihRJtx901llnxbTZ1D7e03vYn75OUHA7Jbqpnbto0aKE28UfX6+++uoeX+f1118/qHZuouM7vc9y1FFHRXLmzJnmd/Tv3z/6/P/++y9SsWLFNM+pUaNGutv1QPsUw4cPT7cPqZv252+++eag2qvp+eGHH6LPf/TRRxM+L7ivxJ9H9nScqJ9Vp06dPfZHg3+7RNsm0e9ItA/rb6b+hu6/+OKL97odgINFORcgi1JWgTKnNaqr+oDK4NbIvV/RPEiZFxpZVx1ojfArC1mj3xr1VzaHn6KWHr3us88+677WiLiyNbQwYzJp6peySpRNo+wDfSZlCSiDQZ9Jo9t7WsRGGQBacFDTR5VBoKxklRvJ6JIjqu2oVd6VBbOn6ZJ+wUtfpy1+IZaMoCxc7QN6fZXw0Arz77333l5/TlnSgwYNclnkytZRJrdWvA/OGNBq9hrhv+uuu1zWukb5tY31tabqKSPJZ60fLGUgqY68siOuv/5693v39e+mz6IMHX/MaFaAPtcNN9zgjh1fk1S/Q+9ZGRKZtaCusse6dOnisraURaPMLWXZq8SKd91117n3rGNVz9H+quNVZXPSo+2hzBX9PYLTR/dE2/Krr75yv0fnB+2nyo5XZpmmYo8ZM+aAp8XuiRYKE2WgBLPVMoqyeHTeUr1W7Y/6PJpqG1w8NTP4acc6L9WqVStTfxcA4NBI5Tb3/tKMRC3452nGW7BW8aHcnqLZh5rVp9dQe1/vRdnByixW1q1K6SSL3psy4tVfUFtF7Qa1D1UHfk/Ujtdn12dQm01tObVl1QYJttnUPlabXc9Te1PtXm0DtW+VCe9nJRws/U79HfX31HtX+1H77b4s7qlSPbfeeqvLDlYfRX9f/Z3V19OaVdp/Dqaduz/0O9X+V19H7WF9HpUOCi6gq204YcIE977VL9KMEW1HP6s43oH2KW666SbXV1X/QH9fvU65cuVcv0r7s9q1GU1tZJ/VHyyjk1H0t/XlpvQ3Vp9Hf/sXXnjBMpP6Gb4m+v7MvgEOVA5F0g/4pwEA+1Q/0E9xU2NeJTuAMFNdSE0r1nRRrUmgjlJ2p8/ig/T6PPpcAAAAQHYQHLhQuzYM9cPVHtfglAap5s2blykDMEAQexgAZBLVnFM9yGD2gjIMgLBTA9bXXdfMEb8YZ3bma5Iqo0yLqwEAAADZKeDsE0KeeOIJy+5U595n1WtNCALoOBTIRAeATBJcVFVUxkVTSwEAAAAAAJB9MFQDAJlMdeEuu+wyGz16dLLfCgAAAAAAAPYTmegAAAAAAAAAACRAJjoAAAAAAAAAAAnkTvQA/p/du3fbH3/8YYUKFbIcOXIk++0AAAAgZDQ59O+//7Zy5cqxOFYc2uIAAABIdjucIPo+UKO9QoUKyX4bAAAACLmVK1da+fLlk/02shTa4gAAAEh2O5wg+j5Q1ovfmIULF0722wEAAEDIbN682QWKfbsT/w9tcQAAACS7HU4QfR/4aaNqtNNwBwAAQGahXElatMUBAACQ7HY4BReRLc2cOdNatWplRxxxhNvJdXvmmWdinrN06VK78sor3WhSvnz5rGTJknb66afbxIkTo8/5/fffrXXr1m66hp5TtGhRq1u3rg0ePNjV3wzaunWr9ezZ06pWreqeW6xYMTv55JPtm2++OWSfGwAAAAAAAMChRSY6sqVvv/3WpkyZYkcddZStW7cu3UUBzjrrLFu2bJkLeNeqVct9reD7Z599Zv/73/9csPzPP/+0Tz75xCpVqmRlypSxX3/91ebNm2d333237dq1y+699173etu2bbNmzZrZ7Nmz3SIDxx57rOXNm9fmz59vP/30k5144olJ2AoAAAAAAAAAMhuZ6MiWrrrqKlez6OOPP073cWWYK2guffv2dUH3cePGRQPsqqkpxx13nFuBd9GiRTZnzhz3M4cddph77Isvvoi+3pAhQ1wAvWzZsrZw4UL3fAXbN2zYYG3atDkEnxgAAAAAAABAMhBER7ZUokQJK1CgQMLHFew+5phj3NcPPPCA1a9f3wW7c+fObddee62dc8457jF9r5tKujRs2NCqVKli//zzj3vs1FNPjb7e2LFj3f/KfFcAv2DBglajRg17+umnLX/+/Jn8aQEAAAAAAAAkC0F0hFKuXLls+vTp1qBBA9u+fbsr37Jx40ZXx1wBdT0eNHfuXHf766+/3Pcq56Kbt3jx4mh2urLVS5cu7bLRb7nlFnv88ccP8acDAAAAAAAAcKgQREcoaVHQG264wQXGb731VtuyZYu99dZbrgZ6t27dbMKECTHPX716tVs49P3337fDDz/cHn30UXvxxRejj+/cudP9X7x4cVuyZIlbtLR58+buvmHDhh3iTwcAAAAAAADgUCGIjlCaNm2affDBB+7rjh07uvIrF198sRUuXNjdN3Xq1DQ/o1roKuuiBUkVhO/du3f0sSOPPNL9X7VqVStSpIjlyJHDlX+RFStWuOcDAAAAAAAACB+C6AilTZs2Rb/WgqHy008/uUVERUF1UUa67vfWrl0bfb4y0z2fda7nakFTLU6qLHc5+uijLWdODiUAAAAAAAAgjIj8IVsaN26cWzi0adOm0fuUOa772rdvb82aNXP1z0VlXWrXru1qoSv4nSdPHrv88sujQfRq1aq5TPO6detapUqVbOXKldEMdu++++6zokWL2vr1693v0G3KlCnR3wsAAAAAAAAgnAiiI1tSNrjqki9fvjx6n+qd677ff//dSpQo4RYBVUC9fPny9vPPP1uhQoWsVatWNmPGDKtXr140w/zkk092i48uWLDABdhPPPFEe/LJJ23IkCHR165SpYp9/vnndu6557rnrlu3zv3cRx99ZFdddVVStgEAAAAAAACAzJcjotRc7DVgqzrYKhHia2oDAAAAGYX2ZmJsGwAAACS7rUkmOgAAAAAAAAAACeRO9ACyjpYPfpDstwDsl497tU72WwAAADh4fS6y0OozPtnvAAAAINsgEx0AAAAAAAAAgAQIogMAAAAAAAAAkABBdAAAAAAAAAAAEiCIDgAAAAAAAABAAgTRAQAAAAAAAABIgCA6AAAAAAAAAAAJEEQHAAAAAAAAACABgugAAAAAAAAAACRAEB0AAAAAAAAAgAQIogMAAAAAAAAAkBWD6DNnzrTzzjvPypUrZzly5LAJEybEPK770rsNHjw4+pzKlSunefzhhx+OeZ158+bZaaedZvnz57cKFSrYoEGDDtlnBAAAAAAAAABkX0kNom/dutXq1q1rw4cPT/fxVatWxdxeeuklFyRv27ZtzPP69esX87ybb745+tjmzZutRYsWVqlSJZs7d64LwPfp08eee+65TP98AAAAAAAAAIDsLXcyf/k555zjbomUKVMm5vuJEydas2bN7Kijjoq5v1ChQmme640ePdr+++8/F4DPmzev1apVy7777jt7/PHHrUuXLun+zPbt290tGIgHAAAAAAAAAKSebFMTfc2aNfbBBx9Yp06d0jym8i0lSpSw448/3mWa79y5M/rYrFmzrEmTJi6A7rVs2dIWL15sGzZsSPd3DRw40IoUKRK9qQQMAAAAAAAAACD1ZJsg+ssvv+wyztu0aRNz/y233GJvvPGGTZ8+3a6//nobMGCA3X333dHHV69ebaVLl475Gf+9HktPjx49bNOmTdHbypUrM+UzAQAAAAAAAACytqSWc9kfKsfSvn17tzhoUPfu3aNf16lTx2WcK5iubPJ8+fId0O/Szx3ozwIAAAAAAAAAwiNbZKJ/9tlnrvzKddddt9fnNmrUyJVz+fXXX933qpWuUjBB/vtEddQBAAAAAAAAAMg2QfQXX3zRGjRoYHXr1t3rc7VoaM6cOa1UqVLu+8aNG9vMmTNtx44d0edMmTLFqlWrZsWKFcvU9w0AAAAAAAAAyN6SGkTfsmWLC3rrJsuWLXNfr1ixIvqczZs321tvvZVuFroWDR0yZIh9//339ssvv9jo0aPt9ttvtyuvvDIaIL/iiitciRctSLpgwQIbO3asPfnkkzFlYAAAAAAAAAAAyHI10efMmWPNmjWLfu8D2x07drRRo0a5r7VoaCQSscsvvzzNz6tuuR7v06ePbd++3apUqeKC6MEAeZEiRWzy5MnWtWtXl81esmRJ6927t3Xp0uWQfEYAAAAAAAAAQPaV1CB606ZNXYB8TxTsThTwrl+/vn311Vd7/T1acFR11QEAAAAAAAAACF1NdAAAAAAAAAAAkoEgOgAAAAAAAAAACRBEBwAAAAAAAAAgAYLoAAAAAAAAAAAkQBAdAAAAAAAAAIAECKIDAAAAAAAAAJAAQXQAAAAAAAAAABIgiA4AAAAAAAAAQAIE0QEAAAAAAAAASIAgOgAAAAAAAAAACRBEBwAAAAAAAAAgAYLoAAAAAAAAAAAkQBAdAAAAAAAAAIAECKIDAAAAAAAAAJAAQXQAAAAAAAAAABIgiA4AAAAAAAAAQAIE0QEAAAAAAAAASIAgOgAAAAAAAAAACRBEBwAAAAAAAAAgAYLoAAAAAAAAAAAkQBAdAAAAAAAAAIAECKIDAAAAiLFr1y7r1auXValSxQoUKGBHH320PfjggxaJRKLP0de9e/e2smXLuuc0b97cfv7555jXWb9+vbVv394KFy5sRYsWtU6dOtmWLVuS8IkAAACAA0cQHQAAAECMRx55xEaMGGHDhg2zH3/80X0/aNAge+qpp6LP0fdDhw61Z555xr7++msrWLCgtWzZ0rZt2xZ9jgLoCxYssClTptj7779vM2fOtC5duiTpUwEAAAAHJvcB/hwAAACAkPryyy/tggsusNatW7vvK1eubK+//rp988030Sz0IUOGWM+ePd3z5JVXXrHSpUvbhAkTrF27di74PmnSJJs9e7Y1bNjQPUdB+FatWtmjjz5q5cqVS/d3b9++3d28zZs3H4JPDAAAACRGJjoAAACAGCeffLJNmzbNfvrpJ/f9999/b59//rmdc8457vtly5bZ6tWrXQkXr0iRItaoUSObNWuW+17/q4SLD6CLnp8zZ06XuZ7IwIED3Wv5W4UKFTLxkwIAAAB7RyY6AAAAgBj33nuvywCvXr265cqVy9VIf+ihh1x5FlEAXZR5HqTv/WP6v1SpUjGP586d24oXLx59Tnp69Ohh3bt3j36v90EgHQAAAMlEEB0AAABAjDfffNNGjx5tY8aMsVq1atl3331nt912myvB0rFjx0z93fny5XM3AAAAIKsgiA4AAAAgxl133eWy0VXbXGrXrm3Lly93pVYURC9Tpoy7f82aNVa2bNnoz+n7evXqua/1nLVr18a87s6dO239+vXRnwcAAACyA2qiAwAAAIjxzz//uNrlQSrrsnv3bvd1lSpVXCBcddODZVdU67xx48bue/2/ceNGmzt3bvQ5n3zyiXsN1U4HAAAAsoukBtFnzpxp5513npsWmiNHDpswYULM41dffbW7P3g7++yzY56jTBbVZixcuLBbuKhTp062ZcuWmOfMmzfPTjvtNMufP7+rpzho0KBD8vkAAACA7EhtdNVA/+CDD+zXX3+18ePH2+OPP24XXXSRe1ztcpV36d+/v7377rv2ww8/WIcOHVy7/sILL3TPqVGjhmu7d+7c2b755hv74osvrFu3bi67Xc8DAAAAsouklnPZunWr1a1b16699lpr06ZNus9Rw3vkyJHR7+PrIyqAvmrVKpsyZYrt2LHDrrnmGuvSpYur3+gzYlq0aGHNmze3Z555xjXw9fsUcNfzAAAAAMR66qmnrFevXnbTTTe5kiwKel9//fXWu3fv6HPuvvtu155Xm1oZ56eeeqpNmjTJJa54qquuwPmZZ57pMtvbtm1rQ4cOTdKnAgAAAA5MjkgkErEsQNksynDxmSs+E10N8vgMde/HH3+0mjVr2uzZs61hw4buPjXcW7VqZb/99ptr7I8YMcLuv/9+W716teXNm9c9R/Ud9ZqLFi1K93W3b9/ubp4C8cpg37Rpk8t4P9RaPvjBIf+dwMH4uFfrZL8FAACyFbU3ixQpkrT2ZlaW1G3T5/8y70Opz/hkvwMAAIBs09bM8jXRP/30UytVqpRVq1bNbrzxRvvrr7+ij82aNctllPsAuijjXFkuqsfon9OkSZNoAF1atmxpixcvtg0bNqT7O7VgkjaevymADgAAAAAAAABIPVk6iK5SLq+88opbsOiRRx6xGTNm2DnnnGO7du1yjyu7XAH2oNy5c1vx4sXdY/45pUuXjnmO/94/J16PHj3c6IO/rVy5MpM+IQAAAAAAAAAgK0tqTfS90aJDXu3ata1OnTp29NFHu+x01VXMLKq7Hl97HQAAAAAAAACQerJ0Jnq8o446ykqWLGlLlixx35cpU8YtdBS0c+dOW79+vXvMP2fNmjUxz/Hf++cAAAAAAAAAAJDtg+haLFQ10cuWLeu+b9y4sVt4dO7cudHnfPLJJ7Z7925r1KhR9DkzZ860HTt2RJ8zZcoUV2O9WLFiSfgUAAAAAAAAAIDsIqlB9C1btth3333nbrJs2TL39YoVK9xjd911l3311Vf266+/urroF1xwgR1zzDFuYVCpUaOGq5veuXNn++abb+yLL76wbt26uTIw5cqVc8+54oor3KKinTp1sgULFtjYsWPtySeftO7duyfzowMAAAAAAAAAsoGkBtHnzJljxx9/vLuJAtv6unfv3pYrVy6bN2+enX/++Va1alUXBG/QoIF99tlnMfXKR48ebdWrV3c10lu1amWnnnqqPffcc9HHixQpYpMnT3YBev38HXfc4V6/S5cuSfnMAAAAAAAAAIDsI6kLizZt2tQikUjCxz/++OO9vkbx4sVtzJgxe3yOFiRV8B0AAAAAAAAAgNDWRAcAAAAAAAAA4FAiiA4AAAAAAAAAQAIE0QEAAAAAAAAASIAgOgAAAAAAAAAACRBEBwAAAAAAAAAgAYLoAAAAAAAAAAAkQBAdAAAAAAAAAIAECKIDAAAAAAAAAJAAQXQAAAAAAAAAABIgiA4AAAAAAAAAQAIE0QEAAAAAAAAASIAgOgAAAAAAAAAACRBEBwAAAAAAAAAgAYLoAAAAAAAAAAAkQBAdAAAAAAAAAIAECKIDAAAAAAAAAJAAQXQAAAAAAAAAABIgiA4AAAAAAAAAQAIE0QEAAAAAAAAASIAgOgAAAAAAAAAACRBEBwAAAAAAAAAgAYLoAAAAAAAAAAAkQBAdAAAAAAAAAIAECKIDAAAAAAAAAJAAQXQAAAAAAAAAABIgiA4AAAAAAAAAQAIE0QEAAAAAAAAASIAgOgAAAAAAAAAACRBEBwAAAAAAAAAgKwbRZ86caeedd56VK1fOcuTIYRMmTIg+tmPHDrvnnnusdu3aVrBgQfecDh062B9//BHzGpUrV3Y/G7w9/PDDMc+ZN2+enXbaaZY/f36rUKGCDRo06JB9RgAAAAAAAABA9pXUIPrWrVutbt26Nnz48DSP/fPPP/btt99ar1693P/jxo2zxYsX2/nnn5/muf369bNVq1ZFbzfffHP0sc2bN1uLFi2sUqVKNnfuXBs8eLD16dPHnnvuuUz/fAAAAAAAAACA7C13Mn/5Oeec427pKVKkiE2ZMiXmvmHDhtmJJ55oK1assIoVK0bvL1SokJUpUybd1xk9erT9999/9tJLL1nevHmtVq1a9t1339njjz9uXbp0yeBPBAAAAAAAAAAIk2xVE33Tpk2uXEvRokVj7lf5lhIlStjxxx/vMs137twZfWzWrFnWpEkTF0D3WrZs6bLaN2zYkO7v2b59u8tgD94AAAAAAAAAAKknqZno+2Pbtm2uRvrll19uhQsXjt5/yy23WP369a148eL25ZdfWo8ePVxJF2Way+rVq61KlSoxr1W6dOnoY8WKFUvzuwYOHGh9+/bN9M8EAAAAAAAAAMjaskUQXYuMXnrppRaJRGzEiBExj3Xv3j36dZ06dVzG+fXXX+8C4fny5Tug36dAfPB1lYmuBUkBAAAAAAAAAKkld3YJoC9fvtw++eSTmCz09DRq1MiVc/n111+tWrVqrlb6mjVrYp7jv09UR13B9wMNwAMAAAAAAAAAwiN3dgig//zzzzZ9+nRX93xvtGhozpw5rVSpUu77xo0b2/333+9eK0+ePO4+LViqAHt6pVwAAAAAAAn0uchCq8/4ZL8DAACQRSU1iL5lyxZbsmRJ9Ptly5a5ILjqm5ctW9Yuvvhi+/bbb+3999+3Xbt2uRrmosdVtkWLhn799dfWrFkzK1SokPv+9ttvtyuvvDIaIL/iiitcffNOnTq5murz58+3J5980p544omkfW4AAAAAAAAAQPaQ1CD6nDlzXADc83XIO3bsaH369LF3333XfV+vXr2Yn1NWetOmTV3JlTfeeMM9d/v27W4BUQXRg/XMixQpYpMnT7auXbtagwYNrGTJkta7d2/r0qXLIfucAAAAAAAAAIDsKalBdAXCtVhoInt6TOrXr29fffXVXn+PFhz97LPPDug9AgAAAAAAAABSV85kvwEAAAAAAAAAALIqgugAAAAAAAAAACRAEB0AAAAAAAAAgAQIogMAAABI4/fff7crr7zSSpQoYQUKFLDatWvbnDlzYtYv6t27t5UtW9Y93rx5c/v5559jXmP9+vXWvn17K1y4sBUtWtQ6depkW7ZsScKnAQAAAA4cQXQAAAAAMTZs2GCnnHKK5cmTxz766CNbuHChPfbYY1asWLHocwYNGmRDhw61Z555xr7++msrWLCgtWzZ0rZt2xZ9jgLoCxYssClTptj7779vM2fOtC5duiTpUwEAAAAHJvcB/hwAAACAkHrkkUesQoUKNnLkyOh9VapUiclCHzJkiPXs2dMuuOACd98rr7xipUuXtgkTJli7du3sxx9/tEmTJtns2bOtYcOG7jlPPfWUtWrVyh599FErV65cEj4ZAAAAsP/IRAcAAAAQ491333WB70suucRKlSplxx9/vD3//PPRx5ctW2arV692JVy8IkWKWKNGjWzWrFnue/2vEi4+gC56fs6cOV3meiLbt2+3zZs3x9wAAACAZCKIDgAAACDGL7/8YiNGjLBjjz3WPv74Y7vxxhvtlltusZdfftk9rgC6KPM8SN/7x/S/AvBBuXPntuLFi0efk56BAwe6gLy/KSMeAAAASCaC6AAAAABi7N692+rXr28DBgxwWeiqY965c2dX/zyz9ejRwzZt2hS9rVy5MtN/JwAAALAnBNEBAAAAxChbtqzVrFkz5r4aNWrYihUr3NdlypRx/69ZsybmOfreP6b/165dG/P4zp07bf369dHnpCdfvnxWuHDhmBsAAACQTATRAQAAAMQ45ZRTbPHixTH3/fTTT1apUqXoIqMKhE+bNi36uGqXq9Z548aN3ff6f+PGjTZ37tzocz755BOX5a7a6QAAAEB2kTvZbwAAAABA1nL77bfbySef7Mq5XHrppfbNN9/Yc889526SI0cOu+2226x///6ubrqC6r169bJy5crZhRdeGM1cP/vss6NlYHbs2GHdunWzdu3auecBAAAA2QVBdAAAAAAxTjjhBBs/fryrT96vXz8XJB8yZIi1b98++py7777btm7d6uqlK+P81FNPtUmTJln+/Pmjzxk9erQLnJ955pmWM2dOa9u2rQ0dOjRJnwoAAAA4MATRAQAAAKRx7rnnulsiykZXgF23RIoXL25jxozJpHcIAAAAHBrURAcAAAAAAAAAIAGC6AAAAAAAAAAAJEAQHQAAAAAAAACABAiiAwAAAAAAAACQAEF0AAAAAAAAAAASIIgOAAAAAAAAAEACBNEBAAAAAAAAAEiAIDoAAAAAAAAAABkZRD/qqKPsr7/+SnP/xo0b3WMAAAAAkoO2OgAAAJAFgui//vqr7dq1K83927dvt99//z0j3hcAAACAA0BbHQAAAMhYuffnye+++270648//tiKFCkS/V4N9WnTplnlypUz9h0CAAAA2Cva6gAAAEAWCKJfeOGF7v8cOXJYx44dYx7LkyePa5Q/9thjGfsOAQAAAOwVbXUAAAAgCwTRd+/e7f6vUqWKzZ4920qWLJlJbwsAAADA/qCtDgAAAGSBILq3bNmyjH8nAAAAAA4abXUAAAAgCwTRRTUVdVu7dm0068V76aWXMuK9AQAAADgAtNUBAACAjJPzQH6ob9++1qJFC9cwX7dunW3YsCHmBgAIly1bttgDDzxg1atXtwIFCli5cuXsxhtvTPec/9tvv1nx4sVdTV7dJk2aFH2sadOm0fvjbyx2BwAZg7Y6AAAAkAUy0Z955hkbNWqUXXXVVQf1y2fOnGmDBw+2uXPn2qpVq2z8+PHRBZEkEom4oM3zzz9vGzdutFNOOcVGjBhhxx57bPQ569evt5tvvtnee+89y5kzp7Vt29aefPJJO/zww6PPmTdvnnXt2tXVhjziiCPc8+++++6Deu8AkErOO+88+/TTTy1XrlxWq1YtVypA14I5c+bYrFmzLHfu/7ucKNuxQ4cOCYM0NWvWtG3btsXcp2vAzp07rWzZsofkswBA2GVUWx0AAADAQWSi//fff3byySfbwdq6davVrVvXhg8fnu7jgwYNsqFDh7qOwNdff20FCxa0li1bxgRg2rdvbwsWLLApU6bY+++/7wLzXbp0iT6+efNml4lTqVIlF6hR0L5Pnz723HPPHfT7B4BUsHDhQhdAFw1Sfv/99+58Kgqiv/nmm9Hn6hw7ffp0u/TSS9N9raefftq++uqr6E3nfwXQRQOcAICDl1FtdQAAAAAHEUS/7rrrbMyYMXawzjnnHOvfv79ddNFFaR5TFvqQIUOsZ8+edsEFF1idOnXslVdesT/++MMmTJjgnvPjjz+6MgEvvPCCNWrUyE499VR76qmn7I033nDPk9GjR7uOhGo/KnuyXbt2dsstt9jjjz+e8H1t377dBd+DNwBIVcFauprxE/xfpk6d6v7/9ttvrVevXi5rXaVe9oWC7lKxYsWEgXcAQHLa6gAAAAAOopyLMsGVya3AiYLbefLkiXl8TwHqfaVSAatXr7bmzZtH7ytSpIgLlqt0gILh+r9o0aLWsGHD6HP0fAV3lLmu4Lye06RJE8ubN2/0Ocpmf+SRR1y5gWLFiqX53QMHDnS1JAEAZjVq1LDjjjvO5s+f77LFn332WXeO9n7//Xf7559/7IorrrCSJUu6QUs9d29+/fVXe/vtt93Xt912W7QkDADg4ByKtjoAAACQSg4oYqEa4/Xq1XNfxwdKtDhcRlAAXUqXLh1zv773j+n/UqVKxTyuIIwWtAs+p0qVKmlewz+WXhC9R48e1r179+j3ykSvUKFChnwuAMhuVAf9o48+snvvvdcFZH755Rc3OLlo0SJbunSpC87ovPnTTz/Zxx9/7ALp++KJJ56wXbt2ucHQzp07Z/rnAIBUcSja6gAAAEAqOaAguurdhlm+fPncDQDwf8qXL2+vvfZaTJZjmTJl3NfVqlWL1kj35bkUHPd0nxaNfv3116P3aSaQMtblhhtuiFkMGgBwcMLeVgcAAACyRU30Q8EHZ9asWRNzv773j+n/tWvXxjyuBerWr18f85z0XiP4OwAAe6Z653///Xc0QH7XXXfZpk2b3PeXXXZZdC0LLRitW3ABaH3977//xrzeiBEjbMuWLa7UltapAAAAAAAACFUmerNmzfY4FfSTTz6xg6USLApyT5s2LTodVWVVVOvcL1jXuHFj27hxo8uAbNCgQfR3axE81U73z7n//vttx44d0XqQU6ZMcZmT6ZVyAQCkpazxF1980Y455hhXCmvdunXRWuYnnniiffrppzHP1/e6VohKwZx99tnRx7TYsxaBlvbt21vZsmUP6WcBgLA7FG11AAAAIJUcUBDdB7U9Bai/++47V3OxY8eO+/w6ykJcsmRJ9HstVKfXUU3zihUruuBM//797dhjj3VB9V69elm5cuVcWQC/2J0CM6ql+8wzz7j30a1bN7foqJ4nWuhOi4R26tTJ7rnnHvcen3zySVeLFwCwbxQoV3kA1UNXxrkGLjWgqXPr/lJZGAXiFeC54447MuX9AkAqy6i2OgAAAICDCKInCkD36dPHBcb31Zw5c6KZiuIX81TjftSoUXb33Xe7sgBdunRxGeennnqqTZo0yfLnzx/9mdGjR7vA+Zlnnmk5c+a0tm3b2tChQ6OPFylSxCZPnmxdu3Z1QR8teNe7d2/3mgCAfdOhQwd321dNmzZ1wfb0XHvtte4GAMgcGdVWBwAAAPB/ckQSRTkOgLLKla2omuRhojIyCsar/m/hwoUP+e9v+eAHh/x3Agfj416tk/0WAADIVg5FezO7ttWT2hbv838LZodSn/EH+HNsEwAAEB772tbM0IVFZ82aFZMlDgAAACBroK0OAAAAHMJyLm3atIn5Xsnsq1atcuVZVLccALILZnogO2K2B4A9oa0OAAAAZIEgulLcg1SLvFq1atavXz9r0aJFRr03AAAAAPuJtjoAAACQBYLoI0eOzOC3AQAAACAj0FYHAAAAskAQ3Zs7d679+OOP7utatWrZ8ccfn1HvCwAAAMBBoK0OAAAAJDGIvnbtWmvXrp19+umnVrRoUXffxo0brVmzZvbGG2/YEUcckUFvDwAAAMD+oK0OAAAAZKycB/JDN998s/3999+2YMECW79+vbvNnz/fNm/ebLfccksGv0UAAAAA+4q2OgAAAJAFMtEnTZpkU6dOtRo1akTvq1mzpg0fPpzFigAAAIAkoq0OAAAAZIFM9N27d1uePHnS3K/79BgAAACA5KCtDgAAAGSBIPoZZ5xht956q/3xxx/R+37//Xe7/fbb7cwzz8zI9wcAAABgP9BWBwAAALJAEH3YsGGupmLlypXt6KOPdrcqVaq4+5566qkMfosAAAAA9hVtdQAAACAL1ESvUKGCffvtt67W4qJFi9x9qrnYvHnzDH57AAAAAPYHbXUAAAAgiZnon3zyiVuUSFksOXLksLPOOstuvvlmdzvhhBOsVq1a9tlnn2XwWwQAAACwN7TVAQAAgCwQRB8yZIh17tzZChcunOaxIkWK2PXXX2+PP/54Rr4/AAAAAPuAtjoAAACQBYLo33//vZ199tkJH2/RooXNnTs3I94XAAAAgP1AWx0AAADIAkH0NWvWWJ48eRI+njt3bvvzzz8z4n0BAAAA2A+01QEAAIAssLDokUceafPnz7djjjkm3cfnzZtnZcuWzaj3BgAAAGAf0VYHkqTPRRZafcYn+x0AAJD9MtFbtWplvXr1sm3btqV57N9//7UHHnjAzj333Ix8fwAAAAD2AW11AAAAIAtkovfs2dPGjRtnVatWtW7dulm1atXc/YsWLbLhw4fbrl277P7778+ktwoAAAAgEdrqAAAAQBYIopcuXdq+/PJLu/HGG61Hjx4WiUTc/Tly5LCWLVu6xrmeAwAAAODQoq0OAAAAZIEgulSqVMk+/PBD27Bhgy1ZssQ1zo899lgrVqxY5rxDAAAAAPuEtjoAAACQBYLonhriJ5xwQsa+GwAAAAAHjbY6AAAAkKSFRQEAAAAAAAAASCUE0QEAAAAAAAAASIAgOgAAAAAAAAAACRBEBwAAALBHDz/8sOXIkcNuu+226H3btm2zrl27WokSJezwww+3tm3b2po1a2J+bsWKFda6dWs77LDDrFSpUnbXXXfZzp07k/AJAAAAgANHEB0AAABAQrNnz7Znn33W6tSpE3P/7bffbu+995699dZbNmPGDPvjjz+sTZs20cd37drlAuj//fefffnll/byyy/bqFGjrHfv3kn4FAAAAMCBI4gOAAAAIF1btmyx9u3b2/PPP2/FihWL3r9p0yZ78cUX7fHHH7czzjjDGjRoYCNHjnTB8q+++so9Z/LkybZw4UJ77bXXrF69enbOOefYgw8+aMOHD3eB9US2b99umzdvjrkBAAAAyUQQHQAAAEC6VK5F2eTNmzePuX/u3Lm2Y8eOmPurV69uFStWtFmzZrnv9X/t2rWtdOnS0ee0bNnSBcUXLFiQ8HcOHDjQihQpEr1VqFAhUz4bAAAAEJogeuXKlV39xfibGvTStGnTNI/dcMMNMa9BLUYAAABg/7zxxhv27bffuqB2vNWrV1vevHmtaNGiMfcrYK7H/HOCAXT/uH8skR49erhMd39buXJlBn0iAAAA4MDktmxQg1H1FL358+fbWWedZZdcckn0vs6dO1u/fv2i3ytYHl+LsUyZMm566apVq6xDhw6WJ08eGzBgwCH8JAAAAED2oMD1rbfealOmTLH8+fMf0t+dL18+dwMAAACyiiyfiX7EEUe4ALi/vf/++3b00Ufb6aefHhM0Dz6ncOHC0ccOpBYjdRgBAACQylSuZe3atVa/fn3LnTu3u2nx0KFDh7qvlVGutvTGjRtjfm7NmjWuPS76X9/HP+4fAwAAALKLLB9ED1JDXcHwa6+91pVt8UaPHm0lS5a04447zk3//Oeff6KPHUgtRuowAgAAIJWdeeaZ9sMPP9h3330XvTVs2NAtMuq/1szOadOmRX9m8eLFroxi48aN3ff6X6+hYLynzHYlvNSsWTMpnwsAAAAIZTmXoAkTJrhsl6uvvjp63xVXXGGVKlWycuXK2bx58+yee+5xDfhx48YdcC1GBeK7d+8e/V4BdwLpAAAASBWFChVyCSpBBQsWtBIlSkTv79Spk2szFy9e3AXGb775Zhc4P+mkk9zjLVq0cMHyq666ygYNGuTa3j179nRrG1GuBQAAANlJtgqiv/jii64ciwLmXpcuXaJfK+O8bNmyLnNm6dKlruzLgaAOIwAAALBnTzzxhOXMmdPatm3ryiFqtufTTz8dfTxXrlyuFOONN97ogusKwnfs2DFmLSMAAAAgO8g2QfTly5fb1KlToxnmiTRq1Mj9v2TJEhdEV73Fb775JuY51GIEAAAA9s+nn34a870WHNU6Q7olohmjH3744SF4dwAAAEDmyTY10UeOHGmlSpWy1q1b7/F5qtEoykgXajECAAAAAAAAAEKdib57924XRNf0z9y5/99bVsmWMWPGWKtWrVx9RtVEv/32261JkyZWp04d9xxqMQIAAAAAAAAAQh1EVxmXFStW2LXXXhtzf968ed1jQ4YMsa1bt7rFP1WTUUFyj1qMAAAAAAAAAIBQB9GVTR6JRNLcr6D5jBkz9vrz1GIEAAAAAAAAAIS6JjoAAAAAAAAAAIcaQXQAAAAAAAAAABIgiA4AAAAAAAAAQAIE0QEAAAAAAAAASIAgOgAAAAAAAAAACeRO9AAAAAAAAMB+63ORhVaf8cl+BwCAJCCIDgAAAAAAkJkYWACAbI1yLgAAAAAAAAAAJEAQHQAAAAAAAACABAiiAwAAAAAAAACQAEF0AAAAAAAAAAASIIgOAAAAAAAAAEACBNEBAAAAAAAAAEiAIDoAAAAAAAAAAAkQRAcAAAAAAAAAIAGC6AAAAAAAAAAAJEAQHQAAAAAAAACABAiiAwAAAAAAAACQAEF0AAAAAAAAAAASIIgOAAAAAAAAAEACBNEBAAAAAAAAAEiAIDoAAAAAAAAAAAkQRAcAAAAAAAAAIAGC6AAAAAAAAAAAJEAQHQAAAAAAAACABAiiAwAAAAAAAACQAEF0AAAAAAAAAAASIIgOAAAAAAAAAEACBNEBAAAAAAAAAMiOQfQ+ffpYjhw5Ym7Vq1ePPr5t2zbr2rWrlShRwg4//HBr27atrVmzJuY1VqxYYa1bt7bDDjvMSpUqZXfddZft3LkzCZ8GAAAAAAAAAJDd5LYsrlatWjZ16tTo97lz/7+3fPvtt9sHH3xgb731lhUpUsS6detmbdq0sS+++MI9vmvXLhdAL1OmjH355Ze2atUq69Chg+XJk8cGDBiQlM8DAAAAAAAAAMg+snwQXUFzBcHjbdq0yV588UUbM2aMnXHGGe6+kSNHWo0aNeyrr76yk046ySZPnmwLFy50QfjSpUtbvXr17MEHH7R77rnHZbnnzZs3CZ8IAAAAAAAAAJBdZOlyLvLzzz9buXLl7KijjrL27du78iwyd+5c27FjhzVv3jz6XJV6qVixos2aNct9r/9r167tAuhey5YtbfPmzbZgwYKEv3P79u3uOcEbAAAAAAAAACD1ZOkgeqNGjWzUqFE2adIkGzFihC1btsxOO+00+/vvv2316tUuk7xo0aIxP6OAuR4T/R8MoPvH/WOJDBw40JWH8bcKFSpkyucDAAAAAAAAAGRtWbqcyznnnBP9uk6dOi6oXqlSJXvzzTetQIECmfZ7e/ToYd27d49+r0x0AukAAAAAAAAAkHqydCZ6PGWdV61a1ZYsWeLqpP/333+2cePGmOesWbMmWkNd/+v7+Mf9Y4nky5fPChcuHHMDAAAAAAAAAKSebBVE37Jliy1dutTKli1rDRo0sDx58ti0adOijy9evNjVTG/cuLH7Xv//8MMPtnbt2uhzpkyZ4oLiNWvWTMpnAAAAAAAAAABkH1m6nMudd95p5513nivh8scff9gDDzxguXLlsssvv9zVKu/UqZMru1K8eHEXGL/55ptd4Pykk05yP9+iRQsXLL/qqqts0KBBrg56z549rWvXri7bHAAAAAAAAACAbBtE/+2331zA/K+//rIjjjjCTj31VPvqq6/c1/LEE09Yzpw5rW3btrZ9+3Zr2bKlPf3009GfV8D9/ffftxtvvNEF1wsWLGgdO3a0fv36JfFTAQAAAAAAAACyiywdRH/jjTf2+Hj+/Plt+PDh7paIstg//PDDTHh3AAAAAAAAAICwy1Y10QEAAAAAAAAAOJQIogMAAAAAAAAAkABBdAAAAAAAAAAAEiCIDgAAAAAAAABAAgTRAQAAAAAAAABIgCA6AAAAAAAAAAAJEEQHAAAAAAAAACABgugAAAAA0hg4cKCdcMIJVqhQIStVqpRdeOGFtnjx4pjnbNu2zbp27WolSpSwww8/3Nq2bWtr1qyJec6KFSusdevWdthhh7nXueuuu2znzp2H+NMAAAAAB44gOgAAAIA0ZsyY4QLkX331lU2ZMsV27NhhLVq0sK1bt0afc/vtt9t7771nb731lnv+H3/8YW3atIk+vmvXLhdA/++//+zLL7+0l19+2UaNGmW9e/dO0qcCAAAA9l/uA/gZAAAAACE3adKkmO8V/FYm+dy5c61Jkya2adMme/HFF23MmDF2xhlnuOeMHDnSatSo4QLvJ510kk2ePNkWLlxoU6dOtdKlS1u9evXswQcftHvuucf69OljefPmTdKnAwAAAPYdmegAAABJNmTIEKtbt64VLVrU8uXLZ+XLl7dLLrnE5s2b5x7/7bff7IYbbrDatWtbsWLFXNmM4447zh599FGXHRy0ZMkSu/jii6148eJWoEABq1+/vo0dOzZJnwxhoqC5aN8SBdO1/zVv3jz6nOrVq1vFihVt1qxZ7nv9r/1WAXSvZcuWtnnzZluwYEG6v2f79u3u8eANAAAASCaC6AAAAEmmMhh//vmnHXXUUXb00UfbqlWr7O2337ZmzZq50hkKjD/77LP266+/WuXKlS1XrlwuAKna0rfeemv0dfRzp5xyir3zzjuujEbZsmXtf//7n7Vr185eeumlpH5GZG+7d++22267ze1fGsCR1atXu0xyDf4EKWCux/xzggF0/7h/LFEt9iJFikRvFSpUyKRPBQAAAOwbgugAAABJ9vrrr7ta0t9++60rfXHfffe5+9evX2+LFi1ymb/PP/+8rVu3zgXFFUyvUqWKe87o0aNjgo9r1651C0H++OOP9ssvv7iFHkXlM1SXGjgQqo0+f/58e+ONNzL9d/Xo0cNlvfvbypUrM/13AgAAAHtCEB0AACDJ8ufPb+PHj3c1pGvWrGkDBgxw9x9xxBFWtWpVq1Onjl133XWu1IuopIvPBvb3yUcffeT+b9y4sZUrV8597Rd5VAB+zpw5h/yzIfvr1q2bvf/++zZ9+nRXasgrU6aMG5jZuHFjzPPXrFnjHvPP0ffxj/vH0qN9unDhwjE3AAAAIJkIogMAAGQBCix+/fXXLoNcpTOUaa6gpbLK4y1evNg++eQT93Xnzp2j9/uMXS3+6AVLaaxYsSKTPwXCJBKJuAC6Bni0v/nZD16DBg0sT548Nm3atJh9U/uZBnJE///www9uhoQ3ZcoUFxjXgBEAAACQHRBEBwAAyAK0cKiC58uXL7fLLrvMli1b5v7/+++/Y543e/ZsO/30012tdGWZ9+3bd6+BUOBAS7i89tprNmbMGDeYoxrmuv3777/ucdUr79Spk3Xv3t0N+Gih0WuuucYFzjWrQlq0aOGC5VdddZV9//339vHHH1vPnj3dawdnUQAAAABZGUF0AACALCJHjhxWsWLFaE10LR6qeunexIkTrWnTpi5rvUuXLvbmm29a7ty5o4/7BRiDWb/Br/XawL4aMWKEq0mufU6L1Prb2LFjo8954okn7Nxzz3W195s0aeJKtIwbNy76uBbBVSkY/a/g+pVXXmkdOnSwfv36JelTAQAAAPvv//W6AAAAcMj99ddf9uGHH7qs87x587r79L2njHN58sknXcavMssfeeQRu/vuu9O81tlnn23Dhg2zWbNmuYVKVRfdBzRLlixpDRs2PGSfC9nfvsxiUD3/4cOHu1silSpVitmnAQAAgOyGIDoAAEASqVyLMnOvv/56O/roo13mr69trhIaKtmioPhtt90WvU+B8WC2r2pWK0P43nvvtTfeeMMtIlqjRg0rUaKEKwsjWqzUB+kBAAAAAPuOci4AAABJVLRoUWvXrp0Lgi9dutRWrVrlyrKo7IUWGlUW7/bt22OC7ro/ePOPH3nkkfbFF1+4wLtKwygbvV69ejZ69OiYBUgBAAAAAPuOTHQAAIAkB9GDdc/To5rU+7pAaNWqVe2dd97JoHcHAAAAACATHQAAAAAAAACABMhEBwAAmablgx8k+y0A++3jXq2T/RYAAAAAZCFkogMAAAAAAAAAkABBdAAAAAAAAAAAEiCIDgAAAAAAAABAAgTRAQAAAAAAAABIgCA6AAAAAAAAAAAJEEQHAAAAAAAAACABgugAAAAAAAAAAGTHIPrAgQPthBNOsEKFClmpUqXswgsvtMWLF8c8p2nTppYjR46Y2w033BDznBUrVljr1q3tsMMOc69z11132c6dOw/xpwEAAAAAAAAAZDe5LQubMWOGde3a1QXSFfS+7777rEWLFrZw4UIrWLBg9HmdO3e2fv36Rb9XsNzbtWuXC6CXKVPGvvzyS1u1apV16NDB8uTJYwMGDDjknwkAAAAAAAAAkH1k6SD6pEmTYr4fNWqUyySfO3euNWnSJCZoriB5eiZPnuyC7lOnTrXSpUtbvXr17MEHH7R77rnH+vTpY3nz5k3zM9u3b3c3b/PmzRn6uQAAAAAAAFJan4sstPqMT/Y7AJBK5Vzibdq0yf1fvHjxmPtHjx5tJUuWtOOOO8569Ohh//zzT/SxWbNmWe3atV0A3WvZsqULjC9YsCBhGZkiRYpEbxUqVMi0zwQAAAAAAAAAyLqydCZ60O7du+22226zU045xQXLvSuuuMIqVapk5cqVs3nz5rkMc9VNHzdunHt89erVMQF08d/rsfQoEN+9e/fo9wq4E0gHAAAAAAAAgNSTbYLoqo0+f/58+/zzz2Pu79KlS/RrZZyXLVvWzjzzTFu6dKkdffTRB/S78uXL524AAAAAAAAAgNSWLcq5dOvWzd5//32bPn26lS9ffo/PbdSokft/yZIl7n/VSl+zZk3Mc/z3ieqoAwAAAAAAAACQ5YPokUjEBdDHjx9vn3zyiVWpUmWvP/Pdd9+5/5WRLo0bN7YffvjB1q5dG33OlClTrHDhwlazZs1MfPcAAAAAAAAAgOwud1Yv4TJmzBibOHGiFSpUKFrDXIt9FihQwJVs0eOtWrWyEiVKuJrot99+uzVp0sTq1KnjntuiRQsXLL/qqqts0KBB7jV69uzpXpuSLQAAAAAAAACAPcnSmegjRoywTZs2WdOmTV1mub+NHTvWPZ43b16bOnWqC5RXr17d7rjjDmvbtq2999570dfIlSuXKwWj/5WVfuWVV1qHDh2sX79+SfxkAAAAAAAAAIDsIHdWL+eyJxUqVLAZM2bs9XUqVapkH374YQa+MwAAAAAAACAD9bnIQqvP+GS/AyC8megAAAAAAAAAACQTQXQAAAAAAAAAABIgiA4AAAAAAAAAQAIE0QEAAAAAAAAASIAgOgAAAAAAAAAACRBEBwAAAAAAAAAggdyJHgAAAAAAAACApOlzkYVWn/HJfgfYD2SiAwAAAAAAAACQAEF0AAAAAAAAAAASIIgOAAAAAAAAAEAC1EQHAAAAAAAAgKwuzDXis3ideDLRAQAAAAAAAABIgCA6AAAAAAAAAAAJEEQHAAAAAAAAACABgugAAAAAAAAAACRAEB0AAAAAAAAAgAQIogMAAAAAAAAAkABBdAAAAAAAAAAAEiCIDgAAAAAAAABAAgTRAQAAAAAAAABIgCA6AAAAAAAAAAAJEEQHAAAAAAAAACABgugAAAAAAAAAACRAEB0AAAAAAAAAgAQIogMAAAAAAAAAkABBdAAAAAAAAAAAEiCIDgAAAAAAAABAAgTRAQAAAAAAAABIgCA6AAAAAAAAAAAJpFQQffjw4Va5cmXLnz+/NWrUyL755ptkvyUAAAAg9GiHAwAAIDtLmSD62LFjrXv37vbAAw/Yt99+a3Xr1rWWLVva2rVrk/3WAAAAgNCiHQ4AAIDsLney38Ch8vjjj1vnzp3tmmuucd8/88wz9sEHH9hLL71k9957b8xzt2/f7m7epk2b3P+bN2+2ZNi57Z+k/F7gQCXrWDkQHF/IjjjGgPAdY/53RiIRS+V2eJZri2/fYaF1oNuTbZIW2yQttklabJO02CZpsU3SYpukzvaQLNwOzxEJY0s9zn///WeHHXaYvf3223bhhRdG7+/YsaNt3LjRJk6cGPP8Pn36WN++fZPwTgEAAJDKVq5caeXLl7dUbYcLbXEAAABktXZ4SmSir1u3znbt2mWlS5eOuV/fL1q0KM3ze/To4aacert377b169dbiRIlLEeOHIfkPSPzR5kqVKjgDpDChQsn++0AocMxBmQujrHwUV7L33//beXKlbNUboenalucYzottklabJO02CZpsU3SYpukxTZJi22Sutskso/t8JQIou+vfPnyuVtQ0aJFk/Z+kHl0EgjziQBINo4xIHNxjIVLkSJFkv0WsoRUbotzTKfFNkmLbZIW2yQttklabJO02CZpsU1Sc5sU2Yd2eEosLFqyZEnLlSuXrVmzJuZ+fV+mTJmkvS8AAAAgzGiHAwAAIAxSIoieN29ea9CggU2bNi1mWqi+b9y4cVLfGwAAABBWtMMBAAAQBilTzkV1FbWAUcOGDe3EE0+0IUOG2NatW+2aa65J9ltDEmiK8AMPPJBmqjCAjMExBmQujjFkJ7TD945jOi22SVpsk7TYJmmxTdJim6TFNkmLbZIW2yRWjoiqp6eIYcOG2eDBg2316tVWr149Gzp0qDVq1CjZbwsAAAAINdrhAAAAyM5SKogOAAAAAAAAAMD+SIma6AAAAAAAAAAAHAiC6AAAAAAAAAAAJEAQHQAAAAAAAACABAiiAwAAAAAAAACQAEF0AEC2snv3bvc/62IDycdxCAAAkt0vAIBDgSA6kIkXci7qQMbLmfP/Ll2///57st8KkPJy5Mjh/l+3bl2y3woAhGZQMtUHKKdOnWo//fRTst8GslG/oHfv3jZs2LBkvx0AIUcQHThIPlC+bds227Vrl7uQf/XVVzEXdQAZa9y4cXbJJZfYX3/9ley3AqQ8dVrbtWuX7LcBZEmpHgyNR4JJ4u3iByUl+HWqHS8//PCDnXfeeTZ8+HD75Zdfkv2WkA3OJeoXvPLKK9agQQNLZfHnV64/2BPFrrD/iPABB0mB8mXLllnLli1dZuzYsWPt5JNPtpkzZyb7rQGh9e+//9rKlStt8+bN7nsaiUDyNGzY0L7//nubPHlyst8KkKWofeiDoe+8846tWrXKUp1PMPn000/tv//+S/bbyRJmzJhhGzdudF/ff//91q9fP0tVOl5q165tTz/9tE2YMMEN0i5dujTZbwtZ+FzyySef2JQpU6xbt27WuHHjlO0TKIDut8nQoUPtxhtvtKZNm9prr71mS5YssVTm94m///7b/vnnn2S/nSwjV65c7n8lpuk4StVjZ38RRAcyQJkyZVxH6cwzz7QrrrjCXnrpJWvSpAknIuAg6RhKr0RS+/bt7ZhjjrHu3bundMYWkOwsJ2WxVKlSxerXr29ffvllus8BUtGsWbPs0ksvdYHAO+64w7UPUznrK3heWLx4sZ1xxhn22GOPpXwgfcOGDda2bVu77LLL7Prrr3dB44svvthSle87XXPNNda3b1978803XUZ6qgfS/XbRdli4cKGtXr06zWOp6Mcff7QbbrjBXn31Vdu0aVO0T5CK28QH0O+55x7r379/tG3Wp08fe+CBB1wAOVVpn3j33XddsFjJjjrPpvIsl+D1+OWXX3ZVFLS/0J/eNwTRgYOkDlGBAgXsiSeecA2b8uXLu1FwPy0zFS/iQEbRMRQsixT8ukuXLrZ27VrXgBaONSDzG9z+GPQ10JXFUrp0abvgggts8ODB9vPPP1PKDClt+/bt7v+CBQta9erVXXakkisWLFjg2oipGEjX9dmfFwYOHGivv/662z49e/Z0wZ6dO3daqpk0aZIbQChWrJgtWrTIDUKOHj3aJk6caDVr1rRUbvf5683VV1/t9g8C6f+3Xd5++21r3ry5nXbaaXbllVe6bH3/WKq0gf3n9P/XqFHDHnnkERcA/PDDD6OD+akaDNRM+PHjx7ttcffdd9uFF15oy5cvt1atWlmhQoVSZj9Jb1D7qquusuOOO87NnnzooYfs4YcfdrMoU5G/Huv8qnb7gAED3DGEfUMvB8igaTBFihRxo+C6QCnz6Ntvv01T31DI0AP27uabb3YBOe+pp55ymecjR46MZg60aNHCTY0fNWpUSjeYgcx27bXXugweH+h65plnXDaPMnl8ZtNNN91kp5xyigsCKUjItQ6p6LrrrrP77rvPfV2nTh0XRF+zZo1Vrlw52llXuzHVjg9/fX7wwQft8ccft0aNGrn6xcqQVOdd/6dSIF2JN7169bI8efK4fWH9+vXu8+fPn98GDRrk9plUXmw0OBCrQLrK26R6IF2BUGUT9+jRwx07OqdocE7HT6oE0oP9apU/8oP5F110kRucEw0szJ49O/ozYd8m8bRGW9GiRV2gWCVmtbaASrtoBu/WrVtt+vTpKVfOROU/9bl1zn300UfthRdecP3KL774wv2fqoF0zWjRuUTnEO03smPHjmS/rewhAuCA7N692/2/fv36yLZt26L3//PPP5Hq1atH6tSpE/n222+jz3vnnXeS9l6B7GTVqlWRa6+91h1HTz/9tLtv0aJFkfbt20dOO+20SOnSpSOPPPJIZMmSJZH33nsvUq9evcgPP/yQ7LcNhFbjxo0jZcqUiUyaNMl9/+6770buueeeSJEiRSJnnnlm5I477ohs2rQpcvvtt0dOPfXU6M/56x+QCnbs2BGZMGFC5L///nPf79q1K/L9999H3n///UjHjh0jp5xySuTVV1+NpCq1j5s2bRp56KGHYu5/8cUXIzlz5oz07ds3pj2dCvuLaB/x58sVK1ZEjjzyyEiLFi0ia9asiaQSf72YO3du5M0334yMHDky8vvvv0cff+GFF9y20XVm6dKlkVSi/qSuszfddFN0v9G2ueuuuyLHH398zDEV1utu8HMNHDjQnU9r167t2hzaPjJ+/PjICSecELnyyisjs2fPjoSdrjHx3n77bbcNPvjgg0jhwoUjw4YNiz6mtlvnzp3deSYVaJ/59ddf3XnjiCOOiPTv3z/m8bfeeitSo0aNSJcuXSJz5syJpNr+orbK5MmTIw0aNHDbwV9/d+7cmaR3mH0QRAcOwsSJEyPNmjVzF/HBgwdHG8L//vuvCwCqYfP6669HevToEcmVK1dk2bJlyX7LQLagAHn37t0jVatWjYwYMSLmfgXWGzZsGKlfv74LoFepUsU1hBI1KAEcmODxdP7557tOiA+ky8qVKyMDBgxwHbZatWpFunXrFsmRI0fkqaeeStI7BpIjPnD1/PPPR84+++zI1q1b3ffqoF9xxRUu8DN69Ojo85555pmUCZZu3rw5Urly5UifPn2i20znGN0uv/xyd+6ID7CHkQ9Q6HN/+OGH7nMrYLxlyxZ3/4IFC1zQ55xzznGBUgVNlUTw2GOPRcIqmHBUokSJSJMmTdz/2gbB40WB9EqVKrlA4C+//BJJBdovFBQuWbJk5Iwzzoh57Lfffovceeed7hp8//33R1JBr169IqVKlYq88sorkR9//NHtD+oL/PHHH9F9qFGjRpFWrVq5x1OhfabjItgPqlu3rjuvvPTSS9HnKDbRunVrd64N60BLIsOHD48ULVo00qZNmzSxGO0vSs66+eabQz2IGwyMKwE0uB0+++wzF7fScaP9RPxgHdJHEB04QN98803k8MMPj/Tu3TtyzTXXuAu4LkyzZs1yj+skpOw9BfqOPvro6Cg5gH2jgLkyjqpVqxZ58sknYx5TZsG0adNctlaBAgXcxX/Dhg1Je69AWAUb0ueee67ryH/00UfRhrbvyD3++OMusJE7d24X+PDZuEAqCAY09LWC42oXXnzxxdHgqDJsFQxVwOu+++5zAY3y5cuHcvA30We69957I8cee2y0TeyDOdoeGnSID/ykwna5/vrrXX/i5Zdfjg66LFy40O0b6j8oIUftoLCfU6dPn+6CoxqA8gNPup6cfPLJMfuEMmtr1qwZWb16dSTMgoFOzba8+uqr3UD2s88+myaQfuONN7qBh3Xr1kXCTJ9V50/N7hEN6ivbOphsIzqWOnXqFMpzazwNolSoUMGdW/0xoWNJSUjK0ldGugYc1F867rjjom26sAbSE30uJXeULVvWJTaqDxmkGWTqc4ZV8DhQzOr000+P5M+fP3LddddF3njjDXe/+tS61uh86wcTUuH4OVAE0YEDoGmE/fr1c9PJPJ2E1IC59NJLo4F0XahUhuLPP/9M4rsFsgd/sQ5etJVFokC6GoPKJEg0I0QXfd+oDmvDEDiUEh1Hyu5SoEOB9Pigjn5m6tSpLvChUktAKghesxQcVsa1sr4UyDnxxBMjF110UTSQrhmLKstw0kknudkdwdIvYRH8LCqp8Omnn0aDwxpIULBc55HvvvvO3afHtC3GjRvnto0CPWo3h+1aHtwuCmop+9xTFmS+fPliAulKDFB28cMPPxwNfIUpOzD499Vx8OCDD0Zuu+22aD9LAwiXXXaZm/GrRIlgKaSNGzdGwspvF50z9LU/R6g/edVVV7nZLCqBFKQs7DDOaIk/L2owQQFjURtEg08asBSdd+MTbtJ7jTDRgJMSG4LlY0VB0C+//NLFJTRbVxnGmgnl96Wwluvw20CZ1ZrxpPNn8Dz7xBNPuFk+CqQvX748kmqU7KmyLdo+X3/9tds3VGJNmem6tiiQrsF/nXvDdK3JDATRgf2k0UuVktBophp8QQqkq2azLlRffPFF0t4jkN0EG7mq1adsE09TztSxig+kb9++Pfqz6lQoEwdAxh6PKtmiDvrff/8dvU9BMB9IDza0fcdMg8kKhgFhFwxcKJtamVyaVq9jSNcodeDjA+n6X4FS/7Nh7awqQ7JcuXKRww47zLWbVatXVINVQXRlkKoDrwCpAud+Rou2YZizrrVdVNZGpWuCtYlVDkuBdAXYFRCMF7b9xO//X331lQuaK0CqxAldazTIpLVxfFa+9hWVqNAgQ/Bnw8Z/LmUP6zqrPqX+9/Waf/rpp0iHDh3cTOcwz9iI5wfcRNtEGbSFChWKzlrwgwzaLjq/pAoNvukmiQbaFCzWMRX2602wPIuuObrm6pyhgHCwDJIC6SoBdMstt7j2barQOUTr9S1evNh9/9xzz7nzqhJfgu13lRhLldJQB4MgOrCPgg02NfJ1AtaCavHTf7QYjmqka7pMmGtrAZlBF+6jjjoqUrFiRdepVna5ghFq6CiQrs52cNqmD/aps6WakWHueAOHmqYHqxOiBUTbtm0bU+tcJVtUR1LTqeOPOwXG1MkFUoWSKjSw9PHHH7usLk+BdAW7lAkYLO0SxizJ4GfRAJs67FOmTHE1vlUKSuUNR40aFV1AXMFizTRTprUfFL/hhhsiF1xwQZrtFBaqXaySHMoC9IJZoQqIFSxY0GXXhrUPEexP6fqhEj4K5PgSYZ988klMsEcZtbqmKIsyFbJH1e7NmzevG5RTm1hln1R64bXXXnOPz58/3/UxVdImFRYq1kwWtf2VPat9R4upFi9e3JW3ia/3rXZJmM6pe6PPe95556U5trSIs58VHxTGwafgZ9KgpPqQfkaCBqt1blEgvXnz5tHnDRo0yB0/a9eujYRV/GyD//3vf26AWlRJoVixYq69IprFonbKX3/9FbM9w7i/ZBSC6MBe+BOILsrBk4kCeQryaSQzPpCuKanx9bYApBVs7GomhxrGY8aMcSvIt2vXznU2fdBcx5myW7U4jI4xTx0s1Q71C/sCOPjjUdPFy5QpExk7dqyrwap655pG3bdv3+hz1HlTAESZhJ4CZpqpxTogCKv44Kbq0DZo0CCaJRvfidUgkwLGSr5QYCxstPhlkDLOFehS2cPgNlNpDnXi1Vn3AdPgayigruu7MpLDQEG/eJox17Vr14Ql7ESzWRU0Djs/kDJ48GD3ve9jKYisQJhfxFprT910000xs6HCIv4z6bhQ7WodP0E6NhRI9+1c/a8Bp/hFEsMg/nhQBq2Oh/79+7vvNWtB5Z/8WmQa7FfZEiWwhbE8VqLPo+uLFlnV4KS2UTBoqsEm1b0O86x4/d3j+32asaByLWqHesq817lEa3H42VASHOwOMx0vvpSaSv8owUUD/prt4imYrhkv9KP3HUF0YA98g06ZNJo+p4CBFgDyCxgqK08dAk3B9CcpAPtPAfShQ4dGaxt6yj7XaLku/qKGkZ4XP8Ie9gWmgENJGUwK9ASPR5V0eeSRR1xwQ+UqvLvvvjvmeFQQQNksQBgpWDN+/PiY+3755RfXOfVB02DAwx8P6shrmnTYatF27NjRZZL7z60MyFq1arnBNQW4gpRtrsFxlbcZMmRINPtcwQyVNlGgLFi2ITtTwE/lBNSPCCbg6D7NSIinQQbVo/X8PhTWTMCff/7Z7SOazRS/KKQCgNpHVLtXgVENrCiLMmzUvu3evXvMOUFBdSVoqZ0rwVleZ511VuSSSy6JGZwLs+C5QKUn8uTJE+0LaP/RNtI5Q4NzGnQI47oB8dcTXWM+//zz6CwNHSsKGisAqoxrzeBRNrbiFSp7E7brjadyV1qkOz7oq76gkqq0vwQpbqO2qx+wC/O5NUhteB03fmaXBh503n3sscdiBrA1IKX4FvYdQXRgL7RisxYu0RRLZeapwadpuT5opylDWilc08rCmBEAZDbVeFQjUBd2v1hvMEtNq8urxnI8NQ7Dlm0CJJsyyFWXV9PJFTQP0loF6rQq+yle2DquQHo0Ddxnovt9XlPGVfs7WEfUBy8U8NBaHumtHRAGKjHhg3l+8ExB8ZYtW0aqVavmBhyCn1eBcwUDO3XqFBPE0LT6devWRcJCwR3/N/cBL59RrO2i+4KfX4OUKmOjUiaix8Lcvtm0aZOb1aTsagV2RJ/X7ysKkipRScdbcPuFibJj/YwtP6AkCoDqOuv//v740iyGYOmOMFPdavUJVKbRZwwryKf+to6VRMJ0bo2nhAUNKGlGk2pZ+2QGJfEpCKrBSyUdKTNdM6PCvoio/1yqge+PIy04rEFKlQ+bOXNmzPNVgje9hWfDJP5vre2hwRQle+p6pNKoGnzQsaXZpRoE10ClSiGl0uBCRiCIDuyBGvW6ED366KPRkUyNcCpDL3iSUQaNspPIhgX2Lv4Crcw1lWdR9o0ayJ5vAGrqmbLXAGTe8Rg8LjXFXqWVFOzSom5BflYWDW2kEi14GDRgwAAXHPcLQKrkhOo4P/300zEdWpVm0PUrbMdL/OfRAn+q06zF/XxAXQPgJ598cuS9996LCQjr2p6olEl25/sL3sSJE11ZLC125zONlRGp7aK66H/++afLBNRCq2HOHE1v/1fgWMeNAjpKUvLPC+s2CAru95qhotIsGqQWDTyp73nrrbfG/IyOL83u0PETtvNJ/HlAg0kamNR6LKeccorLqNV6AldddZXLQA+eQ8Iq+DfWoFzVqlXdLEGVz1NAPWfOnG6biM4jGrDVrA6VQ/LHUJiSG4LbI/j5LrzwQncO8YF0lbbRQIKy8zXjSSU/NXipAQYNzqWC4CwO7ROKUfl1ODQopXaKBm01MKV1/rywH1MZiSA6EBj1njFjRsx9athqhE6dJDVudEHv0qVL9HFdqFKtthZwMIIXaGXz+dJIovpsykhXBo4ayOpgqdHUuHFjl7UGIPOORwV3gov5qW6xgj/KYPE1ipU9qJlYug9IFarHrOtScDFIDe6q467jxJd0USCsSpUqkTZt2rhkCwV/NDjsB4TDFPiK/yxaWFXtZZWo8JnDyizXNtBN1/f4DnrYOuwKYuXOnTumjI3uUzatto2vx6uEG+0XqtGr2rQKmAYzR8O2Xfy+oj6WZhuqH6XECd/+08wmHUsjR46MeX7YBP+uweCm6hHr82vGszJH1fbVLDCVC1X794EHHnDZo5oVHZb1AvZGbZGePXu6vrlKIynYp4EnLRCpQXy1RVKFZmP06dMnZqaT9h8NQCmQ7q9B8cI0GOXPCYq1KPFKVP5KsRmdT1XSRwMus2fPjgbSdd7VOj7aZzTAnSrr9PTo0cOdT5TgqZr42g+aNWvmguZBYb8eZzaC6MD/f+I444wz3ChlcDVrXcTV0NX0H2WO6CLuG7laOFSdKr/wDYA9C16gdXHXwkAK0umCr+l4fmBKjR4FIjT1TlknmvocxiAEkFWOR2VPqvyCMkfV0PbBDWUHKsijYI9KKinjRxk+fuo5xyNSgTqiygLUNPFgG1ELXaveqLKwRZ15re+ha5dqFyugHMY6vcHj3tcoFmW0KfB3yy23RAPpykhXFpzOIWFe5M6X9dHfX+UWFNTxNPiiafOq8e0z0hXYUHtH51iVjQxj5miQPreCwOpHqe2nmufKvlfpPvW1FChWCbH4+uhho77j/Pnzo9vEl0zTIJMCohqI0/bQNfajjz5y+5EWiNT1N+wBdP3t1ddWcFSB0k8//dTNTtX2UtBc51kFShUg9OswhJ2ODy00rM/sy1r686/OGf64Cc6ACvNCxJodqf1k9OjRbpvoGPGPtW3b1pW5UQDdn4/VllW5m2DCVtjEB7+Vfa9toxlwmjmqAW6VG9bs0meffTaUgyzJQBAd+P+pwaITsAIGmvrjT0zqDOiifc4558Q8X4E/BRP89DsA+0bZFEcccUTk5ZdfjowdO9Z1LJVts2bNGnccvvvuu5GGDRu6mR/BRWPC2rkEkknXMl33NF1a08o1mHzSSSdFM71U87hQoUKu1ICfOpwKi5oBwQ6qMtyOOeYY104MBoMVKFf2sY6NRNeoMF27gh12DX4rw89nEPsBufhAukojKjiYCp12Bf9ef/11lwwQXMtFJRgUSK9Zs2Y0kB4vrNtHQSwNQvmFqlWXV9eUO++8M+YY0SKbCvQoGzuMFBxXUFzJWRpwUqDr1VdfjT6uQRUfSA8G/XStDdM5JFHwT7O/Vcta7X+VrlFgVFnYOmb89tCgnTKww7g9EiUmqAa8rjMKlvuEo2AgXaVKlAAR9qQGBcW1/pzOJcHBa/+5fSBdMZtUyToP0nnV08wVZZ9PmTLFXY81EKfBbM3mWLBgQVLfZ1gQRAcCFMC76KKLYgLpWhFeGee6QKlzoCwTLe6i0c5gzSkAe6eLt6Y1+9JJmuqsRQyDnXA1rFVHtHr16q6mXdg7mECyqD5k3bp1XUPbZ8Pp2hafDahsyYoVK7rMWwaOkWp8sOebb75JGEhXgEPT6n2N9DAKBr3efPNNtzCZBt0U5NI6Cp7aykoy0XaJ77CH8ToeH7xSsFSBdK2hFB9IVxBIbSD1JVKFjhslS+hvr7JHupZo3/F0LClQrBJ/GnAJM7V5tQhkrly53IxM0Wf3x4UPpKu0SzAoFuZziRaQDZYkGTVqlJv1o2CosmrVB1cwPbj4qoQtkB7cJtof/ALWvua5ylpqIV5l6gfPO/q59Na2CeO20ewEzWipXLmya6f60i6eZoMpA1sDVKkUo7nvvvtcsqfWaRENIigL3Q+63HXXXW5wStvFlxXDwSGIDvz//IVHFy1NWS9ZsmS0k6Tpu6oBqwaxOgaagjhv3rwkv2Mg+9GiY+pAilaWV2PIB+yUZaCLu2re+Yx0dc6VFQsg4zskCurouuY77zoefbaggoH+a1GmrcoUaDq+pqQDYZaoPqjag+kF0pVFqw5qcK2csIgPzNxzzz2uFJvqFavGtTJrVZ4jOFNFmbZa40TPSe81wrqf+GCoyjAoUK5tEAykq7SLSmYpUzDs/N9cn1mBUA2o+AC6304qvaCAsV+QNqz8fqKsYvUjlSSirFA/21IBYb9NNJitc4kGrcM46BSk4J6OEQ0oKBPdUz/gsccec0ltapeozMvy5csjYRU8j2jhVMUhmjdvHh1o8aWxFEgvUKCAW3g1XljPsUFKbNQaAmqH6pqj60x6gXQFkMN8Tok/L2hwToPWKoWqQQRtJ609ofs8nYd99j4OHkF0pLTgBSf4tbIC1MgNBtJ9UEEN4/gTNoD0s1x1IQ82ZDQ6rmnOavgULVo0MmzYsJhGgBqOvp6dAukKtGv0PMyNZ+BQUE1EBTGCHVVNkdZ6ICrpoo7qc889F31MWTyqkx68Bup41cCWSi8BqRDQUM1VZVlPnTo1ut9rpmJ6gXStnxO27EjfWff///jjjy6g9d5770Wfo+u8AsXKsFX5J2/MmDGhDgIG+w0K+GkNF9XsVfDc7ys+kB6ska7zcFgXcUsvkKfMfLX7FBjWgrtBGnxSqTBl2oaV3yZqE+tvr/as2rtKyFIgMBhI96ZPnx5ZuHBhJMzUnlA/O5gxHH/+VOBPgWMFlMN6zATde++9rpSl/tf1RMeMyrVo4Xc/uKBBKN0fXI8i7MeO4jLBv7+SrlTyR8ePZisoNuNnMWi2ZJj3leA1VTXxVRpV20f7iJ/1o6z0a6+91pW90ePxwrx9DhWC6EhZ/sSshopG+5UVosZucHEfH0gPLiQFYO900VZ2WokSJVzQrW/fvtHHbrrpJtcA1GrzngamVAvxvPPOi7m4+4YBgAOnuqs6DpV1rnItKjXgO2SaNq2SSuqoeeqQqIOvBeDiG9thrVcLxAcBdUyoDajjRgtcqxarXxRQ7UJ9rwVE47MCwxJIV81qDaQFP48CFGXLlnUB8iDNztRaJ7Vq1YopzyZhDKQHz4ta50W1vBXcatOmjStxo6814CBa+0XlB7TgbKLXCNOxM3PmTFe3WrMMfaBPwR0NJmjgSV+rpJ8C6LoehXlmr98m48aNc/uAyi0oo1gmTZrkrrOabem3gRbMVDmksNM5QaVRdeyI1k9Qv0FJMyqrOn78+Oi20/oswRrgYaUSWRqc9eVklXGtIKjW3LjyyiujfSENOGkGUFiuM4n4v7nPPFddbyV6+GNFgXQFirWmlvYlXa/Ut/RrcYS9faLjRG0QzdoOtsvVb9ZsMQ3qanvoeq11KZCxCKIjpalRo8auGr0+sKdRPV/zVRcoNfhUu06NPgB7pxIQqtunaWOqX6e65pqS+dlnn7nH1cBRxnnBggVdQ7Bnz54uy0Sdb79YYdg6l0Ayj0fVa1Zdc5Wa0DVNWee+I/LTTz+5DFJlA2rqpzIq1VnRIFjweAx7zU0guG8ryKcsN5U8UtBLmaMaVNIMKj+7Su1CBQFVjzRsdOxrxpiCWkoy8QGbFStWuPOFgl+aLRbcZhoEV4kKBd4VSE0FWsxO5UiCn1eDlFprQvf7RAANLCjoEfa2zYQJE1y5CQWGFeDRvqLZHKLBJpUbUEkXPabgl2YxhJ3qEh922GEugK5yLkEKEOq8Urp0aTdbQf3QMG6T9NoNKrmhz6166NoXlD2rgZVGjRq58j/BmuCJXiM7iz8XaLBN2ee+pI+uNepH6fhRHELtM7/guxf2QLoGU3Ts3HrrrS5QruuL+o+aoeATsFQSSP1MXatSpQ66BgzUZw7O4NF1xs+A0r6lbaFtdvnllyfxnYYXQXSkLJWM0PRCP31dF2sFFrSgi6Yb+oaOLlDqQIR5ZBPIKJrNoU6ARsY9Be50X3BKmTJgNVJ+wgknuIazGki+MRj2RiFwKDPQdez5hahEx6Eym4LZoj/88IPriNSpU8dlxqnhzfGIVL6OXXHFFWk6n1oLQJ113fwCogqohzU7Uu1iBXE0wKZt4c8FTz/9tGsrKyiobEDR/woCPvvssy5rPzjTLOztHQWF42es6tyrZAIf1AkGBMMaSFcAR0kRGrAVZdSq5IL6Wh9++GG0tIu2iTIj1Q4MMwV9dW7QsaNralDwuqqguWZrKnM0fiHeMAju75rl5oPhGpxs3bq1y74eMGCAK/coKhV16qmnRjP2w07BccUiFBBW2b1169a5gLBmJYgW41U2sU/0SxU6LrRv+DreuuZqYOHoo4927dTZs2dHjyUFkOMHGMJKx4+utZrtIxpQ0NojGphUQlqihUPDNgiVbLkNSFG///67XX311da5c2dbuXKlnXbaadalSxc78cQT7YorrrAiRYrY9ddfbxUrVrTXXnst2W8XyPL++ecfe/HFF61q1aoaoI3er/tk/vz5NmDAAKtVq5a1bt3aHn744TSvsXPnTsudm0sTkBHH4+TJk93XVapUid7/5ptv2q5du+zLL7+03377zU499VRr2LChDRo0yB2fweOP4xGpYPfu3ZYzZ0533dLX48aNs0mTJrn2n+7LkSOH+79SpUp2/vnn2xNPPGH//vuvFSpUyKpVq+ZeQ8dUrly5LEzbI1++fFahQgWrV6+ePf/8865N/Mwzz9iNN95oGzdutFtuucVmzJhhxYoVswULFtjff/9tb7zxhn322Wc2a9as6OuEle8vjBkzxtauXevu27Fjh+XJk8euvPJK6927t33xxRdWt25dty29MG6T77//3jp06OA+u/YRady4sR1++OHua+07Tz/9tJ177rlue6QCnTfkp59+sosuuijmPOGvq3/88Yc7vnQL6/XW7++DBw9259UyZcpY8+bN7ZprrrH333/f1q1bZyVLlnTP0Tlj2LBhduSRR7rzShj5a4p8/PHH7nqj60qBAgWscuXKtnDhQtu8ebPbRpI/f3678MILXcyiQYMGlip0jT3rrLPcfrJ8+XI744wzrF27dnb66adbt27drG/fvtajRw87+eSTo+eZsO8v+lrbZdu2bTZ79mwXw9L+ouOlTZs2tnTpUnetPvvss91+49skwddAxgjfVRzYi19++cW2bt3qggZt27a1//77z3UIzjzzTBs4cKC7UB111FHua13I1eABsHeHHXaY6yQpiP7UU0/ZxIkT7ZJLLrHFixfbo48+6oJ106ZNs379+rmgni7yc+bMif68LvJh7EAAyToeH3roIXdNU7Dn119/dYGdn3/+2UaPHm21a9d291166aVuEFkDWzpWPY5HpAof5FHgV53OV1991Tp16uSCO7peKaDhO6A1atRw7cJNmzbFvEZYAujB7dG9e3cXpNiyZYv73Ap4dezY0QWKdb+CxxpIWLZsmRtM+Prrr93PbdiwwWrWrBmqYLGCe/HUjtHAowLD1157rX333XcuiCzad3QOLVy4sKUCfd7y5cvbokWL3GCKp+uM9iO19xQAmzJliqUSnReOOOII++STT6Lf+36ljhsdQxrM9o+FSfCYeeyxx1zijPreGoDT1zqHiALoOp9qAK5Vq1a2atUqdw72g5dh468l6iMpgK4EvmbNmkUfV0BYbbO3337bDUjq3KK22QknnOD2EQ22hJH/W+v8oWNEg3D33HOPu47cddddrg85dOhQdx7R9UX9R32vgHJYaTv4/UWfc/v27a5t37NnTytatKgLoN96660uZqVb/fr1rWDBgu45wfMJAfRMkOxUeOBQTifT9EEtdOhracnatWsjDRo0iE5/0XShW265JfLKK6+EfmV0IDOmbP7888+uRIsWkdLNrzHgp3Lq1r9/f3ecUSoCyFy///67q1WsqcCqR+vLUHiaEqvrnRbSDmtZCmBvpk6d6tqHq1evdt+r3rcWM1P7UOXGVMpFi4qeddZZrrxJWEtyBLeHFgr94osv3Pf6vFovQbW+VerGr5cQLFOi8guqD6/FWMPUfg5Og9eCqkOGDIm88847MedYlRfQGksqt6ByNypTUbt27ZRq42hf0eKp1atXT1PeRqUZunXr5tbgCCu/n6hMjUpy+HIk2ldq1KjhSqYF3XvvvW7tEfVDw0xlfR566CFXG150jn3kkUdcGSS/noTOr6qH3q5du5QoJacyYKrvXaRIkUiPHj2i9/vPrDaZykGpNJbWF/Dn27CW5PCfS7Xgu3TpEpkyZUr0GqsyLSo1qPV9fOkwlT7SPqRzb1gF/9baJirVUr9+fbdtRPuE+tOejitdn++4446kvN9UQxAdKUcnITV21UHyAT8tcKiTseqeq56fGoCq2wdg//hGj2r4nXvuuZFTTjkl8tZbb0UfT69RTOAOyFzLly+PdOzY0XXY/PoevlMWj+MRqSA+GKGOqYKgwYCWAsSqZaw2ogLKWtBM9Y19xzXMgXQtjqk6vMGFyzQApzayFo687rrrou1o0TpCGhivVKlSKBdGFH12LXKn4JcGJTt37hxdP0nBHC3arPsV4HnhhRei+0nYgoH+2NHaUlpI9KmnnnJBYz8oqwHZ448/PiZhSYL7S9j4bTJx4kTXz9SAtc4XgwYNcvf369fPLbKqfUeDcm3atHHX47AeK57WY9F5pFy5ctGa575+vraNzhe+zrfqWvvtGLZ2SHrBbx076iNVrlzZLVwdT+cUDUb660zYziPxxo0b5wYOHnzwweji3aJr0BlnnBHp1KlT5NNPP4306tUrUrNmzegimmEU3P91ndEgnJLPtDh1njx53PXFt+E1AKW1SHTOVb/bC+uAS1ZBEB2hFd+58Y03ZZxrFfCvvvoq+pgagGr4arGKUqVKRebOnXvI3y+Q3cRfoP33/thbsmSJy0hX40cLcHlhaxwD2eE6qKw4NbCVbauFRIVjEYhEAxS1atVyGdjBDGu1HW+++Wb3mDqxPsEimIEdJv6coExiJZR8/PHHaQbkNMOscOHCLqgcvP7rmr9y5cpI2M6f+mzKhtT5U1m12ldmzJgRyZcvnxtU8dmQK1asiFxyySWuH/Hjjz+Gej9RX0oDSy1atIgcddRRLoAzbNgw99j06dNdsOfEE09MNzgY1jawsmgVBHz88cfd/nH33Xe7vqX6mzpvaHFV7S9amFiBsTAuIhpPwVAtnHn44YdHF8r0NGD56KOPuqCggoBhDf4F22G6ngQHk7TPqI+kvlIwLhHfNgvzgK1oQVUFijWLJz26X7PCNCCjAapUidNoEEXHT3BQQdfd3Llzu0C6jhVdk9u3bx8z0yXs+0tWQBAdoeOzQjw1aoMXZI10qzN07bXXxjxPGRUzZ84MVQcAyCzBC/R3332X8HF1qjXzQ1PgX3rppUP6HoFU5q9777//fjQbTsEeZQkqyBP2DDggPSqt4KdD9+nTx7UFVVbh5ZdfdkHBYDDHUyBUWXAKCj7xxBOuHRkWiTrbyv474YQT3PVbZWw8leNQgFQD42HuqAc/m2bWzZs3zwUzVKrD00CDAukqb+MD6b60izJv/WBl2CiAVbp06cjIkSOjmZAKFvvrjHz22WeRZs2aRU4//XSXkR+2wGh8xrQ+owJZKlviA8Tly5d3A3DpCeOxk+gzqR+gY0eJakpaC1q1alVk9OjRoR3QD24TlcPyiUUqz+FL67333nuuj6QSUPGzN8JI5434ILiCxcrI10wWL/6coUC7+pvxcZ6wev755915VdeS+H62Aum69jz33HPuew3yhvnckhURREeoqEOkGpY+80MN2IYNG7oLljoBfpruRx995KaQ+fpsAPZdsGGjTBtlImmwak+BdAUfNNUbQMZKLzjhjz1Nj1UpilGjRkUfU5Dn1FNPdZ05IJWMGDEikjdvXjclXFOhFfBSWRLVEdV1TB1W3VSWQzd1UH1mnC/tUrVq1WjGbXYX7Gzrsyrgp0xZX+9bweMKFSq4AM/gwYNdm1mlKhRE9z8b1uCXp+y+Y445xmXeaxaPH4AJBtJ1jlV2sS99o3VgdI499thjE5bNyg4SBWPefPNNFyAXZUgqM1THkefLLCiQHsbEJNWr1vUz+LfV7IRGjRpFxo4d64J8mq2hbHNP96u0SVgF9xVl4atUiWb1+BIk2k9Uq1k1vuMD6V6YzyV+rYjevXtH7rnnHheDUD18P0CptprOIdqHwjxDQceG1opQQDxI+4qCwlq7ToLZ+kpy1LET5v0jPfq8OmbUJlF5tXgqa6PHNPPHC9tgZVZGEB2hosatvyCpw6Ppc2rstWzZ0l2wLr74YpeVpwau7lMddEm1EzOQEdTQUz0/v/DYnhrWOuYYHQcyVvCYUuDCL4rogzsKGKaXWatgD8cjUokWJdMUaAUr0qNOuwZ6VbNYC72pLIcCoQpq+A692pWqZ6zgcpjceeedLgv/0ksvjS5CrEUg9XkV7LjsssvcVHsNICiz2AcPw3gOCX6md999131mZcq++OKLLvta/QgFdYIUNGzatGlMX0KDleklF2S37aAg+GuvveYGWVQ2QDQb4/zzz3efV4Msyqr1z1dNcNX/DmsZG5XcUFkS1Te/8soro0Hif/75x607osQSDSoogO4DWqoXrxkvuhaH8ZgJBu40q0eDR1o0VOdSzXzz5wsF0nWuUT3rgQMHRlKFZu8oC1/xB0+zmVSeRGWQPAVKlbEfxn1EdExoBpNfK0I18r/55pvo47rWNmnSxC0cGqRrkbZLWM8pe4pDaV/QuaNQoUKRSZMmpVtWC8lBEB2h9Mknn7jplb4moagRqCyiXLlyuU6QLlxaIEjBPQD7Z8CAAa4+qBZHim/w7KmBHdbGIZDsLCdd01SmRdkpCqarUx9fzzg+S4XjEalAAUANKI0fPz7N/X6hXVHNc3XiPQV//DET1kURFQBWndlgMENZs8WLF3cZk6Jr/IYNG9zggd8eYVzkzi+OKapfrZmtqm/tKbNa9b81qBAfSPfCkJTjrwtKStIsDQWLFRz2dMxoQCFnzpxpZhjqey2oGSwvEBY33XSTy0DXAIlKLdSvXz/Srl27aJBYM740AHXSSSdF107w12cFUX2WbVgpMa1MmTJu3QBR1rW2h86p/vypQLpmLWi7pUrW7Pfff+8GKVWyRPy2UCkbtdmGDx+e5mfC1jbTZ1Qg2JcR1DVF5VtUwsaXcNEAnAYWtG6dypcoMVLnnaJFi4a2NFb8NUOzwF599dU0AXMN0Gn7xbfpw7q/ZAcE0RFKKtdSrFgxN3oXX3dLdc87dOjgphPp4q5afgD2jwaldPyoI+UbhgAOjWCDWZ15TR1Xlps6sRocVkmG4HTZVOmsAvE01VnXqr59+8bcr0FglRkL1rhWe1HBLk05Dx5jYT5+1F5WYFifWZ15/1lVI14L/u1pzZMwUd9A2eTaXxQAVakFff74mtYKpGsfUaKOZvuEjf/7K4CufpRq7wYD4irToRm+Q4YMcUEwn1GsARbN4NDgSxjLUWjGpQLEvnSCtolmJyiQrkEVH0hX2SOdb66++mrXB1V/s0iRIi7rNsz099cAg2Zv+POKFhPVoIrKIamsqt9GmtHg97OwnVvT+zw6n6iv9OCDD0bv07lW2ejaf7S4athpTRENrokCwQqmq/67yvto1pcPkisJUudhHTM6zyo5JMzr9wSvpdoOmsWiMsSaNadSLsEY1TXXXOPKimmwAclHEB2hpSwSTSdTQya+E6DFPHQRJ4AO7F2iRq4Ww1FnQdk5fr0BAIeOgjiaOq8pssHMUtXeVPagsr6AVKap9KeddporP+Ez3lTvvE6dOtGBJn+N0/fKrg1mZYeJMh+1QKYy3RS02Lhxoxs40HVc2ZLip8wr81xlEFNlurjOlQreaFFQ7TNay0XlfJSJrf5E0Oeff+4GK5VpG0Z//fWXyx5WGYUglTHRvqJtpJIuCgoqS1QzGZSYpIBYWIPFCgqrJr6OCyWRKJtagXQNXit7NhhI1/GlvqfKhiqTNlUSTdQOUZa+St5oUVWV0JLu3bu7/UYloYJ15MM2GBf8PJrV4suWyAMPPOAC5sHyeprNo/uGDh0aCTvN+tLfX8eNrrEajBPNWtAgrspk+WuQ6LqkOE1wdlCYqdSNzqG+BNgNN9zgjhkFzoNlwVQeKbjWApKHIDqyPT+lVI1enYxVwkXT2H2QzwfS1XHwwjbyDRyqRmH8IlGa9q0LvUbM/aJaADKXrmG61vmFELVgor8/GEjXFFC/TgiQqtQ+1KJtmjquwKiy2+ID6LrWjRkzxgU7wlCSI56miSv4qWxaZbMVKFDADSwow1ZlS9SB//nnn2PWWFBt42Ad31TYT7TArBZS1flV32vdF9WJj59Gr4BPGPcTUdBXWaDKCvVtQF1jlJmvRSG1fTQQpfafr5mua44CqGGmbGpl3+ua64Oh6m8qQOgD6b5Uhw+ghi1QnJ74PrVm/bRv3z66DbTPaH9Rwk1Yj5mgPn36uEEoBY1HjhzpBl4000eBUR1XSnBQSUwN2tWqVSuUpbFE5wR/PGjwRDMVdOxoFk+QrkEKpCsTO6wD2Huia41mj/r1xTRYqTI/mlmqMnRacyJs67CEAUF0ZEuaZqqphP5irNFvdQxUc0yZEMo68qvD+0C6phKFNUMCyAzBxr+yXU844QQ3JVEj4ZrS7DNKdPypYXTXXXdFjzsAmU8BLq3zoU6JskyDHVodozoudewCqU4B0ebNm7tp4ipHEX+NU4BZgQ9/X5iCPQryqTSHygZMnTrVBXV0XqhevbprMz/00EORq666ymWeayBBC9xpeyhLMkzbYX8C6bqp9rcCHBp4USB98uTJaZ4fxu2jTGpdV4LBUQXLVfJGlJR05plnusBxsGxYWPlzgo4jXVNVPk2zODwFi30gXdfisK6fsK9UxkbBYVGAWGsnDRo0KLTHTPA6osEmJTA8+eSTbl/QvqLFVJWEpJuC6tpPNKirUj++HxW2baLrSLNmzaKzlDXApv6jrsEqV6LtE6QAsq5FCrSHuXxLeoNOOpdovRYdK5r5pYE6XxZJa/npnKNjSDOEEr0GDj2C6Mh21FjRSVarOKsWrBq4ql2oC5emp7711lsuc0RTyfzJW1MxVZtNo+Cp3rgB9pcWKtR0XTX+lKGkC7wyKHTR9w1An5GujBMAmddJ850t34hWQFDH3u233x695vnHVMosbJ0z4ECpRIdKLKgNqSw5T9+rbq+/noUpe9QvqqpM9HgaAFdAQ4MH6ryrw64AkDL1lbUf1gDP/gbSVepF20gL3qVCpqQGYPPlyxfdZ9JbHF77lRIr/OBtmOnzK+NcGdYqvaE+pgJ+KjcR7Ju+8MILLtNYSVupTINNysLWNlLAuGbNmtFs6zAH/zQ7RTXggzWrlfBXtWpVN1v3t99+i94fvMaEMRNdC4f648P/ryQrBdO7du3qrjHxZWx0Tdb9we0UFhq4Dg6aeP548PdrtoLOH/57rUmhTHQNTCFrIYiObEmjuZoqpql19957b+TSSy+NqT2mRu/JJ5/sGsD+/mnTprmGMYB9p8wjTfP2iympFqimgWvxE2WaaLTcD0wpwy2MjUEgmYKdreHDh7uaku3atYsMGzYsuiiiH8S67bbb0l2fgOMSiC3tokxrXc+U4aUgh++0hulYiV9UVR123YKfURmBKu/iA6bKOFatZ9+5D9P2OJBAugZd1KdQko4GGcI0wJKI9gGVE1C5n0RrRykoqPILWmMqrBIFfBXk0wCCZnIE6xUr0K6Z0mEsvbA/+70CqAqka3aqknD8OSTMg3FTpkyJFCxY0A1Cxg9Y6hyrAQVtDyX+BYVxUCF4zVDilRIdNQvKx2M0KKn1FtILpAdjOWGhz1SvXj2XhR8UDKj786gS1NS+1zGkQQedZ9ROCfP+kl0RREe2vZArkK7gebly5dyId/wJZtSoUe5+Fg8FDpw6jso48o1ELaykY0sXf5VQOv300109zGCjKVU73UBm0gJlxYsXdxnnGkBWqQWVGfBrEWgWVu7cud1CRMp6AZA4QKpMa9V4VnAjjAH04KKqKsHmS3GkFxRTkEMB4vhtkAoB471tP81S0Lk2GCxNhe2imQmawaAyPwsWLIjerwEWBQNVHijM6234vqTavbfeequrA6866GoT+0C6ZkQrkB6/VlDYBPd3DcxNmjQpzWK7fnslCvKF7dya3ufUehpacFj7S3xpS83S1SK8Sn4IO79t/Kwd1YBXW1WLEfsguQYmFUhXkFi1v+N/NkwUBFdZH1+OReWygjRbwQ8mjBs3zg18a0Frlb9ROwVZE0F0ZGs6IWl6jBpzWohh27Zt0ce0OrhKUAQXFAWQWHodQx1Tagyq4aPMvfvvv989Tw0dBdDVYNT0MwAZJ74jMXv2bDf749NPP43e98EHH7gSA8qW9Fkso0ePdlPNUyHIAxwMZQTefPPN0eBO2II88Zn3yqhWmY74c4yCoiplw9oJ6VMmpQYuU+2cqqzhZ555xg3MKlCscgJagPbcc891CRSpsMaUAlqFChVybVxlVCsQpkEVXwdewXNdb5W1H8YSFPFU21uJaypZoxmpOqfMmjUr3cBnGIOh6X02ZZ37NTakR48ekQoVKrjM6/hZgUp0CHM2fpAWYlYwWLXOlVWt5A4NOgUD6bo2XX311a4d62dVhpHOFyqbpjItOmZUKeHvv/92j2k9Eh1LqpbgaUHngQMHujLFXqpdf7IDgujIdhet1atXuylzavj7QLpWNT7ppJMi/fv3dycanYyVtaegAwsdAnsXvEB//fXXrrMdrP2pY04ZAxoxFzUE1alScI+LO5CxfHa5P7bUIdFgcXCauLJntQBgnTp13HEYj+MS2DdhDaCnF0j3U8N9m1qLuGkKuV80M8zBr4OViudUJSSp5JEyI5VNqhKaP//8cyTsNPNA11YfyNJxoYC6+pZBqvesMg1abyHMtAbZEUccEZkzZ44bPNA5RSUdFQD1MxVS4dwRPAfo3KkBJp1Xg4sOa6ZGxYoVXSDdt+WCwh5IVwUABcuDa2QlCqTrXBLGdRVU5jQ4Q0XrJWgmqRY297OaFCxXKTXN7PDSO4ZS8bqTHeTQPwZkExMmTLD777/fcubMaSeffLJ16dLFGjRoYOvWrbNbbrnFPvjgAytdurTVrl3bVqxYYc8++6zVr18/2W8byNJ0GciRI4f7+r777rOxY8fa4YcfbsuWLbN27drZzTffbMcee6w1a9bM8ubNa2eddZZNnz7d/vrrL/v222/d8bhr1y7LlStXsj8KkO19/fXXduGFF9ro0aPtjDPOcPfNnz/fLr30Uuvfv7+1adMm+tyNGzda5cqV7fHHH7drr702ie8aQFb2888/u3ayrvdqR5922mm2c+dOu+CCC9w1fOLEie5/IF6Y23fB9m/QypUr3bHx2Wef2R9//OHav61atbLnnnvOPf7NN99YjRo1rFChQqHcPvHb5bbbbrNVq1a5/oH/vOoDqA/epEkTe+WVVyzsgttE59A1a9bYrFmzbOnSpXbSSSfZ3Xff7fYRueeee+ztt9+2q666ym6//XYrUqSIpYJFixZZ27Zt7e+//7YhQ4a49up///3n+o7//POPdevWzX766Sdr3bq1de/e3fLly2dho+uq/u76zD179nT955tuusnGjx9vRx55pItLPfHEE5Y/f35bsmSJVatWLdlvGQeA1hKyjcWLF7uTUOfOne28886z3377zW688Ub78ssvrWTJkjZs2DC7+OKLXUBdF3UF1AmgA3vnG4VPPvmkvfjiizZmzBj7/vvvXcPv5Zdfts2bN7uL/TvvvOOeN3XqVDvssMNs9uzZrtO9e/fu0HUggGTJnTu3GyS+4YYbbMaMGe6+SpUq2RFHHGFPPfWUzZ07N/pcdWaPPvpoK1GiRBLfMYCsTh35oUOHuuv9ww8/bF988YVddtll9uuvv9q4ceOi13IgXnBwJUy5d9rfdTwouKe+o5JDfv/9d9u0aZP7zGvXrnXB8nPOOccFR5955hn3c/PmzXNBMA1MSRjbv75foG0gq1evdtvFf95t27a5dsfgwYNt2rRpbruFad/YUwB9+PDhLubQqVMnmzRpkrupn6T79bU88sgjLuHohx9+sMKFC1uqUJtU7dcNGza4uI0omLxjxw7Xb9R2K1u2rH3yySe2detWC2sbvk6dOrZw4ULXZtcxpEGo//3vf3bNNde4/rUGtDW4oAC6thmyoWSnwgN7EpzWosVctAhFcHGTiy66yK3urJpbovpjqq8V9kVegIMVPEb8VDEtIOUXeFGNPy2C8/TTT7vvt2zZ4v7XFDxNy/PHZtinwQPJoHqzV1xxhStJ5msl/v7775Fjjz3W1VPU2gRjxoxx08g1zT7s04MBZIxUWVQV2BPf7tUCh1pbS2U58ufP78ot6NqrPqdKt6iu88UXXxzzs6p7rfKGf/zxRyRsPvroo8h7773nvu7evbtra/g1WLQG0ksvvRTz/DfeeMO1QcK6mLn6QPHtK5Ulid8nVCarcuXKbiHn4KKr/mdTodRNcL0RrZ+gtRNUxsTz1xqVBw3jsRP/d9ZioTo2FLvyJbDUf3788ccjJ554otuPtC2ENnz2QzkXZPlRX41Wzpw5042AayT89ddfjz7n008/ddmzmmo3aNAgO/30011mAVNSgcQ0m0NZaJpqWLNmTXffv//+a6eccor17dvXlUQ688wzXYaJsmGVQaCsisaNG7v79zYNFsD+UVkWTWstUKBA9D7N9FC221dffeWmkDdv3txdAzWNWJksUrFiRTe9Ok+ePKGcUg4gc6bcP/30064MlLLmNP1c/wOpwPcTlVF+9tlnu7ItKsfRqFEjGzVqlGsb65qqTGNlEmvG84gRI1w/VG3nF154wZV5qVu3roWJyrOofOOcOXNcJu3777/vMvH1tR7TDBbNSFXZEpWr0PZQWVV57733QtcfULtL8QfNyPVtK+07KkmyfPlyN+Pdz97R/qTnawav9qmuXbtGy/GFta/kP5dKf2pf0DXkuOOOc48tWLDAHTOapaD9RRnYov6kjq0wC8ahNPtL5xT1r5V9rhlhmsWhbfPWW2+5klB6TsGCBZP9trG/kh3FB/bk3XffdZkBWtVYq4HnzZs3ZrFDmTFjRuSMM86InH766W5EjwUYgD1TBkD58uXdMeMXBJKePXtGjjrqKHecvfzyy9H7tVBvs2bNIo899liS3jEQXsoo13HXokWLyOjRoyMzZ86MPqbFytq1a+cy0rW4qF+wSNc6LVjFjBAAB4NzB1KJ7yN+//33LrNaWeXxx4AW7FamqBZB1IKayhhVhnrt2rXd7C/9bJiziKtWrRrJmTNnZNiwYe4+385QNm2vXr1cv/zII490M+MaNGgQzTAOW/9bWcM+Q1gzAv3nHDt2rJuh8M4778Q8/5VXXom0atXKbZNOnTpFwszvE+PHj48cd9xxbn846aST3KwOb968eZGuXbu6BWj9rOYwS7T/ayFVVU1QRrpmvvhZ3bpfbX+dY5D9kImOLEujmhrVLVasmF133XUuK0+j4J9//rkbHT/hhBOiz9V9WlytfPnySX3PQFbns1W1QFDDhg1dPWVlpCl7QAsaajEc1fZ799133fGkhXOUQaBMWWXekOkKZBzNALnooots8uTJ7nhTNrqOUdWMPPXUU91ioVp4SHU2P/zwQ3vttdfcjJCgsGY5AQCQ0bRoqNbM0mKhb775ZvQ6qmuvn5Hx7LPPullfAwcOdLM3dR3WdVlZplpMNGx8O0JrJNx6661udoq200MPPeTWIfP0+X/55Rf77rvvXPZsixYtXL8gbLNZgu0qzXq//vrr7dxzz3X7g2p8a1FM9Z0Up1BbTbGKjh07ulkNxYsXd4trKhtbmcZh47fNxx9/bJdcconbJmrHam0NZVtrO6kPKfPnz7dHH33U1QefMmWKqw8fxvZqcCaoMvNV77xChQquDrxoVumrr74ak5Gu9r9mOrRs2TLJ7x4HgiA6siRNsVOQvHr16u7k7Fe71gVJ5Sa02JoCClpAFMC+UQkINZDViFHnQQFyHUNVqlRxC4pWrVrVlUvS4kk6BhVg94uGajorJSOAjOc7rWpsq2PfunVre+mll9w06p9++snKlCnjOqvqhGzfvt2+/fZbd20EAAD7f8299NJLXVD8rrvuckHQ9IKnp512mlvQW8HBVGn7qs2vbfDjjz+6MqlayFzlHBUYFT32999/xyyWGfZto887YMAAF/BUEFRfa8CgZ8+eLjiqfUTUhtPgggLHWrRZ5WgVSA2DWbNmuQGBokWLuu+1WKZK+egYueOOO+zPP/90/cnatWu7WE2tWrVcuRtR21UDC2rLhlFw/+/QoYM7dtTfvuKKK9yixNoXRPvK6NGj3cKrKpXqy6kKyTDZD4WjkVS+lpjnVyguVaqUXXnlla4WnVZ49nRSfuCBB1xdZtWu00rHAPZOF+6rr77aBeeUDaBjTbXP1UDWqLmyzZcuXWqXX365q9+mi72+vvfee11NZgXQlWkS5oYykIxroGZRKVNHsz0++ugjW7FihfteHTZlyd15550uQ13Zb5UqVXIZLAAAYP/pmqs2sbJF+/fv72Yzp0eBUp9JmiptX9Vy1mfV7FRlzCowet9999nEiRPd4xdeeKGr5xwU5m3jZx5oVoKSj5TEp+C5antr35k6daqraf3YY4+5mIWy1LVvHX744aGoc63grmrka/Bg+PDhbqayj9MowVFr9SiArvrvSgAZP368CySrLdukSRP3XAWLwxpAD+7/7du3d9vqqaeecucUJaNpIEpJaqJ6+XqOBuXU9w4igJ4NJbueDKD6a/fdd1/k119/jaknpbrNqq2lmnVffPFFzM+oHp1q1PnaUgASU33zAgUKuDqPGzZsiN7v60CuXr3a1bM75ZRTIosWLUr3NVg5HMgc/rqneqPnnHNOpGnTpq42epCOVa1N4J/L8QgAwIH76aefImeffXakZcuWkc8//zx6v66zK1eudNfjUaNGxdSADmv95uD3wc86Z84cV9+7YMGCkTp16rj1yXxt8FTht83ff/8duf/++129/LvuuivNdli4cKGLTRQvXjzy3XffRbK74H4wdOhQVyf/oYcecm3RoOeee86t6aO+pO9znnzyyZEmTZq42E4qePvttyP169ePft5nn33Wxa+0Zl/dunUjr776avS5kyZNSuI7RUahnAuSSiO5Gt3UyN0xxxzjaompjIum2cnWrVtdPXTV1lLNWD3XUwaBRnwBJKZpdZpKdtttt7ljKX7qmK9jqNIuqpGu41BZ6PXq1Uvq+wbCKH7Kpv9e2U7KANNskJtvvtmVbVEd1nbt2rnn+cfjvwYAAAfm559/dhnXuhYrw9iXdtEsTK1FojW4wrzelko1Kutc5VmC7ZPg18uXL3flKXz7RH2GsNVA31u7yj++ZcsWtz7b9OnTrU6dOjZs2DCXiaz61pq1+8ILL7h9R2VNsjP/eVevXm2//fabmwWpWcyqEqA6+TfeeGO0tItmS2qmgo4l0dpa2nd69+4dncmRCiWiVCNetfNVElVVE95++2137lD5lpIlS7o1jpSN7tGWz94IoiPpBg8e7C7Euoh/8cUXblqUpgipIaOTkaYO6QStae06STdt2jTZbxnINjT4pNpr6gyoDET8lLFgQ1mLjeqCr+dr2h6AjBNsMKtDWrdu3XQfV0dVnXoNMqukkkotAQCAzA2kax0uBQsffPBBV5Ih/jodpnaI+gXqX6vEhD6/yo/sS23msNVAD24TDZooOBysk59eIF0lbrZt2+YWoPXbS9tF7bb8+fNbduY/p2qZq+65AuEqT6MyJE8++aQLBAcD6Vp4Vc/TGgPlypVz21Br+oRxUdVE+78GlXRTAowSQlUPXdtEx5NKEGuf0WKzGmBAOIRnCBHZljLPdcKZNm2a9enTxwXOtdq1TtKvvPKKCyBoxWtlnmsEVCukZ/cLFHCoqO6aFsXRoqES30DW11oERdkGqven2nZFihRJ4jsGwkfHne+kqRGtxaeUsRRcdEqPq/OiBX01mKxGuJ4HAAAyhxJMdM3t3r27nX322W4tLi2kGLYAerAdovWRFi9ebL///rur4axkNgVFFSzdWyA9TAH0+LbZhAkTXPxBAWAthqnt4LeHb6NpG2mxVcUigjMJtV2y+7bx20OzmDWQcNNNN7m4jALkcuutt7rPrNnN/nutUadBJyU7+tkNYQugB2eN+r+xFo5V0Fy13zUApWNIwXKta6QBFvnjjz+sRIkS1qNHDzvrrLNiXgvZG5noyBK0OrqyYBVU0EVJU9iVqXfiiSe6k5Ey1DVarpN5mKfVARntrbfecoNQahi2aNEi3efo4v7XX3+57HMtIBrGTBMgK/CZPVpsSFM80+M7ZOrcquPCdE8AADKXgsp33323DRgwwGrVqmVhpVITGjRQKZICBQq4hQ9VskWJat26ddunQHrY6G8+ZMgQtzBm48aN07S7EpW6CeN2Wr9+vUturF+/vss894IlfLT/KJCu4LniM/ny5XP3K6jsvw4LBcTbtGlj/fr1c2VPRd8rNqW/v46hV1991Q06bNy40ZVO1f8aSFDZH/3/zjvvhHZ/SVVkoiNL0Cjm448/7mqc6+SjqUHKTFcjZtGiRW71a2XJEkAH9k+DBg3ccaXZHdWrV7eKFSvGXMhVLklTWU8//fRoAF0IoAMZS9PElaFTunTpPa45oM6bjs8jjzzSfU/dRAAAMle1atVcHeNgWzhM1K5Yu3atC+hpIF9lXOTCCy90ZRxHjBgRzUjf19Iu2Z0+47p16+zDDz90cQitvbZy5Uo3oPLGG2+4uINmyQcz0uNn84aNZiYrsVHlR4LtT+0b+l6fWeV/9L+y9v/55x+XDKnSLmELoHtKNLv44ovdGn2ava3towC5toEGEjToMHr0aFeOWANxSgpV37p58+ZuwEFS4XhKJWSiI8tQEE/158qUKeMuZmGbRgckixqCV199tWsQKWPg+OOPj04z06CVAukauArTIkFAVqMG9lVXXWWlSpWKZqcAAAAcCio3oUCxSqUqkziYXawsW5WyUfmOrl27ukB6KlC5WJXxqVKlisswVqkbBUkVFJ4xY4Zb5F1Z6qlizJgx0TK6wXI1QQqcq1So6p+rX6lSuypbEkazZ892C6t26NDBfvnlF7dWkRYK1SK7nmZxvPfee66/fc4557iAebBUEMkw4cNfE0nnx3FUi+yYY45xJSUUQGd8B8gYl1xyiZu2qdIu559/vrvAt2zZ0jUWlYGhgJ4a0SrhAuDgpXf9UtaXsliUCabjUesPAAAAZDQF7uIpU1gBwA8++MC1U4Jt/zp16rjAsUqaqF8gYeuLB7eJ/2wKFKtP9NNPP7l+kWrka+agEvpUfk/B4lRSuXJlt19oIVFJL/j7/PPPu6SQTp062dKlS0MdQFdm+datW137XdtGmee//fZbzD702muvuWx0Bdh1/ASD5sFgOsKDvyiSzk9tUdkJnXS0EGLwfgAHR6VZlHGu1dIvuugid5xpQUM1gLR4kqauKhuFEi7AwfPTXf0UUN/YlnPPPddlqmjatBam0iAWAABARgkG8b799lsX6FSZErX3n376adfXVh9AGcU+EKivVRtcz9Fio2HriweDma+88oqrDa9a1ur7qByJgp8//PCDPfzww252vPzvf/9zC4ymEmVdFy5c2G0j1cr3ggMq2pdUllD7WbFixSysNHNbGfkKnKs0qtYXUzte+432jeDxoe2lWR4ff/xxTH86TMcQ/h/KuSBL0Uie6rJpxWMtKgog87GIKJDxHVc1ujW9U4tjn3TSSW7Kq9b/UAd17NixLmNF9+mmEi8AAAAZRbO8VUpO4Z6aNWta9+7d3WxUrTt26aWXunWSVEZVA/4q5aI6zqqXrrrpWjgxjGUe+/bta4MHD3YLiGo7tGvXzgXRfalLZZ5rPbaePXu6+uAacAjjdtgTZaFfccUVbh+599573b7jB1r69+/vSr5MnjzZqlatamHtD+/YscO11xcuXOi2hWrja/0AlUTS/yphM3HixGj1BILlqYVMdGQpWjz0hBNOsHLlyiX7rQChlN64KQF0IGP4AHrv3r1dtvlNN93kpkV///331qtXLzeFWg3zyy67zGWkP/roo/bmm28m+20DAIBsPogfbOMrCK4B+9dff91lmGuxciWqqR1y5plnuuDgWWedZUcddZQ1bdrUfS/KsFU2cthKuGjbbN++3RYsWGCTJk2yKVOm2FdffWVff/21yz5X6Q6ZOnWqG0hQ32jOnDkpWe5SQeInn3zS7TtaT+vaa6917Vklf7z44osuaz9sAXTtG1oPQAMEogC6n7mtmQnaV+Twww93n18liDW7e968eWkC6OQohx+Z6Mhytm3bZvnz50/22wAAYL999tlnblGuoUOHuo6pOrLqqCrb67DDDnO1NlV/U1NDlQWlxnmqZTkBAIDM8fLLL7vBe9U/v++++9x98+fPdwtkKoNY7RMFSoMZtFpMUwP7+lktqFmrVi0L0+xABc/1eZXgoESH0qVLu/u//PJLV9pGSXy6v3r16m4gQZnp+tng4qupRmVAlbWvrOtChQrZySef7Oqgq2582Oj4uPXWW90+okVDFSD3VCFBgwmqi37aaae5+5SRrueoza8ZHAq2I3UQRAcAAMjAhrjWGujcubPLaNJU4ccee8xNB9XU6WrVqrnHlI3uO2ap3EkDAAAHRuVZmjdvbnfccYf7ftmyZS5rWAP4+l9Z1p4CyQqkq22idVlUrsMH0JV1rCxjlX9RvevsLjhAoG3z1ltv2Zo1a1wCgz6n/+yiNlvHjh1dIPS5556zo48+Ok0QPlWlUslPP2iwdu1aF1DXQrOeZpOqtM/IkSOjAzAq/aM1BlQ2CamFIDoAAMABSK+DpSmhmzZtcgszKXNF2Uz9+vVznTmVLNOU4Q4dOrhsKAAAgAOxdetW+/DDD+2CCy5wwWFPQXJlm6sEhRZDVAaxp7ItyrhW+0W1rz0FDtVOOeKIIywMi7v7APrMmTNdGRtl2attpiCpZgYqSKpZgd6nn37qAqIqtZfqgfNEgxGpUPtbgXSV8/nzzz9jAukalNLAk9YV0CzT+OQXBlxSC0F0AACA/RRsMKvR/d9//1m+fPnclGD5999/XamW9u3bu4a4snm6dOliN954o9WvX5/GNgAAyBCa8fbjjz/aCy+84L5XSRZlnS9fvtyGDx/uFtL0lK2uuudqh4QpMBqfNa0FUrX4o+q+a2FIn3WuxTKV6KCyHS1atEjzOgREU4ff/4PHgQafNOiiQPott9ziEmLk6quvdseY6ugHfxaph7MDAADAflDD2XewVG9Uiy2pDroW61Kg/IcffnANa3XmlOnVv39/11HTVFAfQE+1har+v/buBcrGeo3j+NNZKbdqCiG3MIRMRSUdXReZEtJJpXuWrNDUkNtBlCKpjGs1pZO7Mk1RdBuRlepQCh1CSlMYXSghTaZy1u+pd689l12GYcze389as8zsvWevmW2/s/7v8z7/3wMAAIqedsBpXaHIkiDWRRfxk5KSrHbt2v5vMBhRdJseH3RtRwMNvxw0aJB/rt9r8+bNHtsyd+5c++qrr0KP08UERdzs2LHDO8+Vc50XBfTYoHV48P7XMRT0Fjdv3tw7zrUrQzs6dFzJxIkT/b0xevRo/zpajh0UHn8hAAAACiFYOI8dO9ZP0mbOnOlDvHr16uVDuXRypgHZ6oIKtlZrqKiiXIIT11jJmAQAAEVHa4hw2gWn4ZiKoZg8ebL17NnTb9eFfV3gVyd2x44dPRM9GovF2gl4+eWX2wMPPBC6rVq1ajZ06FAf7K41mDLfwwvpiub49NNPPaYDsSd814KaYdRtrugW7d5QMV0RSFrTq5Cuiy3p6elWqlQpn0Gg2UeKBkLsIs4FAADgb2zatMmqV6+ea6uvss0bN25s/fr1804VdaE/+OCDHtmirNJy5cpZdna2P75MmTJefGeIKAAA2B/hUSPa3aYCckJCgpUvX94v4Gsw6D333ONFdRUERbnpKhZrPku0X8BXY0MQ46Ki57Jly/zigoaK6oJC+EBRXVRo0KBB1L8myC08hkXFc70Pbr/9do8+euONNzzzXBFIOs7ee+897zzXYzRfQO8VdaRr18MxxxxT3L8Kikl0XH4EAAA4SLp27epxLBrIJVpYK/Nc3SgNGzb0THRtJR4xYoQX0HNycnzRvWDBAu9IVxd6kLlIAR0AAOyPoICuXG8NxlQRUOsQDcZUzreK54qQUzFdkRTSpk0bGz58uBcAozlKTr+bGhiysrI8v1prsbPOOstfBw0TVWFUHcWBU089NepfE/xB74VAUEBX08vGjRt9foC6zvUeUfSPdi5oTR90pPfo0cPX9vXr17e6dev6jgcK6LGNIjoAAMBfUPfWzp07fSEdFNLVWa7tw9o2ff755/vJWbdu3fy+Xbt22cKFCz3iJRz5iQAA4EAiXLS+mD17ts2aNcs7rtU52759e/9cHelBIV2d6Mp0DhdNXdd5AxX0u912223ecb5u3Tp/HVQ8DTKuTzrpJBsyZIi/fnm/D9FLuzXq1auX7/9dx4p2JlSuXNlSUlL8Y/r06XbjjTf6bgYVznXcXXzxxT6EVvS1djggthHnAgAA8De5iVu2bPGOJnWhKB9RMS5Lly61/v37+xZqDadS3Iu2DHfu3Nm2b99uixcv5uQMAADsF2UvH3fccaGvU1NTbffu3f6h2JaAOmcVK6cOdBXUtS7Rbjh9Ho3rkPBYGw0RVWODnHDCCd6Nrtfhqaeesvj4eJs6daodddRRviabP3++3XvvvVH5miCy5557zjp16pTv9h9++MHX7ZoZoONJj1m+fLk3yegCzH333ecXZYBwFNEBAAAKoE7yzMxM3yKtThQttM8880yrXbu2525qa6eGVemk9uOPP/YCezA0VDmK6lYJH14EAACwL1q0aOHDDnv37u1faz1x4YUX+vrilltusUmTJuV6fJcuXezFF1/0Ncm1114buj3aZrGEF9AVU/PKK6/Y1q1brVGjRtanTx8777zzQoV05VerC1mvlQawBlibxSY1uaghJrwwrqzz5ORkb4xRpMvbb7/tF2D0WA3nBfIizgUAACAPnXwpU/OZZ57xziWdcGnLpwZ5ffHFF764/vzzz+26666zyZMnewa6PldO6ZIlS7yArhNXTtIAAEBhDR482JKSkvxzdZ5rPZGRkeERFPPmzfOiXzhd3NcF/6effjrX7dFUQFf/Z1BAV+fw2LFjParl0Ucf9cK5OooV26HB7jfccIMPfNdQVRXbg+8X1mbR6696hCtUqOAxjFOmTAndprW9djJoHa/3iqIbq1atGiqg03OMvOhEBwAACKOtv8o3VwH90ksvtbi4uFzdXEFH+sknn+wnraecckq+56DLCQAAFJaK402aNPEIElG+uQYgaqDhiSeeaNnZ2dahQwcfbq4cdK1HInVqR4tNmzZ5ZF5AUTV9+/a1CRMm+PDH1157zbvvtR5Tg4M68pUVrxk1emzbtm1Zk8UYXWjSRSVdUOnatas3xmh3x9ChQ/1Y0i4FNcQoMunhhx/2GQNBhr4+F5VKmWeEvKLrrysAAMABWL16tS+mNYxL2YhBAV0LaRXQVUgPOtK//PJLL7avWLEi3/NwsgYAAApDgy+1q+3111/3i/FSo0YNL/g98sgj9t1331np0qU9gkKzWVRM/+ijj3I9hwro4YNISzoVQFu3bh0a7C66mKDbVEDXa6V4G63d1GGsXHR166uwruGRV1xxha/JgtcT0U87QgcMGOC7FBITEz3yJ2h4USa+djHofaVGGM0cGDRokHeha75RUEDXMUQBHQWhEx0AAOBP2iqtwrhOypSjmXcBHd6VomGj6ozS4x977LFi+okBAEA0UFesctB//vlnH1x+2WWXeUd6WlqaX9jv1auXx8ZVqlTJO9L1WK1b1ABQ0K64aKC1VrNmzXzujNZap556amgopBoddCFBFxSCyBZ1natLv2HDhl5Ip5s4No0fP94GDhzox4/mCOj4UKe54hZFQ0NHjBhhTzzxhA/mDcd7Bn+FTnQAAIA/qcN8586dPjRUC+i8vQa6bc2aNfbWW295ZqK6wtS1DgAAsL+0001dseoyV+FPBb5XX33V9uzZ453VGmSu3OaHHnoo1JH+wgsv2F133WXx8fEWjdQ9rrXW+++/b+vXr7fu3bv7BQM5/vjj7dtvv/XdgDVr1vTbtm/fbmXLlvXCqF47oRgaO8J3YOi40XFRp04dP24UxagCerAjQUV0Fdlvu+02HyYajvcM/gqd6AAAAH96/vnnfVuwTmK1Vbgg2iK6bds274gKOlrIQAcAAPsjb465OtIVQ6Juc3Wet2nTxgvrippQ3Evv3r39o0qVKqHvibZ1yMqVKy0zM9OOPfZYz7YO5tGoKJqammqNGjXyx2mA6PLly31X4OzZs714qqKoXotozIdHwcL/ry+55BI/HubOnWuTJk2ymTNn+vvlwQcf9Cig8ONFcwV0rAH7ir8oAAAAf9IJmk5Un3rqKfvqq69Ctwc9Bzt27PBuqISEhFABXaLpxBUAABz64p+6zf/73/96R7oKgGXKlPHO86AjXcMzn3vuORs1apSlp6fnep5oWofMmDHDB0FqwPv8+fO94BnMo9mwYYMXzIOM9KSkJDvjjDNC+daLFi2igB5jtEYP/q8/++wzX59rHa+honfccYddffXVvotUMwe2bt3quz7at2/v76eggB5NcwRwcNGJDgAAEEYnqDp5u+qqq6xPnz7WpEkTvz0rK8u3faqQrpM0DRoFAADYH+HZy8pAVxFdndV9+/b1AZmKl1OxTxnp6ki//PLLvUC4YMECu/DCC6NyHTJ16lQvkquAfumll4YGvKvwqd836EivXbu2P0bza+T777/3iBe9nsFjEVuSk5N9fa48/GnTpvl7IXgfjB071tf3u3fvDkUnKSsdKCyK6AAAAGHU8aTtnz169PDOJw2sUoeKtlfr33fffTeUqxhNnV8AAODQ02yV+++/37uuGzRo4B3owRpDhXR1y/7yyy/eda2u2qAwGG3FYuWdq9u+Z8+e3rSQ92JDeCH9rLPO8mgXvXann3566LF0oMcmFccff/xxmzBhgufoa0eHaAeHdpjKyy+/7DFBei/dc889fhvvFxQWRXQAAIACaFiVupzWrVtnNWrU8I50dUfppDbaTlwBAMChp2J5586drW7dunbvvfeGiufhxT3tgPvnP//pH4qpiFYZGRm+znr99de9wzzvgMfwzv0tW7ZY9erV/fGaUYPYUlDxWwN3NWxXF2E0hFYDRfMW0v/uOYC/w9kfAABAAZSxqQ6nvHSCSwEdAAAcKK0p1B2r/GZRAT3IeFaMi+aznHLKKfb+++/b0UcfbdFMGdXqvK9fv36+ornoc2Vbf/311z5sVEVTxXIgtoTvBN20aZOvyStUqGCVKlXynRq6f/DgwX77I4884gX0gppfKKBjf/CuAQAAiKCgDXtEuAAAgMKKNLywefPm9sUXX9jnn3/uXweFYw1JvPvuu23t2rVWtmxZX3+oQBit4uPj7aeffvKOdMnbiR5kpis7Picnx3Pjo/01QeQCumIX27VrZ61bt/Z5AYpdVDG9U6dONmzYMJsyZYr169fPH0vzC4oKRXQAAIAICjqBAwAAKIzw6IiPP/7Y56tkZmZ6l2zXrl1t8eLFNmrUKL9Pvv32W89tzs7ODnVmR/uFfA0M1euhyBp14OdtaFCszfr16y0hIcFn08TCa4Lcgv/rjh072ttvv20PPPCAjRkzxlatWuXDdjdv3uyFdGXr33ffffboo4/6QFGgqHA5BgAAAAAA4CAI4llk0KBBlpaW5l9rGGL79u1t5MiR9tJLL1mXLl18IKJuP/bYY73b+oMPPvDHxkJ+swaFpqam2q233urRNX369PF5NGpoyMrK8mGjKqQr7xrRLzzOZ8OGDf7+1/vio48+8kifuXPnWu3atf3ikwbvahfD+eef7xekqlWr5tEuikJq2bJlcf8qiCIMFgUAAAAAADiINOhQBfNZs2Z51+ztt9/un8+bN8/OO+88W716tQ8zV0a6ok2uu+46j6GIpWHmiuuYNGmSR3VUrlzZGjdu7BcQFNWhf9XBry708FgPRHcBXdEss2fPtk8//dSaNm3qx0arVq38+NBQWd3/zDPPWNWqVf040lDaOXPmWK1atULPFwsXoXBoUEQHAAAAAAA4CFRy0cc111xj5557rvXu3ds7z2+55RZ76KGHrFu3bh7boqJweEyJxGqxeMWKFV4Y1UWFGjVqeEe6Xie9FrF0USHW9erVy6ZNm2YpKSm2ZcsWmz9/vkcd6bi54IILvJiunQt6b3zzzTfWtm1bL7brtrFjxxb3j48oxF8eAAAAAACAIlBQ16viJlTkU+FP3dQ33nij5zWrG33Pnj2eA64uW3XShovFArqcccYZNm7cuHy366ICBfTYoLxzvQc0O0AXUkR5+IppUUFdxXRl5GswryjORY+bPn26x7gABwP7GQAAAAAAAIqACr0///yzDznU54qlKFOmjOc3X3XVVda6dWt7/PHHvYAuyvlWXEUwVBR/KCg0IVYvKsSa7du3+26NZs2a2bZt20K3t2nTxqpXr+5zA1Qw14e6znU8JSYm+nEWFNAJ3cDBQBEdAAAAAADgAGVkZFhycrIX8pTnfcUVV9jEiRP9voEDB3oBUMV0daKryPf999/bTTfd5N3oQVEdfwgysRF74uLibObMmVahQgXr37+/794Q5Z9ryOyVV17p0UcqnlesWNFmzJhhF198sf+bN1MdKEpkogMAAAAAABwAZXgPGTLErr32Wh+KqULg+PHjbevWrda1a1e7//77LT093YYOHWrfffed1a1b13JycrxbfcmSJQzMBPJQXMtdd91lRx99tFWqVMm709PS0uyiiy7K9TgdYyqmC0NEcTBRRAcAFKnJkydbz549fRvegVD3gLa2dujQoch+NgAAAKCoPfnkk17smzJlike2BANCVQQcPny4vfrqq1487969u8e8PPvss17sq1Klit1www0MzAQi0KDQpKQke+eddzwnXYN5g2G9eYvldKDjYOMvNAAgH2XLqQg+Z86c4v5RAAAAgMOW1ssqjqtLtl27dl4MF3WV16tXzwYPHmxffvml/ec///F4l2rVqlmfPn1yPQcDM4GC1a9f35544gnr0aOHLViwwAeJtmjRosBiOQV0HGzscQAAAAAAACikX375xd544w2rU6eOF8pFxfAglkWdsYptGTBggC1fvtw2bNhQ4PMQ4QJEpmNowoQJXiRXLvrChQuL+0dCjKKIDgAolJSUFEtISLBy5cr5RHR1BezatavArhx135QuXdqnpW/cuDHX/erWadq0qd+vEw9tcQ06dwAAAIDDnbKalYPetm1bmz59uo0cOTJUFFdcS+Dkk0+2o446yn766adi/GmBkkvnlWPGjLFt27bZhx9+WNw/DmIURXQAQKEoe27cuHG2evVqz31UJ0C/fv1yPWb37t2e/zh16lSfpq5omE6dOoXuX7x4sd18882WnJxsn3zyiedIKktd3wMAAACUFFWrVrV///vfdvbZZ/s8n6CQrjWzOtLlf//7n5155pnWqFGjYv5pgZJdSH/55Zetb9++xf2jIEYxWBQAcECZ6Onp6datWzefii4qhnfu3NmWLFli55xzjt+2du1aa9iwoS1dutSaNWtmrVq1spYtW/rW1oC6d1SMz8rK8q8ZLAoAAICS4uuvv/aGkA8++MCuvPJK69+/v9++c+dObyZRsX3ixInkNgNFgCGiKA5MrgAAFMqbb75pI0aM8ML4jh07PIIlOzvbu8/Lli0byoJUN06gQYMGFhcXZ2vWrPEi+sqVK71DPbzzXJ06eZ8HAAAAKAmqVKligwYN8vWtGkEU6aIBojfddJNt3rzZowxV9KP4Bxw4jiEUB+JcAAD7LDMz0zMfTzvtNHvhhRc8j+6xxx7z+/bs2bPPz6MMdWWgr1ixIvShba7r16/3jHQAAACgpBbS1TSiQnrlypW9iUTd6cHAUYp/AFAy0YkOANhnKpprSNKoUaM851HS0tLyPU7d6cuWLfMTCFm3bp3HwyjSRTRQVLfFx8cf4t8AAAAAOLiF9IEDB3qcy3HHHecd6KVKlfL1sQrpAICSib/gAIAC/fjjj94hHq5ixYqWk5Nj48ePt3bt2nkkS2pqar7v1YnCnXfe6QNIdbKQlJRkzZs3DxXVhwwZ4h3tNWvWtI4dO3pBXhEvq1atsmHDhh2y3xEAAAA4GIX0MWPGeBFd61wK6ABQ8hHnAgAo0KJFi6xJkya5PqZNm2YpKSk2cuRIa9y4sc2YMcPz0fNSprm6b66//npr0aKFlS9f3mbNmhW6PzEx0ebNm2cZGRmena4C++jRo61WrVqH+LcEAAAAit7xxx/vBXTt4qSADgAl3xF7NdUCAAAAAAAAAADkQyc6AAAAAAAAAAARUEQHAAAAAAAAACACiugAAAAAAAAAAERAER0AAAAAAAAAgAgoogMAAAAAAAAAEAFFdAAAAAAAAAAAIqCIDgAAAAAAUMJNnjzZ4uLiDvh5jjjiCJszZ06R/EwAEC0oogMAAAAAABwGbr31VuvQoUNx/xgAgDwoogMAAAAAAAAAEAFFdAAAAAAAgMNcSkqKJSQkWLly5axGjRrWo0cP27VrV77HKYqlXr16Vrp0aUtMTLSNGzfmuv+ll16ypk2b+v116tSxoUOH2q+//noIfxMAKHkoogMAAAAAABzm/vGPf9i4ceNs9erVNmXKFFu4cKH169cv12N2795tw4cPt6lTp9q7775r27dvt06dOoXuX7x4sd18882WnJxsn3zyiT355JOepa7vAQBEdsTevXv3/sX9AAAAAAAAOESZ6Cp878tgz/T0dOvWrZtt3brVv1YxvHPnzrZkyRI755xz/La1a9daw4YNbenSpdasWTNr1aqVtWzZ0gYMGBB6nunTp3sxPisrKzRYdPbs2WSzA0CYI8O/AAAAAAAAwOHnzTfftBEjRnhhfMeOHR7Bkp2d7d3nZcuW9ccceeSRdvbZZ4e+p0GDBhYXF2dr1qzxIvrKlSu9Qz288/y3337L9zwAgNwoogMAAAAAABzGMjMzrW3btta9e3cvgJ9wwgn2zjvvWJcuXWzPnj37XPxWhroy0P/1r3/lu08Z6QCAglFEBwAAAAAAOIx9+OGH9vvvv9uoUaM8G13S0tLyPU7d6cuWLfOuc1m3bp3HwyjSRTRQVLfFx8cf4t8AAEo2iugAAAAAAACHiR9//NFWrFiR67aKFStaTk6OjR8/3tq1a+eRLKmpqfm+t1SpUnbnnXf6AFJFuyQlJVnz5s1DRfUhQ4Z4R3vNmjWtY8eOXpBXxMuqVats2LBhh+x3BICS5o/LlwAAAAAAACh2ixYtsiZNmuT6mDZtmqWkpNjIkSOtcePGNmPGDM9Hz0uxLv3797frr7/eWrRoYeXLl7dZs2aF7k9MTLR58+ZZRkaGZ6erwD569GirVavWIf4tAaBkOWLv3r17i/uHAAAAAAAAAADgcEQnOgAAAAAAAAAAEVBEBwAAAAAAAAAgAoroAAAAAAAAAABEQBEdAAAAAAAAAIAIKKIDAAAAAAAAABABRXQAAAAAAAAAACKgiA4AAAAAAAAAQAQU0QEAAAAAAAAAiIAiOgAAAAAAAAAAEVBEBwAAAAAAAAAgAoroAAAAAAAAAABYwf4PeTbPocTVSVoAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 1500x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualize label distributions\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Clarity distribution\n",
        "clarity_counts = clarity_train_df['clarity_label'].value_counts()\n",
        "axes[0].bar(clarity_counts.index, clarity_counts.values, color='steelblue')\n",
        "axes[0].set_title('Task 1: Clarity Label Distribution (Train)', fontsize=12, fontweight='bold')\n",
        "axes[0].set_xlabel('Label')\n",
        "axes[0].set_ylabel('Count')\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "for i, v in enumerate(clarity_counts.values):\n",
        "    axes[0].text(i, v + 20, str(v), ha='center', fontweight='bold')\n",
        "\n",
        "# Evasion distribution\n",
        "evasion_counts = evasion_train_df['evasion_label'].value_counts()\n",
        "axes[1].bar(range(len(evasion_counts)), evasion_counts.values, color='coral')\n",
        "axes[1].set_title('Task 2: Evasion Label Distribution (Train)', fontsize=12, fontweight='bold')\n",
        "axes[1].set_xlabel('Label')\n",
        "axes[1].set_ylabel('Count')\n",
        "axes[1].set_xticks(range(len(evasion_counts)))\n",
        "axes[1].set_xticklabels(evasion_counts.index, rotation=45, ha='right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Dataset & DataLoader Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizer loaded: distilbert-base-uncased\n",
            "Vocabulary size: 30522\n"
          ]
        }
      ],
      "source": [
        "# Initialize tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "print(f\"Tokenizer loaded: {MODEL_NAME}\")\n",
        "print(f\"Vocabulary size: {len(tokenizer)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class QEvasionDataset(Dataset):\n",
        "    \"\"\"PyTorch Dataset for QEvasion tasks.\"\"\"\n",
        "    \n",
        "    def __init__(self, df, tokenizer, max_length, task='clarity'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            df: DataFrame with text and labels\n",
        "            tokenizer: HuggingFace tokenizer\n",
        "            max_length: Maximum sequence length\n",
        "            task: 'clarity', 'evasion', or 'multitask'\n",
        "        \"\"\"\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.task = task\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        text = row['text']\n",
        "        \n",
        "        # Tokenize\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        \n",
        "        item = {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0)\n",
        "        }\n",
        "        \n",
        "        # Add labels based on task\n",
        "        if self.task == 'clarity':\n",
        "            item['labels'] = torch.tensor(row['clarity_id'], dtype=torch.long)\n",
        "        elif self.task == 'evasion':\n",
        "            item['labels'] = torch.tensor(row['evasion_id'], dtype=torch.long)\n",
        "        elif self.task == 'multitask':\n",
        "            item['clarity_labels'] = torch.tensor(row['clarity_id'], dtype=torch.long)\n",
        "            if 'evasion_id' in row and row['evasion_id'] != -1:\n",
        "                item['evasion_labels'] = torch.tensor(row['evasion_id'], dtype=torch.long)\n",
        "                item['evasion_mask'] = torch.tensor(1, dtype=torch.long)\n",
        "            else:\n",
        "                item['evasion_labels'] = torch.tensor(-1, dtype=torch.long)\n",
        "                item['evasion_mask'] = torch.tensor(0, dtype=torch.long)\n",
        "        \n",
        "        return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task 1 DataLoaders created:\n",
            "  Train batches: 194\n",
            "  Val batches: 22\n",
            "  Test batches: 20\n"
          ]
        }
      ],
      "source": [
        "# Create DataLoaders for Task 1 (Clarity)\n",
        "clarity_train_dataset = QEvasionDataset(clarity_train_df, tokenizer, MAX_LENGTH, task='clarity')\n",
        "clarity_val_dataset = QEvasionDataset(clarity_val_df, tokenizer, MAX_LENGTH, task='clarity')\n",
        "clarity_test_dataset = QEvasionDataset(clarity_test_df, tokenizer, MAX_LENGTH, task='clarity')\n",
        "\n",
        "clarity_train_loader = DataLoader(clarity_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "clarity_val_loader = DataLoader(clarity_val_dataset, batch_size=BATCH_SIZE)\n",
        "clarity_test_loader = DataLoader(clarity_test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "print(\"Task 1 DataLoaders created:\")\n",
        "print(f\"  Train batches: {len(clarity_train_loader)}\")\n",
        "print(f\"  Val batches: {len(clarity_val_loader)}\")\n",
        "print(f\"  Test batches: {len(clarity_test_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task 2 DataLoaders created:\n",
            "  Train batches: 194\n",
            "  Val batches: 22\n"
          ]
        }
      ],
      "source": [
        "# Create DataLoaders for Task 2 (Evasion)\n",
        "evasion_train_dataset = QEvasionDataset(evasion_train_df, tokenizer, MAX_LENGTH, task='evasion')\n",
        "evasion_val_dataset = QEvasionDataset(evasion_val_df, tokenizer, MAX_LENGTH, task='evasion')\n",
        "\n",
        "evasion_train_loader = DataLoader(evasion_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "evasion_val_loader = DataLoader(evasion_val_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "print(\"Task 2 DataLoaders created:\")\n",
        "print(f\"  Train batches: {len(evasion_train_loader)}\")\n",
        "print(f\"  Val batches: {len(evasion_val_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Task 1: Clarity Classification\n",
        "\n",
        "Train a transformer model to classify political responses into 3 clarity levels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TRAINING TASK 1: CLARITY CLASSIFICATION\n",
            "============================================================\n",
            "Model: distilbert-base-uncased\n",
            "Parameters: 66,955,779\n",
            "Trainable: 66,955,779\n"
          ]
        }
      ],
      "source": [
        "# Initialize Task 1 model\n",
        "clarity_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=len(CLARITY_LABELS),\n",
        "    id2label=ID_TO_CLARITY,\n",
        "    label2id=CLARITY_TO_ID\n",
        ").to(device)\n",
        "\n",
        "# Setup optimizer and loss\n",
        "clarity_optimizer = torch.optim.AdamW(clarity_model.parameters(), lr=LEARNING_RATE)\n",
        "clarity_loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Early stopping\n",
        "clarity_early_stopping = EarlyStopping(patience=PATIENCE, mode='max', verbose=True)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"TRAINING TASK 1: CLARITY CLASSIFICATION\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Model: {MODEL_NAME}\")\n",
        "print(f\"Parameters: {sum(p.numel() for p in clarity_model.parameters()):,}\")\n",
        "print(f\"Trainable: {sum(p.numel() for p in clarity_model.parameters() if p.requires_grad):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/10\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Train Task 1\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m clarity_history = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclarity_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclarity_train_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclarity_val_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclarity_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclarity_loss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclarity_loss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevasion_loss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclarity_loss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Reuse for single-task\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclarity_early_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_multitask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minhn\\Documents\\GitHub\\Poly\\political-evasion-classifier\\src\\training.py:372\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, optimizer, scheduler, clarity_loss_fn, evasion_loss_fn, device, num_epochs, early_stopping, verbose, is_multitask)\u001b[39m\n\u001b[32m    369\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m60\u001b[39m)\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m train_metrics = \u001b[43mtrain_epoch_improved\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclarity_loss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevasion_loss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[38;5;66;03m# Validation\u001b[39;00m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_multitask:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minhn\\Documents\\GitHub\\Poly\\political-evasion-classifier\\src\\training.py:163\u001b[39m, in \u001b[36mtrain_epoch_improved\u001b[39m\u001b[34m(model, loader, optimizer, scheduler, clarity_loss_fn, evasion_loss_fn, device, max_grad_norm)\u001b[39m\n\u001b[32m    160\u001b[39m     total_clarity_loss += loss_clarity.item()\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# Single-task model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclarity_labels\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m     loss = outputs.loss\n\u001b[32m    170\u001b[39m \u001b[38;5;66;03m# Backward pass with gradient clipping\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minhn\\anaconda3\\envs\\venv-llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minhn\\anaconda3\\envs\\venv-llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minhn\\anaconda3\\envs\\venv-llm\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:905\u001b[39m, in \u001b[36mDistilBertForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    897\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    898\u001b[39m \u001b[33;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[32m    899\u001b[39m \u001b[33;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[32m    900\u001b[39m \u001b[33;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[32m    901\u001b[39m \u001b[33;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[32m    902\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    903\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m--> \u001b[39m\u001b[32m905\u001b[39m distilbert_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdistilbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    910\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    911\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    912\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    913\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    914\u001b[39m hidden_state = distilbert_output[\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[32m    915\u001b[39m pooled_output = hidden_state[:, \u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minhn\\anaconda3\\envs\\venv-llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minhn\\anaconda3\\envs\\venv-llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minhn\\anaconda3\\envs\\venv-llm\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:724\u001b[39m, in \u001b[36mDistilBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config._attn_implementation == \u001b[33m\"\u001b[39m\u001b[33msdpa\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m head_mask_is_none \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m output_attentions:\n\u001b[32m    720\u001b[39m         attention_mask = _prepare_4d_attention_mask_for_sdpa(\n\u001b[32m    721\u001b[39m             attention_mask, embeddings.dtype, tgt_len=input_shape[\u001b[32m1\u001b[39m]\n\u001b[32m    722\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m724\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    727\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minhn\\anaconda3\\envs\\venv-llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minhn\\anaconda3\\envs\\venv-llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minhn\\anaconda3\\envs\\venv-llm\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:531\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m    529\u001b[39m     all_hidden_states = all_hidden_states + (hidden_state,)\n\u001b[32m--> \u001b[39m\u001b[32m531\u001b[39m layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    538\u001b[39m hidden_state = layer_outputs[-\u001b[32m1\u001b[39m]\n\u001b[32m    540\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minhn\\anaconda3\\envs\\venv-llm\\Lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minhn\\anaconda3\\envs\\venv-llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minhn\\anaconda3\\envs\\venv-llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minhn\\anaconda3\\envs\\venv-llm\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:484\u001b[39m, in \u001b[36mTransformerBlock.forward\u001b[39m\u001b[34m(self, x, attn_mask, head_mask, output_attentions)\u001b[39m\n\u001b[32m    481\u001b[39m sa_output = \u001b[38;5;28mself\u001b[39m.sa_layer_norm(sa_output + x)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# Feed Forward Network\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m ffn_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mffn\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa_output\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[32m    485\u001b[39m ffn_output: torch.Tensor = \u001b[38;5;28mself\u001b[39m.output_layer_norm(ffn_output + sa_output)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[32m    487\u001b[39m output = (ffn_output,)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minhn\\anaconda3\\envs\\venv-llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minhn\\anaconda3\\envs\\venv-llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minhn\\anaconda3\\envs\\venv-llm\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:418\u001b[39m, in \u001b[36mFFN.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: torch.Tensor) -> torch.Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mff_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minhn\\anaconda3\\envs\\venv-llm\\Lib\\site-packages\\transformers\\pytorch_utils.py:257\u001b[39m, in \u001b[36mapply_chunking_to_forward\u001b[39m\u001b[34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[39m\n\u001b[32m    254\u001b[39m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(output_chunks, dim=chunk_dim)\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minhn\\anaconda3\\envs\\venv-llm\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:423\u001b[39m, in \u001b[36mFFN.ff_chunk\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    421\u001b[39m x = \u001b[38;5;28mself\u001b[39m.lin1(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m    422\u001b[39m x = \u001b[38;5;28mself\u001b[39m.activation(x)\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlin2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    424\u001b[39m x = \u001b[38;5;28mself\u001b[39m.dropout(x)\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minhn\\anaconda3\\envs\\venv-llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minhn\\anaconda3\\envs\\venv-llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minhn\\anaconda3\\envs\\venv-llm\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Train Task 1\n",
        "clarity_history = train_model(\n",
        "    model=clarity_model,\n",
        "    train_loader=clarity_train_loader,\n",
        "    val_loader=clarity_val_loader,\n",
        "    optimizer=clarity_optimizer,\n",
        "    scheduler=None,\n",
        "    clarity_loss_fn=clarity_loss_fn,\n",
        "    evasion_loss_fn=clarity_loss_fn,  # Reuse for single-task\n",
        "    device=device,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    early_stopping=clarity_early_stopping,\n",
        "    verbose=True,\n",
        "    is_multitask=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate Task 1 on test set\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"TASK 1: TEST SET EVALUATION\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "test_metrics, test_preds, test_labels, test_logits = evaluate(\n",
        "    clarity_model, clarity_test_loader, device, return_predictions=True\n",
        ")\n",
        "\n",
        "# Comprehensive metrics\n",
        "evaluate_task1(\n",
        "    y_true=test_labels,\n",
        "    y_pred=test_preds,\n",
        "    label_names=CLARITY_LABELS,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion matrix for Task 1\n",
        "plot_confusion_matrix(\n",
        "    y_true=test_labels,\n",
        "    y_pred=test_preds,\n",
        "    label_names=CLARITY_LABELS,\n",
        "    title=\"Task 1: Clarity Classification - Confusion Matrix\",\n",
        "    figsize=(8, 6)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Per-class metrics\n",
        "per_class_df = compute_per_class_metrics(test_labels, test_preds, CLARITY_LABELS)\n",
        "print(\"\\nPer-Class Performance:\")\n",
        "print(per_class_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Task 2: Evasion Classification\n",
        "\n",
        "Train a transformer model to classify evasion types (9 classes).\n",
        "\n",
        "**Note:** Test evaluation uses multi-annotator agreement - a prediction is correct if it matches ANY annotator label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Task 2 model\n",
        "evasion_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=len(EVASION_LABELS),\n",
        "    id2label=ID_TO_EVASION,\n",
        "    label2id=EVASION_TO_ID\n",
        ").to(device)\n",
        "\n",
        "# Setup optimizer and loss (use Focal Loss for imbalanced classes)\n",
        "evasion_optimizer = torch.optim.AdamW(evasion_model.parameters(), lr=LEARNING_RATE)\n",
        "evasion_loss_fn = FocalLoss(gamma=2.0)  # Helps with class imbalance\n",
        "\n",
        "# Early stopping\n",
        "evasion_early_stopping = EarlyStopping(patience=PATIENCE, mode='max', verbose=True)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"TRAINING TASK 2: EVASION CLASSIFICATION\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Model: {MODEL_NAME}\")\n",
        "print(f\"Loss Function: Focal Loss (gamma=2.0) - helps with class imbalance\")\n",
        "print(f\"Parameters: {sum(p.numel() for p in evasion_model.parameters()):,}\")\n",
        "print(f\"Trainable: {sum(p.numel() for p in evasion_model.parameters() if p.requires_grad):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Task 2\n",
        "evasion_history = train_model(\n",
        "    model=evasion_model,\n",
        "    train_loader=evasion_train_loader,\n",
        "    val_loader=evasion_val_loader,\n",
        "    optimizer=evasion_optimizer,\n",
        "    scheduler=None,\n",
        "    clarity_loss_fn=evasion_loss_fn,\n",
        "    evasion_loss_fn=evasion_loss_fn,\n",
        "    device=device,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    early_stopping=evasion_early_stopping,\n",
        "    verbose=True,\n",
        "    is_multitask=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate Task 2 on validation set (standard single-label)\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"TASK 2: VALIDATION SET EVALUATION\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "val_metrics, val_preds, val_labels, _ = evaluate(\n",
        "    evasion_model, evasion_val_loader, device, return_predictions=True\n",
        ")\n",
        "\n",
        "evaluate_task2_standard(\n",
        "    y_true=val_labels,\n",
        "    y_pred=val_preds,\n",
        "    label_names=EVASION_LABELS,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 2: Test Set Evaluation (Multi-Annotator)\n",
        "\n",
        "The test set uses 3 annotators. A prediction is correct if it matches **ANY** annotator's label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare test data for evasion (only examples with annotator labels)\n",
        "test_evasion_with_labels = evasion_test_df[\n",
        "    evasion_test_df['annotator_labels'].apply(len) > 0\n",
        "].reset_index(drop=True)\n",
        "\n",
        "print(f\"Test examples with annotator labels: {len(test_evasion_with_labels)}\")\n",
        "print(f\"Total test examples: {len(evasion_test_df)}\")\n",
        "\n",
        "# Create test dataset (use dummy labels since we'll compare to annotator sets)\n",
        "test_evasion_dataset = QEvasionDataset(\n",
        "    test_evasion_with_labels.assign(evasion_id=0),  # Dummy label\n",
        "    tokenizer,\n",
        "    MAX_LENGTH,\n",
        "    task='evasion'\n",
        ")\n",
        "test_evasion_loader = DataLoader(test_evasion_dataset, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get predictions from model\n",
        "evasion_model.eval()\n",
        "test_pred_ids = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_evasion_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        \n",
        "        outputs = evasion_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        preds = torch.argmax(outputs.logits, dim=-1)\n",
        "        test_pred_ids.extend(preds.cpu().numpy())\n",
        "\n",
        "# Convert predictions to label strings\n",
        "test_pred_labels = [ID_TO_EVASION[pred_id] for pred_id in test_pred_ids]\n",
        "\n",
        "# Get gold label sets (from annotators)\n",
        "gold_label_sets = test_evasion_with_labels['annotator_labels'].tolist()\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"TASK 2: TEST SET EVALUATION (MULTI-ANNOTATOR)\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "# Evaluate with multi-annotator metric\n",
        "task2_test_metrics = evaluate_task2_multi_annotator(\n",
        "    y_pred=test_pred_labels,\n",
        "    gold_sets=gold_label_sets,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze prediction distribution\n",
        "pred_dist = pd.Series(test_pred_labels).value_counts()\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.bar(range(len(pred_dist)), pred_dist.values, color='coral')\n",
        "plt.title('Task 2: Prediction Distribution on Test Set', fontsize=12, fontweight='bold')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(range(len(pred_dist)), pred_dist.index, rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nTest Set Prediction Counts:\")\n",
        "print(pred_dist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Multi-Task Learning\n",
        "\n",
        "Train a single model that learns both clarity and evasion classification simultaneously."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create multi-task datasets\n",
        "mt_train_dataset = QEvasionDataset(clarity_train_df, tokenizer, MAX_LENGTH, task='multitask')\n",
        "mt_val_dataset = QEvasionDataset(clarity_val_df, tokenizer, MAX_LENGTH, task='multitask')\n",
        "\n",
        "mt_train_loader = DataLoader(mt_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "mt_val_loader = DataLoader(mt_val_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "print(\"Multi-Task DataLoaders created:\")\n",
        "print(f\"  Train batches: {len(mt_train_loader)}\")\n",
        "print(f\"  Val batches: {len(mt_val_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize multi-task model\n",
        "mt_model = MultiTaskTransformer(\n",
        "    model_name=MODEL_NAME,\n",
        "    num_clarity_labels=len(CLARITY_LABELS),\n",
        "    num_evasion_labels=len(EVASION_LABELS),\n",
        "    dropout_rate=0.1\n",
        ").to(device)\n",
        "\n",
        "# Setup optimizer and losses\n",
        "mt_optimizer = torch.optim.AdamW(mt_model.parameters(), lr=LEARNING_RATE)\n",
        "mt_clarity_loss = nn.CrossEntropyLoss()\n",
        "mt_evasion_loss = FocalLoss(gamma=2.0)  # Handle imbalance in evasion task\n",
        "\n",
        "# Early stopping\n",
        "mt_early_stopping = EarlyStopping(patience=PATIENCE, mode='max', verbose=True)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"TRAINING MULTI-TASK MODEL\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Model: {MODEL_NAME} (shared encoder)\")\n",
        "print(f\"Clarity Head: {len(CLARITY_LABELS)} classes\")\n",
        "print(f\"Evasion Head: {len(EVASION_LABELS)} classes\")\n",
        "print(f\"Total Parameters: {sum(p.numel() for p in mt_model.parameters()):,}\")\n",
        "print(f\"Trainable: {sum(p.numel() for p in mt_model.parameters() if p.requires_grad):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train multi-task model\n",
        "mt_history = train_model(\n",
        "    model=mt_model,\n",
        "    train_loader=mt_train_loader,\n",
        "    val_loader=mt_val_loader,\n",
        "    optimizer=mt_optimizer,\n",
        "    scheduler=None,\n",
        "    clarity_loss_fn=mt_clarity_loss,\n",
        "    evasion_loss_fn=mt_evasion_loss,\n",
        "    device=device,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    early_stopping=mt_early_stopping,\n",
        "    verbose=True,\n",
        "    is_multitask=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate multi-task model\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"MULTI-TASK MODEL: VALIDATION EVALUATION\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "mt_val_metrics = evaluate_multitask(mt_model, mt_val_loader, device)\n",
        "\n",
        "print(\"Clarity Task:\")\n",
        "print(f\"  Accuracy: {mt_val_metrics['clarity_accuracy']:.4f}\")\n",
        "print(f\"  Macro F1: {mt_val_metrics['clarity_macro_f1']:.4f}\")\n",
        "print(f\"  Weighted F1: {mt_val_metrics['clarity_weighted_f1']:.4f}\")\n",
        "\n",
        "if 'evasion_accuracy' in mt_val_metrics:\n",
        "    print(\"\\nEvasion Task:\")\n",
        "    print(f\"  Accuracy: {mt_val_metrics['evasion_accuracy']:.4f}\")\n",
        "    print(f\"  Macro F1: {mt_val_metrics['evasion_macro_f1']:.4f}\")\n",
        "    print(f\"  Weighted F1: {mt_val_metrics['evasion_weighted_f1']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Training History Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training histories\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "\n",
        "histories = [\n",
        "    (clarity_history, 'Task 1: Clarity', 'steelblue'),\n",
        "    (evasion_history, 'Task 2: Evasion', 'coral'),\n",
        "    (mt_history, 'Multi-Task', 'green')\n",
        "]\n",
        "\n",
        "for idx, (history, title, color) in enumerate(histories):\n",
        "    epochs = range(1, len(history['train_loss']) + 1)\n",
        "    \n",
        "    # Loss plot\n",
        "    axes[0, idx].plot(epochs, history['train_loss'], color=color, linewidth=2)\n",
        "    axes[0, idx].set_title(f'{title}: Training Loss', fontweight='bold')\n",
        "    axes[0, idx].set_xlabel('Epoch')\n",
        "    axes[0, idx].set_ylabel('Loss')\n",
        "    axes[0, idx].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Metrics plot\n",
        "    axes[1, idx].plot(epochs, history['val_accuracy'], label='Accuracy', color=color, linewidth=2)\n",
        "    axes[1, idx].plot(epochs, history['val_macro_f1'], label='Macro F1', color=color, \n",
        "                     linestyle='--', linewidth=2)\n",
        "    axes[1, idx].set_title(f'{title}: Validation Metrics', fontweight='bold')\n",
        "    axes[1, idx].set_xlabel('Epoch')\n",
        "    axes[1, idx].set_ylabel('Score')\n",
        "    axes[1, idx].legend()\n",
        "    axes[1, idx].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Final Results Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FINAL RESULTS SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\n📊 TASK 1: CLARITY CLASSIFICATION (Test Set)\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"  Accuracy:     {test_metrics['accuracy']:.4f}\")\n",
        "print(f\"  Macro F1:     {test_metrics['macro_f1']:.4f}\")\n",
        "print(f\"  Weighted F1:  {test_metrics['weighted_f1']:.4f}\")\n",
        "print(f\"  Baseline:     {majority_baseline_accuracy(clarity_train_df['clarity_id'].values, clarity_test_df['clarity_id'].values):.4f}\")\n",
        "\n",
        "print(\"\\n📊 TASK 2: EVASION CLASSIFICATION (Test Set, Multi-Annotator)\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"  Accuracy (any annotator): {task2_test_metrics['accuracy_any_annotator']:.4f}\")\n",
        "print(f\"  Test examples:            {len(test_evasion_with_labels)}\")\n",
        "\n",
        "print(\"\\n📊 MULTI-TASK MODEL (Validation Set)\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"  Clarity Accuracy:  {mt_val_metrics['clarity_accuracy']:.4f}\")\n",
        "print(f\"  Clarity Macro F1:  {mt_val_metrics['clarity_macro_f1']:.4f}\")\n",
        "if 'evasion_accuracy' in mt_val_metrics:\n",
        "    print(f\"  Evasion Accuracy:  {mt_val_metrics['evasion_accuracy']:.4f}\")\n",
        "    print(f\"  Evasion Macro F1:  {mt_val_metrics['evasion_macro_f1']:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ Challenge Complete!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Model Comparison\n",
        "\n",
        "Compare single-task vs multi-task approaches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison DataFrame\n",
        "comparison_data = {\n",
        "    'Model': ['Task 1 (Single)', 'Task 2 (Single)', 'Multi-Task'],\n",
        "    'Clarity Acc': [\n",
        "        test_metrics['accuracy'],\n",
        "        '-',\n",
        "        mt_val_metrics['clarity_accuracy']\n",
        "    ],\n",
        "    'Clarity F1': [\n",
        "        test_metrics['macro_f1'],\n",
        "        '-',\n",
        "        mt_val_metrics['clarity_macro_f1']\n",
        "    ],\n",
        "    'Evasion Acc': [\n",
        "        '-',\n",
        "        task2_test_metrics['accuracy_any_annotator'],\n",
        "        mt_val_metrics.get('evasion_accuracy', '-')\n",
        "    ],\n",
        "    'Parameters': [\n",
        "        f\"{sum(p.numel() for p in clarity_model.parameters()):,}\",\n",
        "        f\"{sum(p.numel() for p in evasion_model.parameters()):,}\",\n",
        "        f\"{sum(p.numel() for p in mt_model.parameters()):,}\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "print(\"\\nModel Comparison:\")\n",
        "print(comparison_df.to_string(index=False))\n",
        "\n",
        "print(\"\\n💡 Insights:\")\n",
        "print(\"  - Multi-task model uses fewer total parameters than 2 separate models\")\n",
        "print(\"  - Multi-task learning can provide regularization and shared representations\")\n",
        "print(\"  - Consider multi-task when tasks are related (as clarity and evasion are)\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv-llm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
