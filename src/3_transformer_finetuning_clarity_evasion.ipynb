{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dd89632c",
      "metadata": {
        "id": "dd89632c"
      },
      "source": [
        "# QEvasion – Transformer Fine-tuning (Clarity & Evasion)\n",
        "\n",
        "In this notebook we fine-tune a pretrained transformer encoder on the QEvasion dataset\n",
        "for the two main tasks:\n",
        "\n",
        "- **Task 1 – Clarity-level classification (3-way)**  \n",
        "  Labels: `clarity_label` → `clarity_id`\n",
        "\n",
        "- **Task 2 – Evasion-level classification (9-way)**  \n",
        "  Labels: `evasion_label` → `evasion_id` (on the train split)  \n",
        "  + special **test evaluation** using annotators (`annotator1/2/3`).\n",
        "\n",
        "We:\n",
        "1. Load and preprocess the data.\n",
        "2. Create train/validation/test splits.\n",
        "3. Tokenize question–answer pairs with a pretrained tokenizer.\n",
        "4. Fine-tune a transformer with a **manual PyTorch loop** (no `Trainer`).\n",
        "5. Evaluate Task 1 on the official test split.\n",
        "6. Train and evaluate Task 2, including test evaluation using annotators.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m4UxZUxGhDNj",
      "metadata": {
        "id": "m4UxZUxGhDNj"
      },
      "outputs": [],
      "source": [
        "#!pip install -q \"transformers==4.45.2\" \"datasets>=2.19\" sentencepiece safetensors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ShQ37qOL-n1Y",
      "metadata": {
        "id": "ShQ37qOL-n1Y"
      },
      "source": [
        "## 1. Imports & device\n",
        "\n",
        "We import:\n",
        "- `datasets.load_dataset` to fetch QEvasion.\n",
        "- `transformers` for tokenizer and model.\n",
        "- `sklearn` for splits and metrics.\n",
        "- `torch` for manual training.\n",
        "\n",
        "We also detect whether a GPU is available.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MB4L2yr4-nNx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MB4L2yr4-nNx",
        "outputId": "06f9141e-897b-45f8-cd28-fb0a625489aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iD0IZWC8-s78",
      "metadata": {
        "id": "iD0IZWC8-s78"
      },
      "source": [
        "## 2. Load QEvasion & build the input text\n",
        "\n",
        "We:\n",
        "- Load the `ailsntua/QEvasion` dataset.\n",
        "- Convert `train` and `test` splits to pandas.\n",
        "- Build a single `text` column per example:\n",
        "\n",
        "> `\"Question: <question> [SEP] Answer: <answer>\"`\n",
        "\n",
        "This is what the model will see.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xkmuMzytip18",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "xkmuMzytip18",
        "outputId": "8c5ed6ea-23b2-4980-e1db-940e54069cff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (3448, 21)\n",
            "Test  shape: (308, 21)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"train_df[[\\\"text\\\", \\\"clarity_label\\\", \\\"evasion_label\\\"]]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Question: Q. Of the Biden administration. And accused the United States of containing China while pushing for diplomatic talks.How would you respond to that? And do you think President Xi is being sincere about getting the relationship back on track as he bans Apple in China? [SEP] Answer: Well, look, first of all, theI am sincere about getting the relationship right. And one of the things that is going on now is, China is beginning to change some of the rules of the game, in terms of trade and other issues.And so one of the things we talked about, for example, is that they're now talking about making sure that no Chineseno one in the Chinese Government can use a Western cell phone. Those kinds of things.And so, really, what this trip was aboutit was less about containing China. I don't want to contain China. I just want to make sure that we have a relationship with China that is on the up and up, squared away, everybody knows what it's all about. And one of the ways you do that is, you make sure that we are talking about the same things.And I think that one of the things we've doneI've tried to do, and I've talked with a number of my staff about this for the last, I guess, 6 monthsis, we have an opportunity to strengthen alliances around the world to maintain stability.That's what this trip was all about: having India cooperate much more with the United States, be closer with the United States, Vietnam being closer with the United States. It's not about containing China; it's about having a stable base, a stable base in the Indo-Pacific.And it'sfor example, when I was spending a lot of time talking with President Xi, he asked why we were doingwhy was I going to have the Quad, meaning Australia, India, Japan, and the United States? And I said, To maintain stability. It's not about isolating China. It's about making sure the rules of the roadeverything from airspace and space in the ocean isthe international rules of the road are abided by.And soand I hope thatI think that Prime Minister XiI mean, Xi has somesome difficulties right now. All countries end up with difficulties, and he had some economic difficulties he's working his way through. I want to see China succeed economically, but I want to see them succeed by the rules.The next question was to Bloomberg.\",\n          \"Question: Q. No worries. Do you believe the country's slowdown and growth could risk destabilizing the global economy or cause China to be more aggressive defensively, including with Taiwan?And separately, sir, are you worried about the meeting between President Putin and Kim Jong Un, if that could mean Russia has more gains in the war in Ukraine? [SEP] Answer: Look, I think China has a difficult economic problem right now for a whole range of reasons that relate to the international growth and lack thereof and the policies that China has followed.And so I don't think it's going to cause China to invade Taiwan. And matter of fact, the opposite: It probably doesn't have the same capacity that it had before.But as I said, I'm notwe're not looking to hurt China, sincerely. We're all better off if China does well, if China does well by the international rules. It grows the economy.But they have had some real difficulty in terms of their economy of late, particularly in real estate. Asidethat end of their bargain. And I think the actions that they're going to have to take are ones that arethey're in the process of deciding right now. And I'm not going to predict what way it will come out. But we're not looking to decouple from China.What I'm not going to do is, I'm not going to sell China material that would enhance their capacity to make more nuclear weapons, to engage in defense activities that are contrary to what is viewed as most people would think was a positive development in the region.Andbut we're not trying to hurt China.Okay. Let'sBBC. Laura. Am I correct? Is that correctLaura?\",\n          \"Question: Q. I can imagine. It is evening, I'd like to remind you. [Laughter]I mean, in the last 6 months, you've signed pacts and deals with Japan, South Korea, Philippines, Australia, and even the Pacific Islands. You're here, standing in Beijing's backyard. Now, China says this is part of your cold war mentality. Are they right, sir? Are they right, Mr. President? Is it a danger of a cold war? And when will you meet Mr. Xi? [SEP] Answer: Well, I hope I get to see Mr. Xi sooner than later. I've spent more time with him than any other world leader has, sum total, over the last 12 years. So I hope we get to see him again soon.But no, lookfor example, one of the things we did in India: We provided for a new path that's going to save everybody money, increase the Third Worldthe Third Worldthe Global South's capacity to grow by sendingwe're going tofromwe're going to have a new railroad from India all the way across to the Mediterranean, new shipping lanes and pipelines across the Mediterranean through Europe, up into Great Britain and beyond.That's all about economic growth. That has nothing to do with hurting China or helping China. It has to do with dealing with everything from climate change to making sure that these countries can succeed economically and grow.Look, my thesis has been, from the beginning, both domestically and in terms of foreign policy: Invest in your people. Invest in the people. Give them a chance.Everything is better off when peopleI know it's going to sound trite. If everybody in the world had a job they get up in the morning and wanted to go to and thought theyand they could put three squares in the table for their family, no matter where they live, the whole world be better off. We'd be a lot better. That's the notion here behind this.For example, you know, one of the things we're doing in terms ofI proposed a long time ago at the G-7, now it'sthat's going to come to fruition at the G-20, is making sure that we build a railroad all the way across the African Continent. Think about it. There is no way to cross the African Continent by roadby rail. And there's not even a direct highway across.Now, let's assume for the sake of discussionwhen we talk about food shortagesassume there was one country in that vast continent that had aan excess of foodstuffs and resources. How would they get it to where they're going to go? How are they going to do it?That's why we're also going to invest billions of dollars in solar facilities in Angola to have the largestthe largest solar facility in the worldamong the largest. That helps Angola, but it also helps the whole region.So I think we think too much in terms of cold war terms. It's not about that. It's about generating economic growth and stability in all parts of the world. And that's what we're trying to do.Sorry. Okay. Am I pronouncing itAuvelia [Aurelia; White House correction]? Did I pronounce the name correctly? There you are.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clarity_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Ambivalent\",\n          \"Clear Reply\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"evasion_label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"General\",\n          \"Dodging\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-745a39d9-77d2-49ae-ab8e-71c02e1fc80d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>clarity_label</th>\n",
              "      <th>evasion_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Question: Q. Of the Biden administration. And ...</td>\n",
              "      <td>Clear Reply</td>\n",
              "      <td>Explicit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Question: Q. Of the Biden administration. And ...</td>\n",
              "      <td>Ambivalent</td>\n",
              "      <td>General</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Question: Q. No worries. Do you believe the co...</td>\n",
              "      <td>Ambivalent</td>\n",
              "      <td>Partial/half-answer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Question: Q. No worries. Do you believe the co...</td>\n",
              "      <td>Ambivalent</td>\n",
              "      <td>Dodging</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Question: Q. I can imagine. It is evening, I'd...</td>\n",
              "      <td>Clear Reply</td>\n",
              "      <td>Explicit</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-745a39d9-77d2-49ae-ab8e-71c02e1fc80d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-745a39d9-77d2-49ae-ab8e-71c02e1fc80d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-745a39d9-77d2-49ae-ab8e-71c02e1fc80d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9de294c1-0051-4c6c-a824-a9df4f03968e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9de294c1-0051-4c6c-a824-a9df4f03968e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9de294c1-0051-4c6c-a824-a9df4f03968e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                text clarity_label  \\\n",
              "0  Question: Q. Of the Biden administration. And ...   Clear Reply   \n",
              "1  Question: Q. Of the Biden administration. And ...    Ambivalent   \n",
              "2  Question: Q. No worries. Do you believe the co...    Ambivalent   \n",
              "3  Question: Q. No worries. Do you believe the co...    Ambivalent   \n",
              "4  Question: Q. I can imagine. It is evening, I'd...   Clear Reply   \n",
              "\n",
              "         evasion_label  \n",
              "0             Explicit  \n",
              "1              General  \n",
              "2  Partial/half-answer  \n",
              "3              Dodging  \n",
              "4             Explicit  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = load_dataset(\"ailsntua/QEvasion\")\n",
        "\n",
        "train_df = dataset[\"train\"].to_pandas()\n",
        "test_df  = dataset[\"test\"].to_pandas()\n",
        "\n",
        "def build_text_column(df):\n",
        "    df = df.copy()\n",
        "    q = df[\"interview_question\"].fillna(\"\")\n",
        "    a = df[\"interview_answer\"].fillna(\"\")\n",
        "    df[\"text\"] = \"Question: \" + q + \" [SEP] Answer: \" + a\n",
        "    return df\n",
        "\n",
        "train_df = build_text_column(train_df)\n",
        "test_df  = build_text_column(test_df)\n",
        "\n",
        "print(\"Train shape:\", train_df.shape)\n",
        "print(\"Test  shape:\", test_df.shape)\n",
        "train_df[[\"text\", \"clarity_label\", \"evasion_label\"]].head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "axTV1nQ2-z2z",
      "metadata": {
        "id": "axTV1nQ2-z2z"
      },
      "source": [
        "## 3. Encode labels & create splits\n",
        "\n",
        "We create integer labels:\n",
        "\n",
        "- **Clarity (Task 1)**: `clarity_label` → `clarity_id` in `{0,1,2}`.\n",
        "- **Evasion (Task 2)**: `evasion_label` → `evasion_id` in `{0,…,8}` for train,\n",
        "  and `-1` when no evasion label is given.\n",
        "\n",
        "Then:\n",
        "\n",
        "- For clarity:\n",
        "  - `clar_train_df` / `clar_val_df` come from the train split (90/10, stratified).\n",
        "  - `clar_test_df` is the official test split.\n",
        "- For evasion:\n",
        "  - we keep only rows with `evasion_id != -1`,\n",
        "  - then split them into `ev_train_df` / `ev_val_df` (90/10, stratified).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zuohvZDYlGa8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "zuohvZDYlGa8",
        "outputId": "a4c21a3f-0547-4057-b966-0c38a1d90152"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clarity mapping: {'Ambivalent': 0, 'Clear Non-Reply': 1, 'Clear Reply': 2}\n",
            "Evasion mapping: {'Claims ignorance': 0, 'Clarification': 1, 'Declining to answer': 2, 'Deflection': 3, 'Dodging': 4, 'Explicit': 5, 'General': 6, 'Implicit': 7, 'Partial/half-answer': 8}\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"train_df[[\\\"clarity_label\\\", \\\"clarity_id\\\", \\\"evasion_label\\\", \\\"evasion_id\\\"]]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"clarity_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Ambivalent\",\n          \"Clear Reply\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clarity_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"evasion_label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"General\",\n          \"Dodging\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"evasion_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 4,\n        \"max\": 8,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          6,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-244fe9cb-0d42-420f-bcf0-88475567966a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clarity_label</th>\n",
              "      <th>clarity_id</th>\n",
              "      <th>evasion_label</th>\n",
              "      <th>evasion_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Clear Reply</td>\n",
              "      <td>2</td>\n",
              "      <td>Explicit</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ambivalent</td>\n",
              "      <td>0</td>\n",
              "      <td>General</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ambivalent</td>\n",
              "      <td>0</td>\n",
              "      <td>Partial/half-answer</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ambivalent</td>\n",
              "      <td>0</td>\n",
              "      <td>Dodging</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Clear Reply</td>\n",
              "      <td>2</td>\n",
              "      <td>Explicit</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-244fe9cb-0d42-420f-bcf0-88475567966a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-244fe9cb-0d42-420f-bcf0-88475567966a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-244fe9cb-0d42-420f-bcf0-88475567966a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6a6a88d5-4833-42c1-b27d-eb51632b8fa0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6a6a88d5-4833-42c1-b27d-eb51632b8fa0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6a6a88d5-4833-42c1-b27d-eb51632b8fa0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  clarity_label  clarity_id        evasion_label  evasion_id\n",
              "0   Clear Reply           2             Explicit           5\n",
              "1    Ambivalent           0              General           6\n",
              "2    Ambivalent           0  Partial/half-answer           8\n",
              "3    Ambivalent           0              Dodging           4\n",
              "4   Clear Reply           2             Explicit           5"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ----- Clarity labels (Task 1) -----\n",
        "clarity_labels = sorted(\n",
        "    list(set(train_df[\"clarity_label\"].dropna().unique()) |\n",
        "         set(test_df[\"clarity_label\"].dropna().unique()))\n",
        ")\n",
        "clarity2id = {lbl: i for i, lbl in enumerate(clarity_labels)}\n",
        "id2clarity = {i: lbl for lbl, i in clarity2id.items()}\n",
        "\n",
        "train_df[\"clarity_id\"] = train_df[\"clarity_label\"].map(clarity2id)\n",
        "test_df[\"clarity_id\"]  = test_df[\"clarity_label\"].map(clarity2id)\n",
        "\n",
        "print(\"Clarity mapping:\", clarity2id)\n",
        "\n",
        "# ----- Evasion labels (Task 2 – train only) -----\n",
        "evasion_labels = sorted(train_df[\"evasion_label\"].dropna().unique())\n",
        "evasion2id = {lbl: i for i, lbl in enumerate(evasion_labels)}\n",
        "id2evasion = {i: lbl for lbl, i in evasion2id.items()}\n",
        "\n",
        "mask_evasion_valid = train_df[\"evasion_label\"].notna() & (train_df[\"evasion_label\"] != \"\")\n",
        "train_df[\"evasion_id\"] = np.where(\n",
        "    mask_evasion_valid,\n",
        "    train_df[\"evasion_label\"].map(evasion2id),\n",
        "    -1,\n",
        ")\n",
        "\n",
        "print(\"Evasion mapping:\", evasion2id)\n",
        "train_df[[\"clarity_label\", \"clarity_id\", \"evasion_label\", \"evasion_id\"]].head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4KI98ty6lHmU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KI98ty6lHmU",
        "outputId": "a2e01938-491c-4e30-909c-df98fdcf372e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clarity shapes (train, val, test): (3103, 23) (345, 23) (308, 22)\n",
            "Evasion shapes (train, val): (3103, 23) (345, 23)\n"
          ]
        }
      ],
      "source": [
        "# ---- Clarity: train / val / test ----\n",
        "clar_full_train_df = train_df.copy()\n",
        "y_clar_full = clar_full_train_df[\"clarity_id\"].values\n",
        "\n",
        "clar_train_idx, clar_val_idx = train_test_split(\n",
        "    np.arange(len(clar_full_train_df)),\n",
        "    test_size=0.1,\n",
        "    stratify=y_clar_full,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "clar_train_df = clar_full_train_df.iloc[clar_train_idx].reset_index(drop=True)\n",
        "clar_val_df   = clar_full_train_df.iloc[clar_val_idx].reset_index(drop=True)\n",
        "clar_test_df  = test_df.copy()\n",
        "\n",
        "print(\"Clarity shapes (train, val, test):\",\n",
        "      clar_train_df.shape, clar_val_df.shape, clar_test_df.shape)\n",
        "\n",
        "# ---- Evasion: train / val (only rows with evasion_id != -1) ----\n",
        "evasion_train_df = train_df[train_df[\"evasion_id\"] != -1].reset_index(drop=True)\n",
        "y_eva_full = evasion_train_df[\"evasion_id\"].values\n",
        "\n",
        "ev_train_idx, ev_val_idx = train_test_split(\n",
        "    np.arange(len(evasion_train_df)),\n",
        "    test_size=0.1,\n",
        "    stratify=y_eva_full,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "ev_train_df = evasion_train_df.iloc[ev_train_idx].reset_index(drop=True)\n",
        "ev_val_df   = evasion_train_df.iloc[ev_val_idx].reset_index(drop=True)\n",
        "\n",
        "print(\"Evasion shapes (train, val):\",\n",
        "      ev_train_df.shape, ev_val_df.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FCvZ6vVv_AW9",
      "metadata": {
        "id": "FCvZ6vVv_AW9"
      },
      "source": [
        "## 4. Tokenizer & PyTorch datasets\n",
        "\n",
        "We choose a pretrained encoder (`roberta-base` or `distilroberta-base`), initialize\n",
        "its tokenizer, and define a helper to tokenize batches of texts.\n",
        "\n",
        "We then build simple PyTorch `Dataset` objects and `DataLoader`s for:\n",
        "\n",
        "- Clarity: train / val / test\n",
        "- Evasion: train / val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "k3h713S5lMfX",
      "metadata": {
        "id": "k3h713S5lMfX"
      },
      "outputs": [],
      "source": [
        "model_name = \"roberta-base\"  # you can switch to \"distilroberta-base\" for faster runs\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "max_length = 256  # can increase to 256 if your QA pairs are long\n",
        "\n",
        "def tokenize_texts(texts, labels):\n",
        "    encodings = tokenizer(\n",
        "        list(texts),\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=max_length,\n",
        "    )\n",
        "    encodings[\"labels\"] = list(labels)\n",
        "    return encodings\n",
        "\n",
        "\n",
        "class TorchTextDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "X337AmZJlQGG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X337AmZJlQGG",
        "outputId": "c270c717-e804-47ec-9bbe-a235874f22c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'input_ids': tensor([    0, 45641,    35,  1209,     4,  1534,    89,    10,  1989,  4258,\n",
              "             14,    47,    74,   356,    13,    31,    42,  2557,  1067,     7,\n",
              "           1679,   549,    47,   206,   383,    32,   164,   157,   116,    20,\n",
              "            270,     4,  2647,     6,    38,   206,     5,  3527,    74,    28,\n",
              "           1291,     4,   370,  1017,   386,    23,   513,    10,  6054,     4,\n",
              "           3047,     6,    47,   216,     6,    25,    10,   432,   621,     6,\n",
              "             38,   348,   626,   182,   157,    19,  2656,     4,   653,    47,\n",
              "            236,     7,   109,    16,   386,    14,     4,   978,     6,    38,\n",
              "           1017,   101,     7, 11829,    55,    87,    14,     4,   125,    23,\n",
              "             10,  3527,     6,    38,   109,   679,     6,    23,   513,     6,\n",
              "             52,   581,    33,  1145,   349,    97,     4,   166,    40,    33,\n",
              "            450,   349,    97,     4, 13088,     6,    52,    40,    33,  6640,\n",
              "            349,    97,     6,     8,    52,   581,   386,    14,   609,     4,\n",
              "           2847,    38,    74,   224,    14,    74,    28,     5,  9865,     4,\n",
              "            178,     5,  4532,     6,    38,   206,    47,   216,     5,  1948,\n",
              "              7,    14,     4,   125,    38,   206,    14,    40,   185,    10,\n",
              "            410,   828,     9,    86,     4, 33082,   116,  3216,     4, 11073,\n",
              "           1101,  1437,  1209,     4,  1336,   251,   109,    47,   206,    14,\n",
              "             24,    40,   185,    47,     7,  1955,    66,   549,    37,    18,\n",
              "           1473,    59,  1311,    62,    39,   578, 10975,  1243,  1906,  4748,\n",
              "            742,   116,   646,  3388,   510,   742, 31652,    35,   280,    18,\n",
              "             10,   205,   864,     4,  1336,   251,    40,    24,   185,   116,\n",
              "             38,   206,   624,     5,    78,  2289,    38,   581,   216,     4,\n",
              "              2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1]),\n",
              "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              "  'labels': tensor(0)},\n",
              " {'input_ids': tensor([    0, 45641,    35,  1209,     4,  1525,     5, 15478,   942,     4,\n",
              "            178,  1238,     5,   315,   532,     9,  8200,   436,   150,  3784,\n",
              "             13,  5813,  1431,     4,  6179,    74,    47,  2519,     7,    14,\n",
              "            116,   178,   109,    47,   206,   270,  7030,    16,   145, 19255,\n",
              "             59,   562,     5,  1291,   124,    15,  1349,    25,    37, 13187,\n",
              "           1257,    11,   436,   116,   646,  3388,   510,   742, 31652,    35,\n",
              "           2647,     6,   356,     6,    78,     9,    70,     6,     5,   100,\n",
              "            524, 19255,    59,   562,     5,  1291,   235,     4,   178,    65,\n",
              "              9,     5,   383,    14,    16,   164,    15,   122,    16,     6,\n",
              "            436,    16,  1786,     7,   464,   103,     9,     5,  1492,     9,\n",
              "              5,   177,     6,    11,  1110,     9,   721,     8,    97,   743,\n",
              "              4,  2409,    98,    65,     9,     5,   383,    52,  3244,    59,\n",
              "              6,    13,  1246,     6,    16,    14,    51,   214,   122,  1686,\n",
              "             59,   442,   686,    14,   117,   732,  3141, 14511,    65,    11,\n",
              "              5,  1111,  1621,    64,   304,    10,  2027,  3551,  1028,     4,\n",
              "           2246,  6134,     9,   383,     4,  2409,    98,     6,   269,     6,\n",
              "             99,    42,  1805,    21,    59,   405,    21,   540,    59,  8200,\n",
              "            436,     4,    38,   218,    75,   236,     7,  5585,   436,     4,\n",
              "             38,    95,   236,     7,   146,   686,    14,    52,    33,    10,\n",
              "           1291,    19,   436,    14,    16,    15,     5,    62,     8,    62,\n",
              "              6, 33756,   409,     6,  3370,  2215,    99,    24,    18,    70,\n",
              "             59,     4,   178,    65,     9,     5,  1319,    47,   109,    14,\n",
              "             16,     6,    47,   146,   686,    14,    52,    32,  1686,    59,\n",
              "              5,   276,   383,     4,  2409,    38,   206,    14,    65,     9,\n",
              "              5,   383,    52,   348,   626,   100,   348,  1381,     7,   109,\n",
              "              6,     8,    38,   348,  3244,     2]),\n",
              "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              "  'labels': tensor(6)})"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ---- Clarity tokenization ----\n",
        "clar_train_enc = tokenize_texts(clar_train_df[\"text\"], clar_train_df[\"clarity_id\"])\n",
        "clar_val_enc   = tokenize_texts(clar_val_df[\"text\"],   clar_val_df[\"clarity_id\"])\n",
        "clar_test_enc  = tokenize_texts(clar_test_df[\"text\"],  clar_test_df[\"clarity_id\"])\n",
        "\n",
        "clar_train_dataset = TorchTextDataset(clar_train_enc)\n",
        "clar_val_dataset   = TorchTextDataset(clar_val_enc)\n",
        "clar_test_dataset  = TorchTextDataset(clar_test_enc)\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "clar_train_loader = torch.utils.data.DataLoader(clar_train_dataset, batch_size=batch_size, shuffle=True)\n",
        "clar_val_loader   = torch.utils.data.DataLoader(clar_val_dataset,   batch_size=batch_size)\n",
        "clar_test_loader  = torch.utils.data.DataLoader(clar_test_dataset,  batch_size=batch_size)\n",
        "\n",
        "# ---- Evasion tokenization ----\n",
        "ev_train_enc = tokenize_texts(ev_train_df[\"text\"], ev_train_df[\"evasion_id\"])\n",
        "ev_val_enc   = tokenize_texts(ev_val_df[\"text\"],   ev_val_df[\"evasion_id\"])\n",
        "\n",
        "ev_train_dataset = TorchTextDataset(ev_train_enc)\n",
        "ev_val_dataset   = TorchTextDataset(ev_val_enc)\n",
        "\n",
        "ev_train_loader = torch.utils.data.DataLoader(ev_train_dataset, batch_size=batch_size, shuffle=True)\n",
        "ev_val_loader   = torch.utils.data.DataLoader(ev_val_dataset,   batch_size=batch_size)\n",
        "\n",
        "clar_train_dataset[0], ev_train_dataset[0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UqDN4fsT_VEC",
      "metadata": {
        "id": "UqDN4fsT_VEC"
      },
      "source": [
        "## 5. Training utilities (loss, train loop, evaluation, predictions)\n",
        "\n",
        "We implement:\n",
        "\n",
        "- `train_one_epoch`: one pass over the training set.\n",
        "- `evaluate`: compute loss, accuracy and macro F1 on a dataloader.\n",
        "- `get_predictions`: get raw predictions and labels (for classification report).\n",
        "\n",
        "We use **unweighted** cross-entropy loss here.  \n",
        "(We tested class weights earlier; they did not consistently improve macro F1, so we keep the simpler version for the main pipeline.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m3Dy2H5JlRlY",
      "metadata": {
        "id": "m3Dy2H5JlRlY"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def train_one_epoch(model, dataloader, optimizer, loss_fn):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=batch[\"input_ids\"],\n",
        "            attention_mask=batch[\"attention_mask\"],\n",
        "        )\n",
        "        logits = outputs.logits\n",
        "        loss = loss_fn(logits, batch[\"labels\"])\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    return avg_loss\n",
        "\n",
        "\n",
        "def evaluate(model, dataloader, loss_fn):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    all_labels = []\n",
        "    all_preds  = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=batch[\"input_ids\"],\n",
        "                attention_mask=batch[\"attention_mask\"],\n",
        "            )\n",
        "            logits = outputs.logits\n",
        "            loss = loss_fn(logits, batch[\"labels\"])\n",
        "\n",
        "            preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    macro_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    return avg_loss, acc, macro_f1\n",
        "\n",
        "\n",
        "def get_predictions(model, dataloader):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_preds  = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=batch[\"input_ids\"],\n",
        "                attention_mask=batch[\"attention_mask\"],\n",
        "            )\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    return np.array(all_labels), np.array(all_preds)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QqB9GvXS_ara",
      "metadata": {
        "id": "QqB9GvXS_ara"
      },
      "source": [
        "## 6. Task 1 – Clarity model: training & evaluation\n",
        "\n",
        "We fine-tune a transformer for 3-way clarity classification.\n",
        "\n",
        "- Model: `roberta-base` with a classification head.\n",
        "- Optimizer: AdamW, learning rate `2e-5`.\n",
        "- Epochs: e.g. 8 (you can tune this).\n",
        "- We keep the **best epoch** based on validation macro F1 (early stopping style).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LIA1r7zRlUA9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIA1r7zRlUA9",
        "outputId": "f675877a-44f4-4392-e897-6eaf09431a4f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "  Train loss: 0.9030\n",
            "  Val   loss: 0.8922 | acc: 0.5913 | macro F1: 0.2477\n",
            "New best clarity model saved (val macro F1 improved)\n",
            "Epoch 2/8\n",
            "  Train loss: 0.8738\n",
            "  Val   loss: 0.7850 | acc: 0.6377 | macro F1: 0.4942\n",
            "New best clarity model saved (val macro F1 improved)\n",
            "Epoch 3/8\n",
            "  Train loss: 0.7793\n",
            "  Val   loss: 0.7370 | acc: 0.6551 | macro F1: 0.5812\n",
            "New best clarity model saved (val macro F1 improved)\n",
            "Epoch 4/8\n",
            "  Train loss: 0.6921\n",
            "  Val   loss: 0.7566 | acc: 0.6667 | macro F1: 0.5708\n",
            "Epoch 5/8\n",
            "  Train loss: 0.6275\n",
            "  Val   loss: 0.7557 | acc: 0.6638 | macro F1: 0.6087\n",
            "New best clarity model saved (val macro F1 improved)\n",
            "Epoch 6/8\n",
            "  Train loss: 0.5450\n",
            "  Val   loss: 0.8770 | acc: 0.6580 | macro F1: 0.6046\n",
            "Epoch 7/8\n",
            "  Train loss: 0.4788\n",
            "  Val   loss: 0.9010 | acc: 0.6435 | macro F1: 0.5927\n",
            "Epoch 8/8\n",
            "  Train loss: 0.4242\n",
            "  Val   loss: 0.9412 | acc: 0.6377 | macro F1: 0.6268\n",
            "New best clarity model saved (val macro F1 improved)\n"
          ]
        }
      ],
      "source": [
        "num_clarity_labels = len(clarity2id)\n",
        "\n",
        "clarity_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=num_clarity_labels,\n",
        "    id2label=id2clarity,\n",
        "    label2id=clarity2id,\n",
        ").to(device)\n",
        "\n",
        "optimizer_clarity = torch.optim.AdamW(clarity_model.parameters(), lr=2e-5)\n",
        "\n",
        "num_epochs_clarity = 8  # you can try 6, 8, 10\n",
        "best_val_f1 = 0.0\n",
        "best_state_dict = None\n",
        "\n",
        "for epoch in range(num_epochs_clarity):\n",
        "    train_loss = train_one_epoch(clarity_model, clar_train_loader, optimizer_clarity, loss_fn)\n",
        "    val_loss, val_acc, val_f1 = evaluate(clarity_model, clar_val_loader, loss_fn)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs_clarity}\")\n",
        "    print(f\"  Train loss: {train_loss:.4f}\")\n",
        "    print(f\"  Val   loss: {val_loss:.4f} | acc: {val_acc:.4f} | macro F1: {val_f1:.4f}\")\n",
        "\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        best_state_dict = clarity_model.state_dict().copy()\n",
        "        print(\"New best clarity model saved (val macro F1 improved)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G-IaP_Cdla8f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-IaP_Cdla8f",
        "outputId": "0f95b855-2549-44f3-ab4a-f821ff5874fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clarity – TEST (best epoch)\n",
            "  Loss: 0.8617 | acc: 0.6201 | macro F1: 0.5294\n",
            "\n",
            "Clarity – classification report (TEST):\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     Ambivalent       0.74      0.67      0.71       206\n",
            "Clear Non-Reply       0.47      0.35      0.40        23\n",
            "    Clear Reply       0.42      0.56      0.48        79\n",
            "\n",
            "       accuracy                           0.62       308\n",
            "      macro avg       0.55      0.53      0.53       308\n",
            "   weighted avg       0.64      0.62      0.63       308\n",
            "\n",
            "Confusion matrix (rows=true, cols=pred):\n",
            "[[139   7  60]\n",
            " [ 15   8   0]\n",
            " [ 33   2  44]]\n"
          ]
        }
      ],
      "source": [
        "# Load the best epoch before evaluating on test\n",
        "if best_state_dict is not None:\n",
        "    clarity_model.load_state_dict(best_state_dict)\n",
        "\n",
        "test_loss, test_acc, test_f1 = evaluate(clarity_model, clar_test_loader, loss_fn)\n",
        "print(\"Clarity – TEST (best epoch)\")\n",
        "print(f\"  Loss: {test_loss:.4f} | acc: {test_acc:.4f} | macro F1: {test_f1:.4f}\")\n",
        "\n",
        "# Detailed per-class report\n",
        "y_true_clar, y_pred_clar = get_predictions(clarity_model, clar_test_loader)\n",
        "print(\"\\nClarity – classification report (TEST):\")\n",
        "print(classification_report(y_true_clar, y_pred_clar, target_names=clarity_labels))\n",
        "\n",
        "print(\"Confusion matrix (rows=true, cols=pred):\")\n",
        "print(confusion_matrix(y_true_clar, y_pred_clar))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52eO-tt1_q5Y",
      "metadata": {
        "id": "52eO-tt1_q5Y"
      },
      "source": [
        "## 7. Task 2 – Evasion model: training & internal validation\n",
        "\n",
        "We now fine-tune a second transformer for 9-way evasion classification.\n",
        "\n",
        "- Train/val data: only rows where `evasion_id != -1`.\n",
        "- Same idea: keep the best epoch based on validation macro F1.\n",
        "\n",
        "We do not compute test metrics yet; that will use the special annotator rule.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "r26ZJXSEzEjs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r26ZJXSEzEjs",
        "outputId": "9a355dd0-ba3d-40b7-d53d-63bb010a389b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Evasion] Epoch 1/8\n",
            "  Train loss: 1.8906\n",
            "  Val   loss: 1.8762 | acc: 0.3043 | macro F1: 0.0546\n",
            "New best evasion model saved (val macro F1 improved)\n",
            "[Evasion] Epoch 2/8\n",
            "  Train loss: 1.8117\n",
            "  Val   loss: 1.8088 | acc: 0.3043 | macro F1: 0.0759\n",
            "New best evasion model saved (val macro F1 improved)\n",
            "[Evasion] Epoch 3/8\n",
            "  Train loss: 1.7057\n",
            "  Val   loss: 1.7326 | acc: 0.3739 | macro F1: 0.2678\n",
            "New best evasion model saved (val macro F1 improved)\n",
            "[Evasion] Epoch 4/8\n",
            "  Train loss: 1.6050\n",
            "  Val   loss: 1.6716 | acc: 0.3362 | macro F1: 0.2876\n",
            "New best evasion model saved (val macro F1 improved)\n",
            "[Evasion] Epoch 5/8\n",
            "  Train loss: 1.4969\n",
            "  Val   loss: 1.6973 | acc: 0.3884 | macro F1: 0.3072\n",
            "New best evasion model saved (val macro F1 improved)\n",
            "[Evasion] Epoch 6/8\n",
            "  Train loss: 1.3798\n",
            "  Val   loss: 1.7125 | acc: 0.4029 | macro F1: 0.3594\n",
            "New best evasion model saved (val macro F1 improved)\n",
            "[Evasion] Epoch 7/8\n",
            "  Train loss: 1.2367\n",
            "  Val   loss: 1.8489 | acc: 0.3681 | macro F1: 0.3485\n",
            "[Evasion] Epoch 8/8\n",
            "  Train loss: 1.1374\n",
            "  Val   loss: 1.7895 | acc: 0.3884 | macro F1: 0.3522\n"
          ]
        }
      ],
      "source": [
        "num_evasion_labels = len(evasion2id)\n",
        "\n",
        "evasion_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=num_evasion_labels,\n",
        "    id2label=id2evasion,\n",
        "    label2id=evasion2id,\n",
        ").to(device)\n",
        "\n",
        "optimizer_eva = torch.optim.AdamW(evasion_model.parameters(), lr=2e-5)\n",
        "\n",
        "num_epochs_eva = 8  # you can tune this as well\n",
        "best_val_f1_eva = 0.0\n",
        "best_state_dict_eva = None\n",
        "\n",
        "for epoch in range(num_epochs_eva):\n",
        "    train_loss_eva = train_one_epoch(evasion_model, ev_train_loader, optimizer_eva, loss_fn)\n",
        "    val_loss_eva, val_acc_eva, val_f1_eva = evaluate(evasion_model, ev_val_loader, loss_fn)\n",
        "\n",
        "    print(f\"[Evasion] Epoch {epoch+1}/{num_epochs_eva}\")\n",
        "    print(f\"  Train loss: {train_loss_eva:.4f}\")\n",
        "    print(f\"  Val   loss: {val_loss_eva:.4f} | acc: {val_acc_eva:.4f} | macro F1: {val_f1_eva:.4f}\")\n",
        "\n",
        "    if val_f1_eva > best_val_f1_eva:\n",
        "        best_val_f1_eva = val_f1_eva\n",
        "        best_state_dict_eva = evasion_model.state_dict().copy()\n",
        "        print(\"New best evasion model saved (val macro F1 improved)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LIDu1fyBzF1B",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIDu1fyBzF1B",
        "outputId": "4a53d330-417b-4c5c-a4bb-9be196de310c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evasion – VALIDATION (best epoch)\n",
            "  Loss: 1.7895 | acc: 0.3884 | macro F1: 0.3522\n"
          ]
        }
      ],
      "source": [
        "# Load best evasion model before test evaluation\n",
        "if best_state_dict_eva is not None:\n",
        "    evasion_model.load_state_dict(best_state_dict_eva)\n",
        "\n",
        "val_loss_eva, val_acc_eva, val_f1_eva = evaluate(evasion_model, ev_val_loader, loss_fn)\n",
        "print(\"Evasion – VALIDATION (best epoch)\")\n",
        "print(f\"  Loss: {val_loss_eva:.4f} | acc: {val_acc_eva:.4f} | macro F1: {val_f1_eva:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dDB9lqX7_0bZ",
      "metadata": {
        "id": "dDB9lqX7_0bZ"
      },
      "source": [
        "## 8. Task 2 – Test evaluation with annotators\n",
        "\n",
        "The test split has no single ground-truth `evasion_label`.  \n",
        "Instead, it has `annotator1`, `annotator2`, `annotator3`.\n",
        "\n",
        "According to the dataset documentation:\n",
        "\n",
        "> Any of the annotator labels (1, 2 or 3) is considered correct.\n",
        "\n",
        "We therefore:\n",
        "\n",
        "1. Build a **set of gold labels** for each test example.\n",
        "2. Filter to those examples where at least one annotator gave a label.\n",
        "3. Run the evasion model on these test texts.\n",
        "4. Count a prediction as correct if `pred_label ∈ gold_set`.\n",
        "5. Report accuracy under this “any annotator correct” rule.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AAhfLwDFzHOD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAhfLwDFzHOD",
        "outputId": "9876b0df-b865-4910-e37b-869dd67a4c15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test examples with at least one annotator label: 308\n",
            "Total test examples: 308\n"
          ]
        }
      ],
      "source": [
        "def get_annotator_gold_set(row):\n",
        "    labels = []\n",
        "    for col in [\"annotator1\", \"annotator2\", \"annotator3\"]:\n",
        "        val = row.get(col, None)\n",
        "        if isinstance(val, str) and val != \"\":\n",
        "            labels.append(val)\n",
        "    return set(labels)\n",
        "\n",
        "test_df[\"evasion_gold_set\"] = test_df.apply(get_annotator_gold_set, axis=1)\n",
        "\n",
        "# keep only rows with at least one annotator label\n",
        "has_gold = test_df[\"evasion_gold_set\"].apply(lambda s: len(s) > 0)\n",
        "test_eva_df = test_df[has_gold].reset_index(drop=True)\n",
        "\n",
        "print(\"Test examples with at least one annotator label:\", len(test_eva_df))\n",
        "print(\"Total test examples:\", len(test_df))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3p_DGjJX_7Ix",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p_DGjJX_7Ix",
        "outputId": "90a70324-506f-4bf8-f126-742cab1b4847"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task 2 – TEST accuracy (any annotator is correct): 0.4383116883116883\n"
          ]
        }
      ],
      "source": [
        "# Tokenize test texts for evasion\n",
        "test_eva_enc = tokenize_texts(test_eva_df[\"text\"], [0] * len(test_eva_df))  # dummy labels\n",
        "test_eva_dataset = TorchTextDataset(test_eva_enc)\n",
        "test_eva_loader  = torch.utils.data.DataLoader(test_eva_dataset, batch_size=batch_size)\n",
        "\n",
        "# Get predictions\n",
        "evasion_model.eval()\n",
        "pred_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_eva_loader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}  # ignore dummy labels\n",
        "\n",
        "        outputs = evasion_model(\n",
        "            input_ids=batch[\"input_ids\"],\n",
        "            attention_mask=batch[\"attention_mask\"],\n",
        "        )\n",
        "        logits = outputs.logits\n",
        "        preds = torch.argmax(logits, dim=-1)\n",
        "        pred_labels.extend(preds.cpu().numpy())\n",
        "\n",
        "pred_labels = [id2evasion[i] for i in pred_labels]\n",
        "\n",
        "gold_sets = test_eva_df[\"evasion_gold_set\"].tolist()\n",
        "\n",
        "correct_flags = [\n",
        "    (pred in gold)\n",
        "    for pred, gold in zip(pred_labels, gold_sets)\n",
        "]\n",
        "\n",
        "accuracy_any_annot = np.mean(correct_flags)\n",
        "print(\"Task 2 – TEST accuracy (any annotator is correct):\", accuracy_any_annot)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "M2JCwVEz0qcX",
      "metadata": {
        "id": "M2JCwVEz0qcX"
      },
      "source": [
        "## 9. Multi-task model: shared encoder for clarity + evasion\n",
        "\n",
        "We now define a single model with:\n",
        "- one shared transformer encoder,\n",
        "- one classification head for **clarity** (3 classes),\n",
        "- one classification head for **evasion** (9 classes).\n",
        "\n",
        "During training:\n",
        "- all examples contribute to the clarity loss;\n",
        "- only examples with a valid evasion label contribute to the evasion loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LPUBLUF20p-C",
      "metadata": {
        "id": "LPUBLUF20p-C"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from transformers import AutoModel\n",
        "\n",
        "class MultiTaskQEvasionModel(nn.Module):\n",
        "    def __init__(self, model_name, num_clarity_labels, num_evasion_labels):\n",
        "        super().__init__()\n",
        "        # Shared encoder (RoBERTa encoder without classification head)\n",
        "        self.encoder = AutoModel.from_pretrained(model_name)\n",
        "        hidden_size = self.encoder.config.hidden_size\n",
        "\n",
        "        self.dropout = nn.Dropout(self.encoder.config.hidden_dropout_prob)\n",
        "\n",
        "        # Clarity head (3 classes)\n",
        "        self.clarity_head = nn.Linear(hidden_size, num_clarity_labels)\n",
        "        # Evasion head (9 classes)\n",
        "        self.evasion_head = nn.Linear(hidden_size, num_evasion_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # Standard transformer forward\n",
        "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        # CLS / <s> token representation\n",
        "        pooled = outputs.last_hidden_state[:, 0]  # (batch_size, hidden_size)\n",
        "        pooled = self.dropout(pooled)\n",
        "\n",
        "        clarity_logits = self.clarity_head(pooled)\n",
        "        evasion_logits = self.evasion_head(pooled)\n",
        "\n",
        "        return clarity_logits, evasion_logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mQGxeXXm0ud0",
      "metadata": {
        "id": "mQGxeXXm0ud0"
      },
      "source": [
        "### 9.1 Multi-task dataset (clarity + evasion) for train/val\n",
        "\n",
        "We build a single dataset where each example has:\n",
        "- tokenized `text`,\n",
        "- `clarity_labels` (always defined),\n",
        "- `evasion_labels` (== -1 if missing),\n",
        "- `evasion_mask` (1 if evasion label exists, else 0).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Z1vpxZwt0si-",
      "metadata": {
        "id": "Z1vpxZwt0si-"
      },
      "outputs": [],
      "source": [
        "def tokenize_multitask(df):\n",
        "    enc = tokenizer(\n",
        "        list(df[\"text\"]),\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=max_length,\n",
        "    )\n",
        "    enc[\"clarity_labels\"] = df[\"clarity_id\"].tolist()\n",
        "    # evasion_id is -1 when no label (train); on val split, same\n",
        "    enc[\"evasion_labels\"] = df[\"evasion_id\"].tolist()\n",
        "    enc[\"evasion_mask\"] = [1 if eid != -1 else 0 for eid in df[\"evasion_id\"]]\n",
        "    return enc\n",
        "\n",
        "class MultiTaskDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(self.encodings[\"input_ids\"][idx]),\n",
        "            \"attention_mask\": torch.tensor(self.encodings[\"attention_mask\"][idx]),\n",
        "            \"clarity_labels\": torch.tensor(self.encodings[\"clarity_labels\"][idx]),\n",
        "            \"evasion_labels\": torch.tensor(self.encodings[\"evasion_labels\"][idx]),\n",
        "            \"evasion_mask\": torch.tensor(self.encodings[\"evasion_mask\"][idx]),\n",
        "        }\n",
        "\n",
        "# Build encodings for train/val\n",
        "mt_train_enc = tokenize_multitask(clar_train_df)\n",
        "mt_val_enc   = tokenize_multitask(clar_val_df)\n",
        "\n",
        "mt_train_dataset = MultiTaskDataset(mt_train_enc)\n",
        "mt_val_dataset   = MultiTaskDataset(mt_val_enc)\n",
        "\n",
        "batch_size = 8  # reuse your value\n",
        "\n",
        "mt_train_loader = torch.utils.data.DataLoader(mt_train_dataset, batch_size=batch_size, shuffle=True)\n",
        "mt_val_loader   = torch.utils.data.DataLoader(mt_val_dataset,   batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "upv8HgUR0_m5",
      "metadata": {
        "id": "upv8HgUR0_m5"
      },
      "source": [
        "### 9.2 Training & evaluation for the multi-task model\n",
        "\n",
        "Loss:\n",
        "- `L_total = L_clarity + alpha * L_evasion` (only where evasion_mask == 1)\n",
        "\n",
        "Metrics:\n",
        "- Clarity accuracy / macro F1 on all examples.\n",
        "- Evasion accuracy / macro F1 on the subset with labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qRFnwrtm0_8x",
      "metadata": {
        "id": "qRFnwrtm0_8x"
      },
      "outputs": [],
      "source": [
        "alpha = 1.0  # weight for evasion loss\n",
        "ce_clarity = nn.CrossEntropyLoss()\n",
        "ce_evasion = nn.CrossEntropyLoss()\n",
        "\n",
        "def train_one_epoch_multitask(model, dataloader, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        clarity_logits, evasion_logits = model(\n",
        "            input_ids=batch[\"input_ids\"],\n",
        "            attention_mask=batch[\"attention_mask\"],\n",
        "        )\n",
        "\n",
        "        clarity_labels = batch[\"clarity_labels\"]\n",
        "        evasion_labels = batch[\"evasion_labels\"]\n",
        "        evasion_mask   = batch[\"evasion_mask\"].bool()\n",
        "\n",
        "        loss_cl = ce_clarity(clarity_logits, clarity_labels)\n",
        "\n",
        "        if evasion_mask.any():\n",
        "            loss_ev = ce_evasion(\n",
        "                evasion_logits[evasion_mask],\n",
        "                evasion_labels[evasion_mask],\n",
        "            )\n",
        "            loss = loss_cl + alpha * loss_ev\n",
        "        else:\n",
        "            loss = loss_cl\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "\n",
        "def evaluate_multitask(model, dataloader):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    all_cl_labels = []\n",
        "    all_cl_preds  = []\n",
        "\n",
        "    all_ev_labels = []\n",
        "    all_ev_preds  = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "            clarity_logits, evasion_logits = model(\n",
        "                input_ids=batch[\"input_ids\"],\n",
        "                attention_mask=batch[\"attention_mask\"],\n",
        "            )\n",
        "\n",
        "            clarity_labels = batch[\"clarity_labels\"]\n",
        "            evasion_labels = batch[\"evasion_labels\"]\n",
        "            evasion_mask   = batch[\"evasion_mask\"].bool()\n",
        "\n",
        "            loss_cl = ce_clarity(clarity_logits, clarity_labels)\n",
        "            if evasion_mask.any():\n",
        "                loss_ev = ce_evasion(\n",
        "                    evasion_logits[evasion_mask],\n",
        "                    evasion_labels[evasion_mask],\n",
        "                )\n",
        "                loss = loss_cl + alpha * loss_ev\n",
        "            else:\n",
        "                loss = loss_cl\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Clarity preds (all examples)\n",
        "            cl_pred = torch.argmax(clarity_logits, dim=-1)\n",
        "            all_cl_labels.extend(clarity_labels.cpu().numpy())\n",
        "            all_cl_preds.extend(cl_pred.cpu().numpy())\n",
        "\n",
        "            # Evasion preds (only where label exists)\n",
        "            if evasion_mask.any():\n",
        "                ev_pred = torch.argmax(evasion_logits, dim=-1)\n",
        "                all_ev_labels.extend(evasion_labels[evasion_mask].cpu().numpy())\n",
        "                all_ev_preds.extend(ev_pred[evasion_mask].cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "\n",
        "    # Clarity metrics\n",
        "    cl_acc = accuracy_score(all_cl_labels, all_cl_preds)\n",
        "    cl_f1  = f1_score(all_cl_labels, all_cl_preds, average=\"macro\")\n",
        "\n",
        "    # Evasion metrics (only if we have any labels)\n",
        "    if len(all_ev_labels) > 0:\n",
        "        ev_acc = accuracy_score(all_ev_labels, all_ev_preds)\n",
        "        ev_f1  = f1_score(all_ev_labels, all_ev_preds, average=\"macro\")\n",
        "    else:\n",
        "        ev_acc, ev_f1 = None, None\n",
        "\n",
        "    return avg_loss, cl_acc, cl_f1, ev_acc, ev_f1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WdxPzUEp1D8d",
      "metadata": {
        "id": "WdxPzUEp1D8d"
      },
      "source": [
        "### 9.3 Train multi-task model (clarity + evasion)\n",
        "\n",
        "We keep the best epoch according to validation **clarity macro F1**.\n",
        "You can also choose to use a combined criterion later.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "0zqoXAjI1ERA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zqoXAjI1ERA",
        "outputId": "9abdde46-ebee-41bd-fc25-38ef8e102052"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MT] Epoch 1/10\n",
            "  Train loss: 2.7785\n",
            "  Val   loss: 2.6182\n",
            "  Clarity  - acc: 0.6000 | macro F1: 0.3391\n",
            "  Evasion  - acc: 0.3043 | macro F1: 0.0519\n",
            "New best multi-task model saved (val clarity macro F1 improved)\n",
            "[MT] Epoch 2/10\n",
            "  Train loss: 2.4972\n",
            "  Val   loss: 2.4398\n",
            "  Clarity  - acc: 0.6377 | macro F1: 0.5865\n",
            "  Evasion  - acc: 0.3768 | macro F1: 0.2372\n",
            "New best multi-task model saved (val clarity macro F1 improved)\n",
            "[MT] Epoch 3/10\n",
            "  Train loss: 2.2665\n",
            "  Val   loss: 2.4156\n",
            "  Clarity  - acc: 0.6580 | macro F1: 0.6081\n",
            "  Evasion  - acc: 0.4087 | macro F1: 0.3220\n",
            "New best multi-task model saved (val clarity macro F1 improved)\n",
            "[MT] Epoch 4/10\n",
            "  Train loss: 2.0341\n",
            "  Val   loss: 2.2763\n",
            "  Clarity  - acc: 0.6783 | macro F1: 0.6062\n",
            "  Evasion  - acc: 0.4058 | macro F1: 0.3543\n",
            "[MT] Epoch 5/10\n",
            "  Train loss: 1.8251\n",
            "  Val   loss: 2.4216\n",
            "  Clarity  - acc: 0.6696 | macro F1: 0.6086\n",
            "  Evasion  - acc: 0.4145 | macro F1: 0.3707\n",
            "New best multi-task model saved (val clarity macro F1 improved)\n",
            "[MT] Epoch 6/10\n",
            "  Train loss: 1.6556\n",
            "  Val   loss: 2.5859\n",
            "  Clarity  - acc: 0.6609 | macro F1: 0.6090\n",
            "  Evasion  - acc: 0.3884 | macro F1: 0.3706\n",
            "New best multi-task model saved (val clarity macro F1 improved)\n",
            "[MT] Epoch 7/10\n",
            "  Train loss: 1.4867\n",
            "  Val   loss: 2.6785\n",
            "  Clarity  - acc: 0.6435 | macro F1: 0.6318\n",
            "  Evasion  - acc: 0.4058 | macro F1: 0.3769\n",
            "New best multi-task model saved (val clarity macro F1 improved)\n",
            "[MT] Epoch 8/10\n",
            "  Train loss: 1.3652\n",
            "  Val   loss: 2.6377\n",
            "  Clarity  - acc: 0.6783 | macro F1: 0.6233\n",
            "  Evasion  - acc: 0.4058 | macro F1: 0.3900\n",
            "[MT] Epoch 9/10\n",
            "  Train loss: 1.2427\n",
            "  Val   loss: 3.1631\n",
            "  Clarity  - acc: 0.6812 | macro F1: 0.6455\n",
            "  Evasion  - acc: 0.4232 | macro F1: 0.4198\n",
            "New best multi-task model saved (val clarity macro F1 improved)\n",
            "[MT] Epoch 10/10\n",
            "  Train loss: 1.1406\n",
            "  Val   loss: 3.2555\n",
            "  Clarity  - acc: 0.6812 | macro F1: 0.6558\n",
            "  Evasion  - acc: 0.4290 | macro F1: 0.4114\n",
            "New best multi-task model saved (val clarity macro F1 improved)\n"
          ]
        }
      ],
      "source": [
        "num_clarity_labels = len(clarity2id)\n",
        "num_evasion_labels = len(evasion2id)\n",
        "\n",
        "mt_model = MultiTaskQEvasionModel(\n",
        "    model_name=model_name,\n",
        "    num_clarity_labels=num_clarity_labels,\n",
        "    num_evasion_labels=num_evasion_labels,\n",
        ").to(device)\n",
        "\n",
        "optimizer_mt = torch.optim.AdamW(mt_model.parameters(), lr=2e-5)\n",
        "\n",
        "num_epochs_mt = 10  # start with 6; you can try 8 later\n",
        "\n",
        "best_val_cl_f1 = 0.0\n",
        "best_state_dict_mt = None\n",
        "\n",
        "for epoch in range(num_epochs_mt):\n",
        "    train_loss_mt = train_one_epoch_multitask(mt_model, mt_train_loader, optimizer_mt)\n",
        "    val_loss_mt, cl_acc_mt, cl_f1_mt, ev_acc_mt, ev_f1_mt = evaluate_multitask(mt_model, mt_val_loader)\n",
        "\n",
        "    print(f\"[MT] Epoch {epoch+1}/{num_epochs_mt}\")\n",
        "    print(f\"  Train loss: {train_loss_mt:.4f}\")\n",
        "    print(f\"  Val   loss: {val_loss_mt:.4f}\")\n",
        "    print(f\"  Clarity  - acc: {cl_acc_mt:.4f} | macro F1: {cl_f1_mt:.4f}\")\n",
        "    if ev_acc_mt is not None:\n",
        "        print(f\"  Evasion  - acc: {ev_acc_mt:.4f} | macro F1: {ev_f1_mt:.4f}\")\n",
        "\n",
        "    if cl_f1_mt > best_val_cl_f1:\n",
        "        best_val_cl_f1 = cl_f1_mt\n",
        "        best_state_dict_mt = mt_model.state_dict().copy()\n",
        "        print(\"New best multi-task model saved (val clarity macro F1 improved)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "p4PVCynI1JiR",
      "metadata": {
        "id": "p4PVCynI1JiR"
      },
      "source": [
        "### 9.4 Clarity evaluation on TEST (using multi-task model)\n",
        "\n",
        "We reuse the existing `clar_test_enc` / `clar_test_loader`, but pass batches through\n",
        "the multi-task model and use only the clarity head.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "RbW-X2RE1J4D",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbW-X2RE1J4D",
        "outputId": "0dbc97fe-44e3-4286-8fe9-6b37a6cedb2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multi-task model – Clarity TEST\n",
            "  acc: 0.6591 | macro F1: 0.5460\n"
          ]
        }
      ],
      "source": [
        "# Reload best multi-task model\n",
        "if best_state_dict_mt is not None:\n",
        "    mt_model.load_state_dict(best_state_dict_mt)\n",
        "\n",
        "# Use the existing clarity test loader: clar_test_loader\n",
        "mt_model.eval()\n",
        "all_labels_test = []\n",
        "all_preds_test  = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in clar_test_loader:\n",
        "        batch_gpu = {k: v.to(device) for k, v in batch.items()}\n",
        "        clarity_logits, _ = mt_model(\n",
        "            input_ids=batch_gpu[\"input_ids\"],\n",
        "            attention_mask=batch_gpu[\"attention_mask\"],\n",
        "        )\n",
        "        preds = torch.argmax(clarity_logits, dim=-1)\n",
        "\n",
        "        all_labels_test.extend(batch_gpu[\"labels\"].cpu().numpy())\n",
        "        all_preds_test.extend(preds.cpu().numpy())\n",
        "\n",
        "cl_test_acc  = accuracy_score(all_labels_test, all_preds_test)\n",
        "cl_test_f1   = f1_score(all_labels_test, all_preds_test, average=\"macro\")\n",
        "\n",
        "print(\"Multi-task model – Clarity TEST\")\n",
        "print(f\"  acc: {cl_test_acc:.4f} | macro F1: {cl_test_f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate multi-task model on TEST for EVASION (any annotator is correct)\n",
        "\n",
        "# 1) Build gold label sets from annotators\n",
        "def get_annotator_gold_set(row):\n",
        "    labels = []\n",
        "    for col in [\"annotator1\", \"annotator2\", \"annotator3\"]:\n",
        "        val = row.get(col, None)\n",
        "        if isinstance(val, str) and val != \"\":\n",
        "            labels.append(val)\n",
        "    return set(labels)\n",
        "\n",
        "test_df[\"evasion_gold_set\"] = test_df.apply(get_annotator_gold_set, axis=1)\n",
        "has_gold = test_df[\"evasion_gold_set\"].apply(lambda s: len(s) > 0)\n",
        "test_eva_df = test_df[has_gold].reset_index(drop=True)\n",
        "\n",
        "print(\"Test examples with at least one annotator label:\", len(test_eva_df))\n",
        "print(\"Total test examples:\", len(test_df))\n",
        "\n",
        "# 2) Tokenize test texts (dummy labels just to reuse the dataset class)\n",
        "test_eva_enc = tokenize_texts(test_eva_df[\"text\"], labels=[0] * len(test_eva_df))\n",
        "test_eva_dataset = TorchTextDataset(test_eva_enc)\n",
        "test_eva_loader  = torch.utils.data.DataLoader(test_eva_dataset, batch_size=batch_size)\n",
        "\n",
        "# 3) Use the multi-task model's evasion head to get predictions\n",
        "if best_state_dict_mt is not None:\n",
        "    mt_model.load_state_dict(best_state_dict_mt)\n",
        "\n",
        "mt_model.eval()\n",
        "pred_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_eva_loader:\n",
        "        batch_gpu = {k: v.to(device) for k, v in batch.items()}\n",
        "        _, evasion_logits = mt_model(\n",
        "            input_ids=batch_gpu[\"input_ids\"],\n",
        "            attention_mask=batch_gpu[\"attention_mask\"],\n",
        "        )\n",
        "        preds = torch.argmax(evasion_logits, dim=-1)\n",
        "        pred_labels.extend(preds.cpu().numpy())\n",
        "\n",
        "pred_labels_str = [id2evasion[i] for i in pred_labels]\n",
        "gold_sets = test_eva_df[\"evasion_gold_set\"].tolist()\n",
        "\n",
        "# 4) Accuracy with \"any annotator is correct\" rule\n",
        "correct_flags = [\n",
        "    (pred in gold)\n",
        "    for pred, gold in zip(pred_labels_str, gold_sets)\n",
        "]\n",
        "\n",
        "accuracy_any_annot = np.mean(correct_flags)\n",
        "print(\"Multi-task model – Task 2 (Evasion) TEST accuracy (any annotator correct):\", accuracy_any_annot)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAeVdKTvNR5S",
        "outputId": "e9907ab5-e33b-4dfd-e7e2-d3bb147d326d"
      },
      "id": "iAeVdKTvNR5S",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test examples with at least one annotator label: 308\n",
            "Total test examples: 308\n",
            "Multi-task model – Task 2 (Evasion) TEST accuracy (any annotator correct): 0.4642857142857143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate multi-task model on the VALIDATION split\n",
        "val_loss_mt, cl_acc_mt, cl_f1_mt, ev_acc_mt, ev_f1_mt = evaluate_multitask(mt_model, mt_val_loader)\n",
        "\n",
        "print(\"Multi-task model – VALIDATION\")\n",
        "print(f\"  Loss: {val_loss_mt:.4f}\")\n",
        "print(f\"  Clarity  -> acc: {cl_acc_mt:.4f} | macro F1: {cl_f1_mt:.4f}\")\n",
        "\n",
        "if ev_acc_mt is not None:\n",
        "    print(f\"  Evasion  -> acc: {ev_acc_mt:.4f} | macro F1: {ev_f1_mt:.4f}\")\n",
        "else:\n",
        "    print(\"  Evasion  -> no labeled examples in this split.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DPt4B9_Gqx9",
        "outputId": "a24f721f-cecf-4834-e2f5-1ef06af8a25d"
      },
      "id": "-DPt4B9_Gqx9",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multi-task model – VALIDATION\n",
            "  Loss: 3.2555\n",
            "  Clarity  -> acc: 0.6812 | macro F1: 0.6558\n",
            "  Evasion  -> acc: 0.4290 | macro F1: 0.4114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "huT7IIhPNNte"
      },
      "id": "huT7IIhPNNte",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}