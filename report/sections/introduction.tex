\section{Introduction}
\label{sec:introduction}

In political interviews and debates, responses to questions often fail to address the information requested, despite appearing relevant on the surface. Such evasive behavior allows speakers to maintain strategic ambiguity and manage accountability, making it a central phenomenon in political communication.

Automatically detecting question evasion is challenging, as it requires more than lexical or semantic similarity between a question and its answer. Effective models must capture pragmatic alignment and intent, reasoning about whether a response truly addresses the question.

The CLARITY shared task at SemEval-2026 provides a structured framework for studying this problem using annotated political question--answer pairs. Two complementary subtasks are defined: response clarity classification and evasion strategy identification, capturing both coarse-grained and fine-grained aspects of evasive behavior.

In this work, we investigate how different modeling choices affect political evasion detection. In particular, we address the following research questions:

\begin{enumerate}
    \item \textbf{RQ1:} How do transformer-based models compare to traditional baselines based on TF--IDF features and linear classifiers for clarity and evasion classification?
    \item \textbf{RQ2:} How does severe class imbalance in evasion strategy labels affect model performance, and can focal loss mitigate this issue?
    \item \textbf{RQ3:} Which transformer architecture (BERT, DistilBERT, ALBERT) offers the best trade-off between predictive performance and computational efficiency?
    \item \textbf{RQ4:} To what extent can an LLM using in-context learning capture strategic evasion, and how does the inclusion of representative examples and explicit reasoning chains affect its adherence to the label taxonomy?
\end{enumerate}

Our contributions are threefold. We provide a systematic comparison between classical baselines and transformer-based models for the CLARITY shared task, analyze the benefits and limitations of multi-task learning for joint clarity and evasion prediction, and conduct an empirical study of class imbalance effects through the use of focal loss for evasion strategy classification. All code and trained models are released for reproducibility.\footnote{\url{https://github.com/minh-de-rien/political-evasion-classifier}}