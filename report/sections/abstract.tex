Question evasion is a pervasive strategy in political communication, where speakers avoid addressing the information requested while maintaining rhetorical control. This phenomenon is the focus of the CLARITY shared task at SemEval-2026, which targets the automatic identification of evasive behavior in political questionâ€“answer pairs. This paper presents a supervised classification approach to equivocation detection using transformer-based language models that jointly encode questions and responses. We compare baseline methods (SVM with TF-IDF features) against fine-tuned transformers (BERT, DistilBERT, ALBERT) for two subtasks: clarity-level classification (3 classes) and evasion strategy identification (9 classes). We further explore multi-task learning to leverage shared representations across tasks. Our best single-task model achieves 68.8\% accuracy and 0.50 macro F1 on Task 1 (Clarity), while Task 2 (Evasion) proves more challenging with 44.2\% accuracy under multi-annotator evaluation. Analysis reveals that class imbalance and annotator disagreement remain key challenges for fine-grained evasion classification.